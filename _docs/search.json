[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AM1: Vergleichende Empirische Populismusforschung",
    "section": "",
    "text": "Auf dieser Seite findet ihr den Kursplan f√ºr das Semester. Alle Lekt√ºren, Fragenkataloge und die Slides der Pr√§sentationen sind hier verlinkt.\nBitte nehmt in der Syllabus das verpflichtende Blockseminar am 07. Juli zur Kenntnis!\n\n\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n  \n    \n      Woche\n      Datum\n      Uhrzeit\n      Raum\n      Thema\n      Lekt√ºre\n      Fragen\n    \n  \n  \n    1\nTue, Apr 4\n10:15 - 11:45\nZoom Raum\n\nEinf√ºhrung\n\nüìö\n\n‚ùì\n    2\nTue, Apr 11\n10:15 - 11:45\n\nEntf√§llt\n\n\n\n    3\nTue, Apr 18\n10:15 - 11:45\n\nEntf√§llt\n\n\n\n    4\nTue, Apr 25\n10:15 - 11:45\n\nEntf√§llt\n\n\n\n    5\nTue, May 2\n10:15 - 11:45\nZoom Raum\n\nIdeational Approach to Populism\n\nüìö Mudde, Rovira Kaltwasser (2017): A Very Short Introduction to Populism. Chapter 1.\n\n‚ùì\n    6\nTue, May 9\n10:15 - 11:45\nWiWi 2095/2197\n\nCoding Populist Parties\n\nüìö [Zoom Raum]\n\n‚ùì\n    7\nTue, May 16\n\n\nüèñÔ∏è Pfingstferien\n\n\n\n    8\nTue, May 23\n10:15 - 11:45\nWiWi 2095/2197\n\nPopulism & Democracy - The theoretical account\n\nüìö\n\n‚ùì\n    9\nTue, May 30\n10:15 - 11:45\nWiWi 2095/2197\n\nPopulists in Power - Empirics\n\nüìö\n\n‚ùì\n    10\nTue, Jun 6\n10:15 - 11:45\nWiWi 2095/2197\n\nPopulism & Democracy\n\nüìö\n\n‚ùì\n    11\nTue, Jun 13\n10:15 - 11:45\nWiWi 2095/2197\n\nVoting for Populists\n\nüìö\n\n‚ùì\n    12\nTue, Jun 20\n10:15 - 11:45\nWiWi 2095/2197\n\nVoting for Populists\n\nüìö\n\n‚ùì\n    13\nTue, Jun 27\n10:15 - 11:45\nWiWi 2095/2197\n\nPopulist Communication - Theory\n\nüìö\n\n‚ùì\n    14\nTue, Jul 4\n10:15 - 11:45\nWiWi 2095/2197\n\nPopulist Communication - Empirics\n\nüìö\n\n‚ùì\n    \nFri, Jul 7\n14:15 - 19:45\nVMP 9 B130\n\n\nüìö\n\n‚ùì\n    15\nTue, Jul 11\n10:15 - 11:45\nWiWi 2095/2197\n\n\nüìö\n\n‚ùì"
  },
  {
    "objectID": "project/project-1.html",
    "href": "project/project-1.html",
    "title": "Project 1",
    "section": "",
    "text": "For this project, you will be using a dataset from the TidyTuesday project. You can choose any dataset you want from the datasets released in 2022 as part of this project: https://github.com/rfordatascience/tidytuesday/tree/master/data/2022#readme. Your task for the project is to come up with two questions to answer, answer them with data visualizations, and write-up and present your method and findings. You will also get to peer review others‚Äô projects."
  },
  {
    "objectID": "project/project-1.html#dataset",
    "href": "project/project-1.html#dataset",
    "title": "Project 1",
    "section": "Dataset",
    "text": "Dataset\nChoosing a dataset is something you should do carefully but also relatively quickly (during the first lab session that you‚Äôre working on the project).\nThe dataset you choose should have some numerical and some categorical variables or you should be able to recode some of the existing variables so that you can ultimately have both numerical and categorical variables to work with.\nIt is also very important that the dataset you choose allows for two distinct questions to be asked and answered using a not-completely-overlapping set of variables, i.e., Question 1 requires the use of variables x, y, and z and Question 2 requires the use of variables a, b, c, and d or x, a, and b. Some shared variables are ok, but the set of variables should not be completely overlapping, i.e., Question 2 can‚Äôt also require the use of variables x, y, and z."
  },
  {
    "objectID": "project/project-1.html#questions",
    "href": "project/project-1.html#questions",
    "title": "Project 1",
    "section": "Questions",
    "text": "Questions\nEach of the two questions you come up with should involve more than two variables two answer. You should phrase them in a way that the is within the scope of inference of your data. For example, if you have an observational dataset, you shouldn‚Äôt phrase your question in a causal way."
  },
  {
    "objectID": "project/project-1.html#workflow",
    "href": "project/project-1.html#workflow",
    "title": "Project 1",
    "section": "Workflow",
    "text": "Workflow\n\nWeek 1 of project (week of January 30): Choose a dataset and write up your proposal in proposal.qmd.\nWeek 2 of project (week of February 6): Provide peer review to two other teams in the form of issues in their GitHub repos, address the issues left on your team‚Äôs project repo by closing them with explicit commits. Feel free to get started on your presentation as well.\nWeek 3 of project (week of February 13): Review feedback from me on your proposal and close any remaining issues. Work on your presentation in presentation.qmd and write-up in README.qmd.\nWeek 4 of project (week of February 20): Finalize your write-up, presentation, and your project website. Present in lab on the Wednesday of this week."
  },
  {
    "objectID": "project/project-1.html#due-dates",
    "href": "project/project-1.html#due-dates",
    "title": "Project 1",
    "section": "Due dates",
    "text": "Due dates\n\nProposals for peer review: due on Tuesday, February 7 at noon.\nRevised proposals for teaching team review: due Friday, February 10 at 5pm.\nWrite-up and presentation: due Wednesday, February 22 at the beginning of your lab section."
  },
  {
    "objectID": "project/project-1.html#deliverables",
    "href": "project/project-1.html#deliverables",
    "title": "Project 1",
    "section": "Deliverables",
    "text": "Deliverables\n\nProposal\nYour proposal should include:\n\nA brief description of your dataset including its provenance, dimensions, etc. (Make sure to load the data and use inline code for some of this information.)\nThe reason why you chose this dataset.\nThe two questions you want to answer.\nA plan for answering each of the questions including the variables involved, variables to be created (if any), external data to be merged in (if any).\n\n\n\nPeer review\n\nReviewer tasks\nEach team will review the proposals of two other teams. The peer review will be completed during the lab session on Wednesday, February 8. On that day teams will have access to the project repos of the two teams whose work they‚Äôre reviewing. Reviews should start by cloning the team‚Äôs repo, re-rendering it locally to make sure you can reproduce their work, and then adding an issue to their repo with your peer review feedback.\nThe reviewer / reviewee assignments can be found below:\n\n\n\n\n\n\n  \n  \n    \n      lab\n      reviewer\n      reviewee_1\n      reviewee_2\n    \n  \n  \n    1\nthe_tibbles\nstats_fm\nphans_of_statistics\n    1\nstats_fm\nphans_of_statistics\nskaz\n    1\nphans_of_statistics\nskaz\nmessi\n    1\nskaz\nmessi\nteam_six\n    1\nmessi\nteam_six\ncia\n    1\nteam_six\ncia\nblue_team\n    1\ncia\nblue_team\nthe_tibbles\n    1\nblue_team\nthe_tibbles\nstats_fm\n    2\npipe_it_up\nrgodz\nmarvel_cinematic_tidyverse\n    2\nco_medians\npipe_it_up\nrgodz\n    2\nviz_villians\nco_medians\npipe_it_up\n    2\no_ggs\nviz_villians\nco_medians\n    2\nvisualization_warriors\no_ggs\nviz_villians\n    2\nggplot_lessthan_3\nvisualization_warriors\no_ggs\n    2\nmarvel_cinematic_tidyverse\nggplot_lessthan_3\nvisualization_warriors\n    2\nrgodz\nmarvel_cinematic_tidyverse\nggplot_lessthan_3\n  \n  \n  \n\n\n\n\nTeams will develop the review together, with discussion among all team members, but only one team member will submit it as an issue on the project repo. To do so, go to the Issues tab, click on the green New issue button on the top right, and then click on the green Get started button for the issue template titled Peer review.\nThis will start a new issue with a peer review form that you can fill out. Make sure to update the introductory paragraph with your team name and the names of the team members participating in the review. Then, answer each of the questions in the spaces provided underneath them. You‚Äôre expected to be thorough in your review, but this doesn‚Äôt necessarily require lengthy responses.\nRemember, your goal is to help the team whose project proposal you‚Äôre reviewing. The team will not lose points because of issues you point out, as long as they address them before I review their proposals. You should be critical, but respectful in your review. Also remember that you will be evaluated on the quality of your review. So that‚Äôs an additional incentive to do a good job.\n\n\nReviewee tasks\nOnce you receive feedback from your peers, you should address them. You should do this by directly updating your proposal or making any other updates to your repo as needed. You can do these updates all in one commit or you can spread it across multiple commits. Regardless, in the last commit that addresses the peer review comments, you should use a keyword in your commit message that will close the peer review issues. These words are close, closes, closed, fix, fixes, fixed, resolve, resolves, and resolved and they need to be followed by the issue number (which you can find next to the issue title). So, your commit message can say something like ‚ÄúFinished updates based on peer review, fixes #1‚Äù.\n\n\n\nWrite-up\nYour write-up should consist of three parts:\n\nIntroduction (1-2 paragraphs): Brief introduction to the dataset. You may repeat some of the information about the dataset provided in the introduction to the dataset on the TidyTuesday repository, paraphrasing on your own terms. Imagine that your project is a standalone document and the grader has no prior knowledge of the dataset.\nQuestion 1: The title should relate to the question you‚Äôre answering.\n\nIntroduction (1-2 paragraphs): Introduction to the question and what parts of the dataset are necessary to answer the question. Also discuss why you‚Äôre interested in this question.\nApproach (1-2 paragraphs): Describe what types of plots you are going to make to address your question. For each plot, provide a clear explanation as to why this plot (e.g.¬†boxplot, barplot, histogram, etc.) is best for providing the information you are asking about. The two plots should be of different types, and at least one of the two plots needs to use either color mapping or facets.\nAnalysis (2-3 code blocks, 2 figures, text/code comments as needed): In this section, provide the code that generates your plots. Use scale functions to provide nice axis labels and guides. You are welcome to use theme functions to customize the appearance of your plot, but you are not required to do so. All plots must be made with ggplot2. Do not use base R or lattice plotting functions.\nDiscussion (1-3 paragraphs): In the Discussion section, interpret the results of your analysis. Identify any trends revealed (or not revealed) by the plots. Speculate about why the data looks the way it does.\n\nQuestion 2: Same structure outlined for Question 1, but for your new question. And the title should relate to the question you‚Äôre answering.\n\nWe encourage you to be concise. A paragraph should typically not be longer than 5 sentences.\nYou are not required to perform any statistical tests in this project, but you may do so if you find it helpful to answer your question.\n\n\nPresentation\nYour presentation should generally follow the same structure as your write-up. Each team will have 5 minutes for their presentation, and each team member must speak (roughly equally) during this time. Your presentation will be created using Quarto, which allows you to write slides using the same Quarto structure you‚Äôre used to. There is a sample Quarto slide template in your repo you can edit to your heart‚Äôs desire to create your presentation. Roughly I recommend 1 slide for introduction, 2 slides for Question 1, ans 2 slides for Question 2. You can imagine spending roughly one minute on each slide. You should feel free to have more (or fewer) slides. Your evaluation will be based on your content, professionalism (including sticking to time), and your performance during the Q&A (question and answer). We don‚Äôt care how many slides you use to do this.\n\n\nWebsite\nEach of your projects will have a website that looks like https://vizdata-s23.github.io/project-01. You are not expected to change the styling of the website, but if you want to, you‚Äôll need to edit the _quarto.yml file in your repo. Feel free to google your way around it or ask on the discussion forum / office hours!"
  },
  {
    "objectID": "project/project-1.html#repo-organization",
    "href": "project/project-1.html#repo-organization",
    "title": "Project 1",
    "section": "Repo organization",
    "text": "Repo organization\nThe following folders and files in your project repository:\n\n/data/*: Your dataset\n\n/data/*.csv: Your dataset in CSV format\n/data/README.md: Metadata about your dataset including information on provenance, codebook, etc.1\n\nindex.qmd: Your project write-up\nproposal.qmd: Your project proposal\npresentation.qmd: Your project presentation\n_quarto.yml: Setup file for project website"
  },
  {
    "objectID": "project/project-1.html#grading",
    "href": "project/project-1.html#grading",
    "title": "Project 1",
    "section": "Grading",
    "text": "Grading\n\n\n\n\n\n\n\nTotal\n100 pts\n\n\n\n\nProposal2\n10 pts\n\n\nPresentation3\n30 pts\n(25 pts from teaching team, 5 pts from audience)\n\n\nWrite-up4\n30 pts\n\n\nReproducibility, style, and organization5\n10 pts\n\n\nWithin team peer evaluation6\n10 pts\n\n\nBetween team peer evaluation7\n10 pts\n\n\n\nSome of the components are further detailed below.\n\nProposal (10 points)\n\nData - Dataset is in the data folder, along with a codebook in the README of that folder. (3 points)\nWrite-up - All required components included. (5 points)\nWorkflow - Peer review issues closed via commits. (1 point)\nTeamwork - All team members must contribute to the repo via commits. (1 point)\n\n\n\nPresentation (30 points)\n\nTeaching team (25 points)\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time? (2 points)\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project? (2 points)\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together? (3 points)\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.? (3 points)\nCreativity Critical Thought: Is the project carefully thought out? Does it appear that time and effort went into the planning and implementation of the project? (3 points)\nContent: Both Question 1 and Question 2 will each be scored by the following criteria. Point values apply per part.\n\nIs the question well articulated in the presentation? (1 point)\nCan the question be answered with the data? (1 point)\nDo(es) the data visualization(s) answer the question? (1 point)\nDo(es) the data visualization(s) follow good visualization practices? (1 point)\nIs/are the conclusion(s) made based on the visualization(s) justifiable? (1 point)\nAre the limitations carefully considered and articulated? (1 point)\n\n\n\n\nPeers (5 points)\n\nContent: Is the research question well designed and is the data being used relevant to the research question? (1 point)\nContent: Did the team use appropriate visualizations and did they interpret them accurately? (1 point)\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project? (1 point)\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.? (1 point)\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Are they reading off of a script? Did everyone get a chance to say something meaningful about the project? (1 point)\n\n\n\n\nWrite-up (30 points)\n\nIntroduction: The introduction provides a clear explanation of the question and the dataset used to answer the question, including a description of all relevant variables in the dataset. (2 points)\n\nBoth Question 1 and Question 2 will each be scored by the following criteria. Point values apply per part.\n\nJustification of approach: The chosen analysis approach and visualizations are clearly explained and justified. (3 points)\nCode: Code is correct, easy to read, properly formatted, and properly documented. (3 points)\nVisualization: The visualizations are appropriate, easy to read, and properly labeled. (4 points)\nDiscussion: Discussion of results is clear and correct, and it has some depth without begin excessively long. (4 points)\n\n\n\nReproducibility, style, and organization (10 points)\n\nAll required files are provided. Quarto files render without issues and reproduce the necessary outputs. (3 points)\nData is in the data folder, with a codebook in the README, and is loaded from this folder in presentation and writeup. (3 points)\nDocuments are well structured and easy to follow. No extraneous materials. (2 points)\nAll issues are closed, mostly with specific commits addressing them. (2 points)"
  },
  {
    "objectID": "project/project-1.html#guidelines",
    "href": "project/project-1.html#guidelines",
    "title": "Project 1",
    "section": "Guidelines",
    "text": "Guidelines\nPlease use the project repository that has been created for your team to complete your project. This means putting all of the content in the Quarto files provided, rendering them to obtain the output, and committing and pushing all files to your repository by the indicated deadlines. Your Quarto files (.qmd) and the resulting html files (.html) will be graded jointly, so they must be consistent (as in, don‚Äôt change the Quarto file without also updating the rendered document!).\nAll results presented must have corresponding code. If you do calculations by hand instead of using R and then report the results from the calculations, you will not receive credit for those calculations. Any answers/results given without the corresponding R code that generated the result will not be considered. For example, if you‚Äôre reporting the number of observations in your dataset, don‚Äôt just write the number manually, use inline R code to calculate the number. All code reported in your final project document should work properly. Please do not include any extraneous code or code which produces error messages. Code which produces certain warnings and messages is acceptable, as long as you understand what the warnings mean. In such cases you can add warning: false and message: false in the relevant R chunks. Warnings that signal lifecycle changes (e.g., a function is deprecated and there‚Äôs a newer/better function out there) should generally be addressed by updating your code, not just by hiding the warning."
  },
  {
    "objectID": "project/project-1.html#tips",
    "href": "project/project-1.html#tips",
    "title": "Project 1",
    "section": "Tips",
    "text": "Tips\n\nYou‚Äôre working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that‚Äôs fine! Commit and push often, and ask questions when stuck.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nSet aside time to work together and apart (physically).\nCode:\n\nIn your presentation your code should be hidden (echo: false) so that your slides are neat and easy to read. However your document should include all your code such that if I re-render your Quarto file I should be able to obtain the results you presented. Exception: If you want to highlight something specific about a piece of code, you‚Äôre welcomed to show that portion.\nIn your write-up your code should be visible.\n\nTeamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\nWhen you‚Äôre done, review the documents on GitHub to make sure you‚Äôre happy with the final state of your work. Then go get some rest!"
  },
  {
    "objectID": "project/project-2.html",
    "href": "project/project-2.html",
    "title": "Project 2",
    "section": "",
    "text": "Your task for this project is to create something related to data visualization.\nThis is intentionally vague ‚Äì part of the challenge is to design a project that showcases best your interests and strengths.\nOne requirement is that your project should feature some element that you had to learn on your own. This could be a package you use that we didn‚Äôt teach in class (e.g., a package for building 3D visualizations) or a workflow (e.g., making a package) or anything else. If you‚Äôre not sure if your ‚Äúnew‚Äù thing counts, just ask!"
  },
  {
    "objectID": "project/project-2.html#ideas",
    "href": "project/project-2.html#ideas",
    "title": "Project 2",
    "section": "Ideas",
    "text": "Ideas\nYour first task is to come up with a goal for your project. Here are a few ideas to help you get started thinking:\n\nBuild a Shiny app that that has an Instagram-like user interface for applying filters, except not filters but themes for ggplots.\nCreate an R package that provides functionality for a set of ggplot2 themes and/or color palettes.1\nBuild a generative art system.\nDo a deep dive into accessibility for data visualization and build a lesson plan for creating accessible visualizations with ggplot2, R Markdown, and generally within the R ecosystem.\nCreate an interactive and/or animated spatio-temporal visualization on a topic of interest to you, e.g., redistricting, COVID-19, voter suppression, etc.\nRecreate art pieces with ggplot2.\nMake a data visualization telling a story and convert it to an illustration, presenting both the computational and artistic piece side by side.\nBuild a dashboard.\nMore TBA‚Ä¶\n\nAnd, of course, your project can be a about visualizing a dataset of interest to you (similar to your first project). The only rule about this dataset is that it can‚Äôt be from TidyTuesday. Beyond that, it should be something truly of interest to your team, and a dataset that allows for a deep exploration.\nMost importantly, be prepared to brainstorm a bunch of ideas and discard them until you settle on a topic that everyone in the team is happy with and feels like a good choice for showcasing what you‚Äôve learned in the class and how you can use that to learn something new and implement for your project."
  },
  {
    "objectID": "project/project-2.html#workflow",
    "href": "project/project-2.html#workflow",
    "title": "Project 2",
    "section": "Workflow",
    "text": "Workflow\n\nWeek 1 of project (week of [TBA]): Pick a focus for your project.\nWeek 2 of project (week of [TBA]): Work on developing your project proposal and setting up the structure for your repository.\nWeek 3 of project (week of [TBA]): Finalize your project proposal.\nWeek 4 of project (week of [TBA]): Conduct peer review on project proposals, and optionally, submit in an updated version of your proposal.\nWeek 5 of project (week of [TBA]): Continue working on your project.\nWeek 6 of project (week of [TBA]): Continue working on your project.\nWeek 7 of project (week of [TBA]): Conduct another round of peer review."
  },
  {
    "objectID": "project/project-2.html#due-dates",
    "href": "project/project-2.html#due-dates",
    "title": "Project 2",
    "section": "Due dates",
    "text": "Due dates\n\nProposals for peer review: due [TBA] at 5pm.\nRevised proposals for instructor review: due [TBA] at 5pm.\nWrite-up and presentation: due [TBA] (scheduled final date)."
  },
  {
    "objectID": "project/project-2.html#deliverables",
    "href": "project/project-2.html#deliverables",
    "title": "Project 2",
    "section": "Deliverables",
    "text": "Deliverables\n\nProposal\nYour proposal should include:\n\nA one sentence description of your high-level goal (such as the ones listed under Ideas above.\nA one to two paragraph description of your goals, including your motivation. Depending on the focus of your project, the following might go in here.\n\nIf using particular dataset(s), a brief description of each dataset including the reason why you chose the particular dataset, its dataset, its dimensions and any other relevant metadata. (Make sure to load the data and use inline code for some of this information.)\nIf answering a particular research question, the question itself and the reason why you chose this question.\n\nA weekly ‚Äúplan of attack‚Äù outlining your steps to complete your project and including the team member(s) assigned to that task.\nThe final organization of your project repository. This means describing the project organization in your proposal as well as implementing that organization in your repo. Create any folders needed and place a README.md in each folder explaining what goes in there.\n\n\n\nPeer review\n\nReviewer tasks\nEach team will review the proposals of two other teams twice during the project. The peer reviews will be completed during the lab session on [TBA] and [TBA]. On those days teams will have access to the project repos of the two teams whose work they‚Äôre reviewing. The peer review assignments are as follows:\n[TBA]\nTeams will develop the review together, with discussion among all team members, but only one team member will submit it as an issue on the project repo. To do so, go to the Issues tab, click on the green New issue button on the top right, and then click on the green Get started button for the issue template titled Peer review.\nThis will start a new issue with a peer review form that you can fill out. Make sure to update the introductory paragraph with your team name and the names of the team members participating in the review. Then, answer each of the questions in the spaces provided underneath them. You‚Äôre expected to be thorough in your review, but this doesn‚Äôt necessarily require lengthy responses.\nRemember, your goal is to help the team whose project you‚Äôre reviewing. The team will not lose points because of issues you point out, as long as they address them before I review their work. You should be critical, but respectful in your review. Also remember that you will be evaluated on the quality of your review. So that‚Äôs an additional incentive to do a good job.\n\n\nReviewee tasks\nOnce you receive feedback from your peers, you should address them. You should do this by directly updating your proposal or making any other updates to your repo as needed. You can do these updates all in one commit or you can spread it across multiple commits. Regardless, in the last commit that addresses the peer review comments, you should use a keyword in your commit message that will close the peer review issues. These words are close, closes, closed, fix, fixes, fixed, resolve, resolves, and resolved and they need to be followed by the issue number (which you can find next to the issue title). So, your commit message can say something like ‚ÄúFinished updates based on peer review, fixes #1‚Äù.\n\n\n\nWrite-up\nYour have a lot more freedom in how you structure your write-up for this project compared to Project 1. This also comes with responsibility. You should make sure you have a clear introduction and a clear conclusion. You should also have other interim section headings that help the reader. Your write-up should be somewhere between 1000 and 2000 words. There is no expectation that you get close to the upper limit, anywhere in that range is fine as long as you have clearly explained yourself. The limits are provided to help you, not to set stresful expectations.\n\n\nPresentation\nYour presentation should generally follow the same structure as your write-up. Each team will have 5 minutes for their presentation, and each team member must speak (roughly equally) during this time.\nYou should create your presentation in a reproducible way, e.g., using Quarto. However you don‚Äôt have to use a package that is designed specifically for slides. If you prefer to build a dashboard or a Shiny app or a website, that‚Äôs fine too. The only rule is that it‚Äôs built reproducibly using R.\nYour evaluation will be based on your content, professionalism (including sticking to time), and your performance during the Q&A (question and answer). We don‚Äôt care how many slides you use to do this.\n\n\nWebsite\nEach of your projects will have a website. You can use the same workflow as for your first project or create something different. For example, if your project is building a dashboard, you might consider making your write-up a tab on that dashboard. Or if it‚Äôs building a package, you might consider making your website using the pkgdown package. Feel free to google your way around it or ask in lab sessions, on the discussion forum, or office hours!"
  },
  {
    "objectID": "project/project-2.html#repo-organization",
    "href": "project/project-2.html#repo-organization",
    "title": "Project 2",
    "section": "Repo organization",
    "text": "Repo organization\nSince you have complete freedom on the focus of your project, you also have complete freedom on the organization of your repository. But‚Ä¶ it should be organized in a logical way!\nAt a minimum each project should have a README. This can be a README.md that you edit directly or a README.qmd that you edit and knit to README.md. If your project is analyzing a dataset, you‚Äôll probably want to structure your repo similar to your Project 1 repo. If you‚Äôre building a package, it should be structured like a package."
  },
  {
    "objectID": "project/project-2.html#grading",
    "href": "project/project-2.html#grading",
    "title": "Project 2",
    "section": "Grading",
    "text": "Grading\n\n\n\n\n\n\n\nTotal\n100 pts\n\n\n\n\nProposal2\n10 pts\n\n\nPresentation3\n30 pts\n(25 pts from teaching team, 5 pts from audience)\n\n\nWrite-up4\n30 pts\n\n\nReproducibility, style, and organization5\n10 pts\n\n\nWithin team peer evaluation6\n10 pts\n\n\nBetween team peer evaluation7\n10 pts\n\n\n\nSome of the components are further detailed below.\nNote that there will be points allocated to commits from each team member for the proposal, presentation, and write-up.\n\nProposal (10 points)\n\nHigh level goal\nExpanded description\nPlan\nRepo organization\nWorkflow - Peer review issues closed via commits. (1 point)\nTeamwork - All team members must contribute to the repo via commits. (1 point)\n\n\n\nPresentation (30 points)\n\nTeaching team (25 points)\n\nTime management: Did the team divide the time well among themselves or got cut off going over time? (2 points)\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project? (2 points)\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together? (3 points)\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.? (3 points)\nCreativity / Critical Thought: Is the project carefully thought out? Does it appear that time and effort went into the planning and implementation of the project? (5 points)\nContent: Including, but not limited to the following: (10 points)\n\nIs the question well articulated in the presentation?\nCan the question be answered with the data?\nDo(es) the data visualization(s) answer the question?\nDo(es) the data visualization(s) follow good visualization practices?\nIs/are the conclusion(s) made based on the visualization(s) justifiable?\nAre the limitations carefully considered and articulated?\n\n\n\n\nPeers (5 points)\n\nContent: Is the project well designed and is the data being used relevant to the focus of the project? (1 point)\nContent: Did the team use appropriate visualizations and did they interpret them accurately? (1 point)\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project? (1 point)\nSlides: Are the slides (or other presentation medium) well organized, readable, not full of text, featuring figures with legible labels, legends, etc.? (1 point)\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Are they reading off of a script? Did everyone get a chance to say something meaningful about the project? (1 point)\n\n\n\n\nWrite-up (30 points)\n\nIntroduction: The introduction provides a clear explanation of the question and the dataset used to answer the question, including a description of all relevant variables in the dataset. (3 points)\nJustification of approach: The chosen approach and visualizations are clearly explained and justified. (3 points)\nCode: Code is correct, easy to read, properly formatted, and properly documented. (10 points)\nVisualization: The visualizations are appropriate, easy to read, and properly labeled. (10 points)\nDiscussion: Discussion of results is clear and correct, and it has some depth without begin excessively long. (4 points)\n\n\n\nReproducibility, style, and organization (10 points)\n\nAll required files are provided. R Markdown files knit without issues and reproduce the necessary outputs. If building a package, the checks pass. (3 points)\nIf there‚Äôs a dataset, it‚Äôs provided in a data folder, a codebook is provided, and a local copy of the data file is used where needed. (3 points)\nDocuments are well structured and easy to follow. No extraneous materials. (2 points)\nAll issues are closed, mostly with specific commits addressing them. (2 points)"
  },
  {
    "objectID": "project/project-2.html#guidelines",
    "href": "project/project-2.html#guidelines",
    "title": "Project 2",
    "section": "Guidelines",
    "text": "Guidelines\nPlease use the project repository that has been created for your team to complete your project. Everything should be done reproducibly. This means that I should be able to clone your repo and reproduce everything you‚Äôve submitted as part of your project.\nAll results presented must have corresponding code. If you do calculations by hand instead of using R and then report the results from the calculations, you will not receive credit for those calculations. Any answers/results given without the corresponding R code that generated the result will not be considered. For example, if you‚Äôre reporting the number of observations in your dataset, don‚Äôt just write the number manually, use inline R code to calculate the number. All code reported in your final project document should work properly. Please do not include any extraneous code or code which produces error messages. Code which produces certain warnings and messages is acceptable, as long as you understand what the warnings mean. In such cases you can add warning = FALSE and message = FALSE in the relevant R chunks. Warnings that signal lifecycle changes (e.g., a function is deprecated and there‚Äôs a newer/better function out there) should generally be addressed by updating your code, not just by hiding the warning."
  },
  {
    "objectID": "project/project-2.html#tips",
    "href": "project/project-2.html#tips",
    "title": "Project 2",
    "section": "Tips",
    "text": "Tips\n\nWe hope some of you will take the challenge to be adventurous and learn some new skills as part of this project. We‚Äôre happy to support you along the way, so don‚Äôt hesitate to ask as many questions as needed!\nYou‚Äôre working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that‚Äôs fine! Commit and push often, and ask questions when stuck.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nSet aside time to work together and apart (physically).\nCode:\n\nIn your presentation your code should be hidden (echo = FALSE) so that your slides are neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented. Exception: If you want to highlight something specific about a piece of code, you‚Äôre welcomed to show that portion.\nIn your write-up your code should be visible.\n\nTeamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\nWhen you‚Äôre done, review the documents on GitHub to make sure you‚Äôre happy with the final state of your work. Then go get some rest!"
  },
  {
    "objectID": "project/project-tips-resources.html",
    "href": "project/project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "The project is very open ended. For instance, in creating a compelling visualization(s) of your data in R, there is no limit on what tools or packages you may use. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.\nBefore you finalize your write up, make sure the printing of code chunks is turned off with the option echo: false. In addition to code chunks, ensure all messages are turned off with the options warning: false and message: false.\nFinally, pay attention to details in your write-up and presentation. Neatness, coherency, and clarity will count."
  },
  {
    "objectID": "project/project-tips-resources.html#suppress-code-and-warnings",
    "href": "project/project-tips-resources.html#suppress-code-and-warnings",
    "title": "Project tips + resources",
    "section": "Suppress code and warnings",
    "text": "Suppress code and warnings\n\nInclude the following in the YAML of your report.qmd to suppress all code, warnings, and other messages.\n\nexecute:\n  echo: false\n  warning: false"
  },
  {
    "objectID": "project/project-tips-resources.html#headers",
    "href": "project/project-tips-resources.html#headers",
    "title": "Project tips + resources",
    "section": "Headers",
    "text": "Headers\nUse headers to clearly label each section. Make sure there is a space between the previous line and the header. Use appropriate header levels."
  },
  {
    "objectID": "project/project-tips-resources.html#references",
    "href": "project/project-tips-resources.html#references",
    "title": "Project tips + resources",
    "section": "References",
    "text": "References\nInclude all references in a section called ‚ÄúReferences‚Äù at the end of the report. This course does not have specific requirements for formatting citations and references. Optional: Use Quarto‚Äôs citation support for generating your reference. See Citations & Footnotes on the Quarto documentation for more on that."
  },
  {
    "objectID": "project/project-tips-resources.html#appendix",
    "href": "project/project-tips-resources.html#appendix",
    "title": "Project tips + resources",
    "section": "Appendix",
    "text": "Appendix\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called ‚ÄúAppendix‚Äù. The items in the appendix should be properly labeled. The appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix. We will not grade your appendix."
  },
  {
    "objectID": "project/project-tips-resources.html#resize-figures",
    "href": "project/project-tips-resources.html#resize-figures",
    "title": "Project tips + resources",
    "section": "Resize figures",
    "text": "Resize figures\nResize plots and figures, so you have more space for the narrative. Resize individual figures: Set fig-width and fig-height in chunk options, e.g.,\n#| echo: fenced\n#| label: plot1\n#| fig-height: 3\n#| fig-width: 5\nreplacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig-height and fig-width options in the YAML header as shown below:\nexecute:\n  fig-height: 3\n  fig-width: 5\nReplace the height and width values with values appropriate for your write up."
  },
  {
    "objectID": "project/project-tips-resources.html#arranging-plots",
    "href": "project/project-tips-resources.html#arranging-plots",
    "title": "Project tips + resources",
    "section": "Arranging plots",
    "text": "Arranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you‚Äôre using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html",
    "href": "slides/00/00-welcome-grammar.html",
    "title": "Welcome to STA 313",
    "section": "",
    "text": "Dr.¬†Mine √áetinkaya-Rundel\nOld Chem 213\nmc301@duke.edu\n\n\n\n\n\nJackie Du - Head TA\nLorenzo Mauri - Lab 1 TA\nSam Rosen - Lab 2 TA\nEvan Dragich - Lecture TA\nHolly Cui - TA\n\n\n\n\n\n\n\n\n\n\n\nLectures (weekly)\n\nTuesdays, 12:00 - 1:15 pm - Old Chem 116\nThursdays, 12:00 - 1:15 pm - Old Chem 116\n\nLabs (weekly)\n\nLab 1: Wednesdays, 1:45 - 3:00 pm - Link Classroom 3\nLab 2: Wednesdays, 3:30 - 4:45 pm - Link Classroom 3\n\n\n\n\n\n\nWhat: the plot\n\nSpecific types of visualizations for a particular purpose (e.g., maps for spatial data, Sankey diagrams for proportions, etc.)\nTooling to produce them (e.g., specific R packages)\n\n\n\n\nHow: the process\n\nStart with a design (sketch + pseudo code)\nPre-process data (e.g., wrangle, reshape, join, etc.)\nMap data to aesthetics\nMake visual encoding decisions t(e.g., address accessibility concerns)\nPost-process for visual appeal and annotation\n\n\n\n\n\nWhy: the theory\n\nTie together ‚Äúhow‚Äù and ‚Äúwhat‚Äù through the grammar of graphics"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#show-and-tell",
    "href": "slides/00/00-welcome-grammar.html#show-and-tell",
    "title": "Welcome to STA 313",
    "section": "Show and tell",
    "text": "Show and tell\n\n\nForm a small group (2-4 people) with people sitting around you\nFirst, introduce yourselves to each other ‚Äì name (and proper pronunciation of name), year, major, where are you from, etc.\nStart with the bad graphs ‚Äì Share your examples of ‚Äúbad‚Äù graphs and why you think they‚Äôre bad.\nThen, share your good graphs ‚Äì Same deal, share your examples of ‚Äúgood‚Äù graphs and why you think they‚Äôre good.\nFinally, choose the one plot from your group that you think is most striking, either because it‚Äôs bad or because it‚Äôs good, and have one team member share the graph on #general in Slack."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#course-website",
    "href": "slides/00/00-welcome-grammar.html#course-website",
    "title": "Welcome to STA 313",
    "section": "Course website",
    "text": "Course website\n\nvizdata.org\n\n\naka ‚Äúthe one link to rule them all‚Äù"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#lectures",
    "href": "slides/00/00-welcome-grammar.html#lectures",
    "title": "Welcome to STA 313",
    "section": "Lectures",
    "text": "Lectures\n\nIn person\nAttendance is required (as long as you‚Äôre healthy!)\nA little bit of everything:\n\nTraditional lecture\nLive coding + demos\nShort exercises + solution discussion\n\nRecordings will be posted after class ‚Äì to be used for review + make-up if you can‚Äôt make it to class due to health reasons, they‚Äôre not an alternative to class attendance"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#labs",
    "href": "slides/00/00-welcome-grammar.html#labs",
    "title": "Welcome to STA 313",
    "section": "Labs",
    "text": "Labs\n\nAttendance is required (as long as you‚Äôre healthy!)\nOpportunity to work on course assignments with TA support\nOpportunity to work with teammates on projects"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#announcements",
    "href": "slides/00/00-welcome-grammar.html#announcements",
    "title": "Welcome to STA 313",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Sakai (Announcements tool) and sent via email, be sure to check both regularly\nI‚Äôll assume that you‚Äôve read an announcement by the next ‚Äúbusiness‚Äù day"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#diversity-and-inclusion",
    "href": "slides/00/00-welcome-grammar.html#diversity-and-inclusion",
    "title": "Welcome to STA 313",
    "section": "Diversity and inclusion",
    "text": "Diversity and inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know!\nPlease let me know your preferred pronouns.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#accessibility",
    "href": "slides/00/00-welcome-grammar.html#accessibility",
    "title": "Welcome to STA 313",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I‚Äôm always learning how to do this better. If any course component is not accessible to you in any way, please don‚Äôt hesitate to let me know."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#attendance-participation-5",
    "href": "slides/00/00-welcome-grammar.html#attendance-participation-5",
    "title": "Welcome to STA 313",
    "section": "Attendance + participation (5%)",
    "text": "Attendance + participation (5%)\n\nRequired throughout the semester in lecture and lab\nStudents who attend at least 80% of the lectures and participate regularly in lecture and/or other course venues (lab + Slack) will receive full credit for this portion of their grade\nParticipation in labs as well as on Slack will also count towards this component"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#reading-quizzes-10",
    "href": "slides/00/00-welcome-grammar.html#reading-quizzes-10",
    "title": "Welcome to STA 313",
    "section": "Reading quizzes (10%)",
    "text": "Reading quizzes (10%)\n\nOnline, individual\nCover reading that is due since the previous quiz and up to and including the deadline for the given quiz\nDue by 12 pm ET (beginning of class) on the indicated day on the course schedule\nLowest dropped"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#homework-assignments-45",
    "href": "slides/00/00-welcome-grammar.html#homework-assignments-45",
    "title": "Welcome to STA 313",
    "section": "Homework assignments (45%)",
    "text": "Homework assignments (45%)\n\nSubmitted on GitHub, individual\nSome lab sessions allocated to working on homework / getting feedback from TAs\nDue by 12 pm ET (beginning of class) on the indicated day on the course schedule\nLowest dropped"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#projects",
    "href": "slides/00/00-welcome-grammar.html#projects",
    "title": "Welcome to STA 313",
    "section": "Projects",
    "text": "Projects\n\nSubmitted on GitHub, team-based\nInterim deadlines, peer review on content, peer evaluation for team contribution\nSome lab sessions allocated to working on projects, doing peer review, getting feedback from TAs"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#teams",
    "href": "slides/00/00-welcome-grammar.html#teams",
    "title": "Welcome to STA 313",
    "section": "Teams",
    "text": "Teams\n\nTeam assignments\n\nIn class exercises and projects\nAssigned different teams for each project\nPeer evaluation during teamwork and after completion\n\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#project-1-15",
    "href": "slides/00/00-welcome-grammar.html#project-1-15",
    "title": "Welcome to STA 313",
    "section": "Project 1 (15%)",
    "text": "Project 1 (15%)\n\nSame/similar data, different results\nPresentation and write-up\nWrapped up before midterms grades are due"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#project-2-25",
    "href": "slides/00/00-welcome-grammar.html#project-2-25",
    "title": "Welcome to STA 313",
    "section": "Project 2 (25%)",
    "text": "Project 2 (25%)\n\nThe world is your oyster! (and more details TBA)\nNew team\nPresentation and write-up\nWrapped up on the final exam date"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#grading",
    "href": "slides/00/00-welcome-grammar.html#grading",
    "title": "Welcome to STA 313",
    "section": "Grading",
    "text": "Grading\nThis course is assessed 100% on your coursework (there is no exam). We will be assessing you based on the following assignments,\n\n\n\n\n\n\n\n\n\n\nAssignment\nType\nValue\nn\nDue\n\n\n\n\nAttendance + participation\nIndividual\n5%\n\n\n\n\nReading quizzes\nIndividual\n10%\n7\n~ Every other week\n\n\nHomeworks\nIndividual\n45%\n6\n~ Every other week\n\n\nProject 1\nTeam\n15%\n1\n~ Week 6 + earlier interim deadlines\n\n\nProject 2\nTeam\n25%\n1\n~ Finals week + earlier interim deadlines"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#community-participation",
    "href": "slides/00/00-welcome-grammar.html#community-participation",
    "title": "Welcome to STA 313",
    "section": "Community participation",
    "text": "Community participation\nThis is not required but highly recommended!\n\nTidyTuesday - New dataset every week for wrangling, visualizing, modeling\nI encourage you to participate, or at a minimum, browse others‚Äô contributions on Twitter or Mastodon with #TidyTuesday"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#covid-policies",
    "href": "slides/00/00-welcome-grammar.html#covid-policies",
    "title": "Welcome to STA 313",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask if the university requires\nStay home if you‚Äôre sick and follow guidance\nRead and follow university guidance"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#late-work-policy",
    "href": "slides/00/00-welcome-grammar.html#late-work-policy",
    "title": "Welcome to STA 313",
    "section": "Late work policy",
    "text": "Late work policy\n\nReading quizzes: Late submissions not accepted\nHomework assignments:\n\nLate, but same day (before midnight): -10% of available points\nLate, but next day: -20% of available points\nTwo days late or later: No credit, and we will not provide written feedback\n\nProject presentations: Late submissions not accepted\nProject write-ups:\n\nLate, but same day (before midnight): -10% of available points\nLate, but next day: -20% of available points\nTwo days late or later: No credit, and we will not provide written feedback\n\nPeer evaluation:\n\nLate submissions not accepted\nMust turn in peer evaluation if you want your own score from others"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#collaboration-policy",
    "href": "slides/00/00-welcome-grammar.html#collaboration-policy",
    "title": "Welcome to STA 313",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively (Projects)\nReading quizzes must be completed individually, you may not discuss answers with teammates, clarification questions should only be asked to myself and the TAs\nHomework assignments must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#sharing-reusing-code-policy",
    "href": "slides/00/00-welcome-grammar.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 313",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course‚Äôs policy is that you may make use of any online resources (e.g.¬†RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#academic-integrity",
    "href": "slides/00/00-welcome-grammar.html#academic-integrity",
    "title": "Welcome to STA 313",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#section-1",
    "href": "slides/00/00-welcome-grammar.html#section-1",
    "title": "Welcome to STA 313",
    "section": "",
    "text": "most importantly:\nask if you‚Äôre not sure if something violates a policy!"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#office-hours",
    "href": "slides/00/00-welcome-grammar.html#office-hours",
    "title": "Welcome to STA 313",
    "section": "Office hours",
    "text": "Office hours\n\nMine:\n\nWednesdays 8 - 9 pm - Zoom (E)\n\nExcept Wed, Feb 1\nAny other exceptions will be announced in class / by email\n\nBy appointment - Zoom or Old Chem 213\n\nTAs:\n\nJackie: Tuesdays 4 - 6 pm - Edge Project Room 2\nLorenzo: Mondays 5 - 7 pm - Old Chemistry 203b\nSam: Tuesdays 1:30 - 3:30 pm - Location TBA\nEvan: Mondays 10 am - 12 pm - Zoom (Link on Sakai > Zoom meetings)\nHolly: Mondays 1-3 pm - Zoom (Link on Sakai > Zoom meetings)\n\n+ lots more resources listed on the syllabus!"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#wellness",
    "href": "slides/00/00-welcome-grammar.html#wellness",
    "title": "Welcome to STA 313",
    "section": "Wellness",
    "text": "Wellness\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don‚Äôt hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you‚Äôre always welcome to talk to me. If I can‚Äôt help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#rstudio",
    "href": "slides/00/00-welcome-grammar.html#rstudio",
    "title": "Welcome to STA 313",
    "section": "RStudio",
    "text": "RStudio\n\nhttps://cmgr.oit.duke.edu/containers\n\n\nBrowser based RStudio instance(s) provided by Duke OIT\nRequires internet connection to access\nProvides consistency in hardware and software environments\nLocal R installations are fine but we will not guarantee support"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#github",
    "href": "slides/00/00-welcome-grammar.html#github",
    "title": "Welcome to STA 313",
    "section": "GitHub",
    "text": "GitHub\n\nhttps://github.com/vizdata-s23\n\n\nGitHub organization for the course\nAll of your work and your membership (enrollment) in the organization is private\nEach assignment is a private repo on GitHub, I distribute the assignments on GitHub and you submit them there\nFeedback on assignments is given as GitHub issues, scores recorded on Sakai Gradebook\n\n\nFill out the Getting to know you survey for collection of your account names, later this week you will be invited to the course organization."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#username-advice",
    "href": "slides/00/00-welcome-grammar.html#username-advice",
    "title": "Welcome to STA 313",
    "section": "Username advice",
    "text": "Username advice\n\nin case you don‚Äôt yet have a GitHub account‚Ä¶\n\nSome brief advice about selecting your account names (particularly for GitHub),\n\nIncorporate your actual name! People like to know who they‚Äôre dealing with and makes your username easier for people to guess or remember\nReuse your username from other contexts, e.g., Twitter or Slack\nPick a username you will be comfortable revealing to your future boss\nShorter is better than longer, but be as unique as possible\nMake it timeless. Avoid highlighting your current university, employer, or place of residence"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#slack",
    "href": "slides/00/00-welcome-grammar.html#slack",
    "title": "Welcome to STA 313",
    "section": "Slack",
    "text": "Slack\n\nOnline forum for asking and answering questions\nPrivate repo in the course organization\nYou will need to join the course organization for access\nAsk and answer questions related to course logistics, assignment, etc. here\nPersonal questions (e.g., extensions, illnesses, etc.) should be via email to me\nOnce you join, browse the channels to make sure you‚Äôre posting questions in the right channel, update your profile with your name, photo/avatar of you that matches your GitHub profile, and your pronouns\nUnfortunately Slack is not the best place to ask coding questions, but it‚Äôs a great place for real-time connection and collaboration\n\n\nDemo on Tuesday for asking good questions with proper code formatting."
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#before-the-weekend",
    "href": "slides/00/00-welcome-grammar.html#before-the-weekend",
    "title": "Welcome to STA 313",
    "section": "Before the weekend",
    "text": "Before the weekend\n\nCreate a GitHub account if you don‚Äôt have one\nRead the syllabus\nMake sure you can login in to RStudio and reserve a container for STA 313: cmgr.oit.duke.edu/containers\nComplete the Getting to know you survey on Sakai ‚Äì to be posted\nComplete the readings and Reading Quiz 1 ‚Äì to be posted"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#data-visualization",
    "href": "slides/00/00-welcome-grammar.html#data-visualization",
    "title": "Welcome to STA 313",
    "section": "Data visualization",
    "text": "Data visualization\n\n‚ÄúThe simple graph has brought more information to the data analyst‚Äôs mind than any other device.‚Äù --- John Tukey\n\n\nData visualization is the creation and study of the visual representation of data\nMany tools for visualizing data -- R is one of them\nMany approaches/systems within R for making data visualizations -- ggplot2 is one of them, and that‚Äôs what we‚Äôre going to use"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#ggplot2-tidyverse",
    "href": "slides/00/00-welcome-grammar.html#ggplot2-tidyverse",
    "title": "Welcome to STA 313",
    "section": "ggplot2 ‚àà tidyverse",
    "text": "ggplot2 ‚àà tidyverse\n\n\n\n\n\n\n\n\n\nggplot2 is tidyverse‚Äôs data visualization package\ngg in ‚Äúggplot2‚Äù stands for Grammar of Graphics\nInspired by the book Grammar of Graphics by Leland Wilkinson"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#grammar-of-graphics-1",
    "href": "slides/00/00-welcome-grammar.html#grammar-of-graphics-1",
    "title": "Welcome to STA 313",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\n\n\nA grammar of graphics is a tool that enables us to concisely describe the components of a graphic\n\n\n\n\n\n\n\n\n\n\nSource: BloggoType"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#hello-ggplot2",
    "href": "slides/00/00-welcome-grammar.html#hello-ggplot2",
    "title": "Welcome to STA 313",
    "section": "Hello ggplot2!",
    "text": "Hello ggplot2!\n\nggplot() is the main function in ggplot2\nPlots are constructed in layers\nStructure of the code for plots can be summarized as\n\n\nggplot(data = [dataset], \n       mapping = aes(x = [x-variable], y = [y-variable])) +\n   geom_xxx() +\n   other options\n\n\nThe ggplot2 package comes with the tidyverse\n\n\nlibrary(tidyverse)\n\n\nFor help with ggplot2, see ggplot2.tidyverse.org"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#data-palmer-penguins",
    "href": "slides/00/00-welcome-grammar.html#data-palmer-penguins",
    "title": "Welcome to STA 313",
    "section": "Data: Palmer Penguins",
    "text": "Data: Palmer Penguins\nMeasurements for penguin species, island in Palmer Archipelago, size (flipper length, body mass, bill dimensions), and sex.\n\n\n\n\n\n\n\n\n\nlibrary(palmerpenguins)\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               <fct> male, female, female, NA, female, male, female, male‚Ä¶\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#goal",
    "href": "slides/00/00-welcome-grammar.html#goal",
    "title": "Welcome to STA 313",
    "section": "Goal",
    "text": "Goal\n\nPlotCode\n\n\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\nggplot(\n  penguins,\n  aes(x = bill_depth_mm, y = bill_length_mm, colour = species)\n) +\n  geom_point() +\n  labs(\n    title = \"Bill depth and length\",\n    subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n    colour = \"Species\"\n  )"
  },
  {
    "objectID": "slides/00/00-welcome-grammar.html#an-improved-goal",
    "href": "slides/00/00-welcome-grammar.html#an-improved-goal",
    "title": "Welcome to STA 313",
    "section": "An improved goal",
    "text": "An improved goal\n\nPlotCodeNarrative\n\n\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\nggplot(\n  penguins,\n  aes(x = bill_depth_mm,y = bill_length_mm,colour = species)) +\n  geom_point() +\n  labs(\n    title = \"Bill depth and length\",\n    subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n    colour = \"Species\",\n    caption = \"Source: Palmer Station LTER / palmerpenguins package\"\n  ) +\n  theme_minimal() +\n  ggthemes::scale_color_colorblind()\n\n\n\nStart with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis.\nRepresent each observation with a point and map species to the colour of each point.\nTitle the plot ‚ÄúBill depth and length‚Äù, add the subtitle ‚ÄúDimensions for Adelie, Chinstrap, and Gentoo Penguins‚Äù, label the x and y axes as ‚ÄúBill depth (mm)‚Äù and ‚ÄúBill length (mm)‚Äù, respectively, label the legend ‚ÄúSpecies‚Äù, and add a caption for the data source.\nFinally, use a discrete colour scale that is designed to be perceived by viewers with common forms of colour blindness."
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html",
    "href": "slides/01/01-layers-1.knit.html",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "",
    "text": "Office hours + locations finalized at vizdata.org/course-team.html.\nDon‚Äôt forget to complete the getting to know you survey by 8pm today at the latest!\nA note on readings for this week: Some of it is review so feel free to skim those parts.\n\n\n\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(openintro)\nlibrary(countdown)\n\n# set theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))\n\n# set width of code output\noptions(width = 65)\n\n# set figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 7,        # 7\" width\n  fig.asp = 0.618,      # the golden ratio\n  fig.retina = 3,       # dpi multiplier for displaying HTML output on retina\n  fig.align = \"center\", # center align figures\n  dpi = 300             # higher dpi, sharper image\n)"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#data-sale-prices-of-houses-in-duke-forest",
    "href": "slides/01/01-layers-1.knit.html#data-sale-prices-of-houses-in-duke-forest",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Data: Sale prices of houses in Duke Forest",
    "text": "Data: Sale prices of houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#openintroduke_forest",
    "href": "slides/01/01-layers-1.knit.html#openintroduke_forest",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "openintro::duke_forest",
    "text": "openintro::duke_forest\n\nlibrary(tidyverse)\nlibrary(openintro)\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    <chr> \"1 Learned Pl, Durham, NC 27705\", \"1616 Pine‚Ä¶\n$ price      <dbl> 1520000, 1030000, 420000, 680000, 428500, 45‚Ä¶\n$ bed        <dbl> 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4,‚Ä¶\n$ bath       <dbl> 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0,‚Ä¶\n$ area       <dbl> 6040, 4475, 1745, 2091, 1772, 1950, 3909, 28‚Ä¶\n$ type       <chr> \"Single Family\", \"Single Family\", \"Single Fa‚Ä¶\n$ year_built <dbl> 1972, 1969, 1959, 1961, 2020, 2014, 1968, 19‚Ä¶\n$ heating    <chr> \"Other, Gas\", \"Forced air, Gas\", \"Forced air‚Ä¶\n$ cooling    <fct> central, central, central, central, central,‚Ä¶\n$ parking    <chr> \"0 spaces\", \"Carport, Covered\", \"Garage - At‚Ä¶\n$ lot        <dbl> 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.‚Ä¶\n$ hoa        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ‚Ä¶\n$ url        <chr> \"https://www.zillow.com/homedetails/1-Learne‚Ä¶"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#a-simple-visualization",
    "href": "slides/01/01-layers-1.knit.html#a-simple-visualization",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "A simple visualization",
    "text": "A simple visualization\n\nCodePlot\n\n\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE, size = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2\n3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#new-variable-decade_built",
    "href": "slides/01/01-layers-1.knit.html#new-variable-decade_built",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "New variable: decade_built",
    "text": "New variable: decade_built\n\nduke_forest <- duke_forest |>\n  mutate(decade_built = (year_built %/% 10) * 10)\n\nduke_forest |>\n  select(year_built, decade_built)\n\n# A tibble: 98 √ó 2\n   year_built decade_built\n        <dbl>        <dbl>\n 1       1972         1970\n 2       1969         1960\n 3       1959         1950\n 4       1961         1960\n 5       2020         2020\n 6       2014         2010\n 7       1968         1960\n 8       1973         1970\n 9       1972         1970\n10       1964         1960\n# ‚Ä¶ with 88 more rows"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#new-variable-decade_built_cat",
    "href": "slides/01/01-layers-1.knit.html#new-variable-decade_built_cat",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "New variable: decade_built_cat",
    "text": "New variable: decade_built_cat\n\nduke_forest <- duke_forest |>\n  mutate(\n    decade_built_cat = case_when(\n      decade_built <= 1940 ~ \"1940 or before\",\n      decade_built >= 1990 ~ \"1990 or after\",\n      TRUE ~ as.character(decade_built)\n    )\n  )\n\nduke_forest |>\n  count(decade_built_cat)\n\n# A tibble: 6 √ó 2\n  decade_built_cat     n\n  <chr>            <int>\n1 1940 or before       8\n2 1950                26\n3 1960                32\n4 1970                11\n5 1980                13\n6 1990 or after        8"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#a-slightly-more-complex-visualization",
    "href": "slides/01/01-layers-1.knit.html#a-slightly-more-complex-visualization",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "A slightly more complex visualization",
    "text": "A slightly more complex visualization\n\nCodePlot\n\n\n\nggplot(\n  duke_forest,\n  aes(x = area, y = price, color = decade_built_cat)\n) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  geom_smooth(method = \"lm\", se = FALSE, size = 0.5, show.legend = FALSE) +\n  facet_wrap(~decade_built_cat) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    color = \"Decade built\",\n    title = \"Price and area of houses in Duke Forest\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#ab-testing-1",
    "href": "slides/01/01-layers-1.knit.html#ab-testing-1",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "A/B testing",
    "text": "A/B testing\n\nIn the next two slides, the same plots are created with different ‚Äúcosmetic‚Äù choices. Examine the plots two given (Plot A and Plot B), and indicate your preference by voting for one of them in the Vote tab."
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#test-1",
    "href": "slides/01/01-layers-1.knit.html#test-1",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Test 1",
    "text": "Test 1\n\nPlot APlot BVote\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#test-2",
    "href": "slides/01/01-layers-1.knit.html#test-2",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Test 2",
    "text": "Test 2\n\nPlot APlot BVote\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#bad-taste",
    "href": "slides/01/01-layers-1.knit.html#bad-taste",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Bad taste",
    "text": "Bad taste\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#data-to-ink-ratio",
    "href": "slides/01/01-layers-1.knit.html#data-to-ink-ratio",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Data-to-ink ratio",
    "text": "Data-to-ink ratio\nTufte strongly recommends maximizing the data-to-ink ratio this in the Visual Display of Quantitative Information (Tufte, 1983).\n\n\n\nGraphical excellence is the well-designed presentation of interesting data‚Äîa matter of substance, of statistics, and of design ‚Ä¶ [It] consists of complex ideas communicated with clarity, precision, and efficiency. ‚Ä¶ [It] is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space ‚Ä¶ [It] is nearly always multivariate ‚Ä¶ And graphical excellence requires telling the truth about the data. (Tufte, 1983, p.¬†51)."
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#section",
    "href": "slides/01/01-layers-1.knit.html#section",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "",
    "text": "Which of the plots has higher data-to-ink ratio?\n\n\nPlot APlot BVote"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#a-deeper-look",
    "href": "slides/01/01-layers-1.knit.html#a-deeper-look",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "A deeper look",
    "text": "A deeper look\n\nat the plotting code"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#summary-statistics",
    "href": "slides/01/01-layers-1.knit.html#summary-statistics",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nmean_area_decade <- duke_forest |>\n  group_by(decade_built_cat) |>\n  summarise(mean_area = mean(area))\n\nmean_area_decade\n\n# A tibble: 6 √ó 2\n  decade_built_cat mean_area\n  <chr>                <dbl>\n1 1940 or before       2072.\n2 1950                 2545.\n3 1960                 2873.\n4 1970                 3413.\n5 1980                 2889.\n6 1990 or after        2822."
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#barplot",
    "href": "slides/01/01-layers-1.knit.html#barplot",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Barplot",
    "text": "Barplot\n\nCodePlot\n\n\n\nggplot(\n  mean_area_decade,\n  aes(y = decade_built_cat, x = mean_area)\n) +\n  geom_col() +\n  labs(\n    x = \"Mean area (square feet)\", y = \"Decade built\",\n    title = \"Mean area of houses in Duke Forest, by decade built\"\n  )"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#scaterplot",
    "href": "slides/01/01-layers-1.knit.html#scaterplot",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Scaterplot",
    "text": "Scaterplot\n\nCodePlot\n\n\n\nggplot(\n  mean_area_decade,\n  aes(y = decade_built_cat, x = mean_area)\n) +\n  geom_point(size = 4) +\n  labs(\n    x = \"Mean area (square feet)\", y = \"Decade built\",\n    title = \"Mean area of houses in Duke Forest, by decade built\"\n  )"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#lollipop-chart-a-happy-medium",
    "href": "slides/01/01-layers-1.knit.html#lollipop-chart-a-happy-medium",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Lollipop chart ‚Äì a happy medium?",
    "text": "Lollipop chart ‚Äì a happy medium?"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#application-exercise",
    "href": "slides/01/01-layers-1.knit.html#application-exercise",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Application exercise",
    "text": "Application exercise\n\n\nGo to the course GitHub organization: https://github.com/vizdata-s23\nClone the repo called ae-01 and work on the exercise.\n\nNote: For today, this is not a personalized repo for you. The repo is public so everyone can clone it, but you won‚Äôt be able to push to it. Starting Thursday you‚Äôll start getting your personalized repos you can push to.\n\nOnce you‚Äôre done, share your code on Slack in #general.\nLabel your chunk(s) and pay attention to code style and formatting!\n\n\n\n\n\n‚àí+\n10:00"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#bad-data",
    "href": "slides/01/01-layers-1.knit.html#bad-data",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Bad data",
    "text": "Bad data\n\nOriginalImproved\n\n\n\n\n\n\n\n\n\n\n\n\nHealy, Data Visualization: A practical introduction. Chapter 1. Figures 1.8 and 1.9."
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#bad-perception",
    "href": "slides/01/01-layers-1.knit.html#bad-perception",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Bad perception",
    "text": "Bad perception\n\n\n\nHealy, Data Visualization: A practical introduction. Chapter 1. Figure 1.12."
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#a-second-look-lollipop-chart",
    "href": "slides/01/01-layers-1.knit.html#a-second-look-lollipop-chart",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "A second look: lollipop chart",
    "text": "A second look: lollipop chart\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(\n  mean_area_decade,\n  aes(y = decade_built_cat, x = mean_area)\n) +\n  geom_point(size = 4) +\n  geom_segment(aes(\n    x = 0, xend = mean_area,\n    y = decade_built_cat, yend = decade_built_cat\n  )) +\n  labs(\n    x = \"Mean area (square feet)\",\n    y = \"Decade built\",\n    title = \"Mean area of houses in Duke Forest, by decade built\"\n  )"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#activity-spot-the-differences",
    "href": "slides/01/01-layers-1.knit.html#activity-spot-the-differences",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Activity: Spot the differences |",
    "text": "Activity: Spot the differences |\n\nPlotCodeDiscussion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(\n  mean_area_decade,\n  aes(y = decade_built_cat, x = mean_area)\n) +\n  geom_point(size = 4) +\n  geom_segment(aes(\n    xend = 0,\n    yend = decade_built_cat\n  )) +\n  labs(\n    x = \"Mean area (square feet)\",\n    y = \"Decade built\",\n    title = \"Mean area of houses in Duke Forest, by decade built\"\n  )\n\n\n\nCan you spot the differences between the code here and the one provided in the previous slide? Are there any differences in the resulting plot? Work in a pair (or group) to answer.\n\n\n\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#global-vs.-layer-specific-aesthetics",
    "href": "slides/01/01-layers-1.knit.html#global-vs.-layer-specific-aesthetics",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Global vs.¬†layer-specific aesthetics",
    "text": "Global vs.¬†layer-specific aesthetics\n\nAesthetic mappings can be supplied in the initial ggplot() call, in individual layers, or in some combination of both.\nWithin each layer, you can add, override, or remove mappings.\nIf you only have one layer in the plot, the way you specify aesthetics doesn‚Äôt make any difference. However, the distinction is important when you start adding additional layers."
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#activity-spot-the-differences-i",
    "href": "slides/01/01-layers-1.knit.html#activity-spot-the-differences-i",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Activity: Spot the differences I|",
    "text": "Activity: Spot the differences I|\n\nDo you expect the following plots to be the same or different? If different, how? Discuss in a pair (or group) without running the code and sketch the resulting plots based on what you think the code will produce.\n\n\nPlotDiscussion\n\n\n\n# Plot A\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(aes(color = decade_built_cat))\n# Plot B\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(color = \"blue\")\n# Plot C\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(color = \"#a493ba\")\n\n\n\n\n\n\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/01/01-layers-1.knit.html#wrap-up",
    "href": "slides/01/01-layers-1.knit.html#wrap-up",
    "title": "Deep dive into ggplot2 layers - I",
    "section": "Wrap up",
    "text": "Wrap up\n\nThink back to all the plots you saw in the lecture, without flipping back through the slides. Which plot first comes to mind? Describe it in words."
  },
  {
    "objectID": "slides/02/02-layers-2.html",
    "href": "slides/02/02-layers-2.html",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "",
    "text": "Thank you for filling out the survey!\nAt this point everyone should be:\n\nOn Slack, in public channels for #general, #homework, #project-1, #project-2, #quizzes, and #random as well as in a private channel for their lab section.\nMake sure your profile photo/avatar and name matches between GitHub and Slack.\n\nHW 1 will be posted after class, due next Thursday.\n\nYou‚Äôll get to work on it in lab next Wednesday, but you should start it before then and go to lab with questions.\n\n\n\n\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(openintro)\nlibrary(countdown)\nlibrary(palmerpenguins)\nlibrary(ggrepel)\nlibrary(waffle)\nlibrary(scales)\n\n# set theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))\n\n# set width of code output\noptions(width = 65)\n\n# set figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 7,        # 7\" width\n  fig.asp = 0.618,      # the golden ratio\n  fig.retina = 3,       # dpi multiplier for displaying HTML output on retina\n  fig.align = \"center\", # center align figures\n  dpi = 300             # higher dpi, sharper image\n)\n\n\n\n\n\nduke_forest <- duke_forest |>\n  mutate(\n    decade_built = (year_built %/% 10) * 10,\n    decade_built_cat = case_when(\n      decade_built <= 1940 ~ \"1940 or before\",\n      decade_built >= 1990 ~ \"1990 or after\",\n      TRUE ~ as.character(decade_built)\n    )\n  )\n\nmean_area_decade <- duke_forest |>\n  group_by(decade_built_cat) |>\n  summarise(mean_area = mean(area))"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geoms-1",
    "href": "slides/02/02-layers-2.html#geoms-1",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Geoms",
    "text": "Geoms\n\nGeometric objects, or geoms for short, perform the actual rendering of the layer, controlling the type of plot that you create\nYou can think of them as ‚Äúthe geometric shape used to represent the data‚Äù"
  },
  {
    "objectID": "slides/02/02-layers-2.html#one-variable",
    "href": "slides/02/02-layers-2.html#one-variable",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "One variable",
    "text": "One variable\n\nDiscrete:\n\ngeom_bar(): display distribution of discrete variable.\n\nContinuous\n\ngeom_histogram(): bin and count continuous variable, display with bars\ngeom_density(): smoothed density estimate\ngeom_dotplot(): stack individual points into a dot plot\ngeom_freqpoly(): bin and count continuous variable, display with lines"
  },
  {
    "objectID": "slides/02/02-layers-2.html#aside",
    "href": "slides/02/02-layers-2.html#aside",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Aside",
    "text": "Aside\nAlways use ‚Äútypewriter text‚Äù (monospace font) when writing function names, and follow with (), e.g.,\n\ngeom_freqpoly()\nmean()\nlm()"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_dotplot",
    "href": "slides/02/02-layers-2.html#geom_dotplot",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_dotplot()",
    "text": "geom_dotplot()\n\nWhat does each point represent? How are their locations determined? What do the x and y axes represent?\n\n\nggplot(duke_forest, aes(x = price)) +\n  geom_dotplot(binwidth = 50000)"
  },
  {
    "objectID": "slides/02/02-layers-2.html#comparing-across-groups",
    "href": "slides/02/02-layers-2.html#comparing-across-groups",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Comparing across groups",
    "text": "Comparing across groups\n\nWhich of the following allows for easier comparison across groups?\n\n\nHistogramFrequency polygon\n\n\n\nggplot(duke_forest, aes(x = price, fill = decade_built_cat)) +\n  geom_histogram(binwidth = 100000)\n\n\n\n\n\n\n\n\n\n\n\nggplot(duke_forest, aes(x = price, color = decade_built_cat)) +\n  geom_freqpoly(binwidth = 100000, size = 1)"
  },
  {
    "objectID": "slides/02/02-layers-2.html#two-variables---both-continuous",
    "href": "slides/02/02-layers-2.html#two-variables---both-continuous",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Two variables - both continuous",
    "text": "Two variables - both continuous\n\ngeom_point(): scatterplot\ngeom_quantile(): smoothed quantile regression\ngeom_rug(): marginal rug plots\ngeom_smooth(): smoothed line of best fit\ngeom_text(): text labels"
  },
  {
    "objectID": "slides/02/02-layers-2.html#application-exercise---part-1",
    "href": "slides/02/02-layers-2.html#application-exercise---part-1",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Application exercise - Part 1",
    "text": "Application exercise - Part 1\n\n\nGo to the course GitHub organization: https://github.com/vizdata-s23\nClone the repo called ae-02-[YOUR-GITHUB-USERNAME] and work on the exercises for Part 1.\nOnce you‚Äôre done, share your plots on Slack in #general.\nLabel your chunk(s) and pay attention to code style and formatting!\n\n\n\n\n\n‚àí+\n10:00"
  },
  {
    "objectID": "slides/02/02-layers-2.html#two-variables---show-density",
    "href": "slides/02/02-layers-2.html#two-variables---show-density",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Two variables - show density",
    "text": "Two variables - show density\n\ngeom_bin2d(): bin into rectangles and count\ngeom_density2d(): smoothed 2d density estimate\ngeom_hex(): bin into hexagons and count"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_hex",
    "href": "slides/02/02-layers-2.html#geom_hex",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_hex()",
    "text": "geom_hex()\nNot very helpful for 98 observations:\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_hex()"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_hex-1",
    "href": "slides/02/02-layers-2.html#geom_hex-1",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_hex()",
    "text": "geom_hex()\nMore helpful for 53940 observations:\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_hex()"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_hex-and-warnings",
    "href": "slides/02/02-layers-2.html#geom_hex-and-warnings",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_hex() and warnings",
    "text": "geom_hex() and warnings\n\nRequires installing the hexbin package separately!\n\n\ninstall.packages(\"hexbin\")\n\n\nOtherwise you might see\n\n\nWarning: Computation failed in `stat_binhex()`"
  },
  {
    "objectID": "slides/02/02-layers-2.html#two-variables",
    "href": "slides/02/02-layers-2.html#two-variables",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Two variables",
    "text": "Two variables\n\nAt least one discrete\n\ngeom_count(): count number of point at distinct locations\ngeom_jitter(): randomly jitter overlapping points\n\nOne continuous, one discrete\n\ngeom_col(): a bar chart of pre-computed summaries\ngeom_boxplot(): boxplots\ngeom_violin(): show density of values in each group"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_jitter",
    "href": "slides/02/02-layers-2.html#geom_jitter",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_jitter()",
    "text": "geom_jitter()\n\nHow are the following three plots different?\n\n\nPlot APlot BPlot C\n\n\n\nggplot(duke_forest, aes(x = bed, y = price)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nggplot(duke_forest, aes(x = bed, y = price)) +\n  geom_jitter()\n\n\n\n\n\n\n\n\n\n\n\nggplot(duke_forest, aes(x = bed, y = price)) +\n  geom_jitter()"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_jitter-and-set.seed",
    "href": "slides/02/02-layers-2.html#geom_jitter-and-set.seed",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_jitter() and set.seed()",
    "text": "geom_jitter() and set.seed()\n\nPlot APlot B\n\n\n\nset.seed(1234)\n\nggplot(duke_forest, aes(x = bed, y = price)) +\n  geom_jitter()\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\nggplot(duke_forest, aes(x = bed, y = price)) +\n  geom_jitter()"
  },
  {
    "objectID": "slides/02/02-layers-2.html#two-variables-1",
    "href": "slides/02/02-layers-2.html#two-variables-1",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Two variables",
    "text": "Two variables\n\nOne time, one continuous\n\ngeom_area(): area plot\ngeom_line(): line plot\ngeom_step(): step plot\n\nDisplay uncertainty:\n\ngeom_crossbar(): vertical bar with center\ngeom_errorbar(): error bars\ngeom_linerange(): vertical line\ngeom_pointrange(): vertical line with center\n\nSpatial\n\ngeom_sf(): for map data (more on this later‚Ä¶)"
  },
  {
    "objectID": "slides/02/02-layers-2.html#average-price-per-year-built",
    "href": "slides/02/02-layers-2.html#average-price-per-year-built",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Average price per year built",
    "text": "Average price per year built\n\nmean_price_year <- duke_forest |>\n  group_by(year_built) |>\n  summarise(\n    n = n(),\n    mean_price = mean(price),\n    sd_price = sd(price)\n    )\n\nmean_price_year\n\n# A tibble: 44 √ó 4\n   year_built     n mean_price sd_price\n        <dbl> <int>      <dbl>    <dbl>\n 1       1923     1     285000      NA \n 2       1934     1     600000      NA \n 3       1938     1     265000      NA \n 4       1940     1     105000      NA \n 5       1941     2     432500   28284.\n 6       1945     2     525000  530330.\n 7       1951     2     567500  258094.\n 8       1952     2     531250  469165.\n 9       1953     2     575000   35355.\n10       1954     4     600000   33912.\n# ‚Ä¶ with 34 more rows"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_line",
    "href": "slides/02/02-layers-2.html#geom_line",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_line()",
    "text": "geom_line()\n\nggplot(mean_price_year, aes(x = year_built, y = mean_price)) +\n  geom_line()"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_area",
    "href": "slides/02/02-layers-2.html#geom_area",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_area()",
    "text": "geom_area()\n\nggplot(mean_price_year, aes(x = year_built, y = mean_price)) +\n  geom_area()"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_step",
    "href": "slides/02/02-layers-2.html#geom_step",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_step()",
    "text": "geom_step()\n\nggplot(mean_price_year, aes(x = year_built, y = mean_price)) +\n  geom_step()"
  },
  {
    "objectID": "slides/02/02-layers-2.html#application-exercise---part-2",
    "href": "slides/02/02-layers-2.html#application-exercise---part-2",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Application exercise - Part 2",
    "text": "Application exercise - Part 2\n\n\nGo to the course GitHub organization: https://github.com/vizdata-s23\nClone the repo called ae-02-[YOUR-GITHUB-USERNAME] and work on the exercises for Part 2.\nOnce you‚Äôre done, share your plot on Slack in #general.\nLabel your chunk(s) and pay attention to code style and formatting!\n\n\n\n\n\n‚àí+\n05:00"
  },
  {
    "objectID": "slides/02/02-layers-2.html#section",
    "href": "slides/02/02-layers-2.html#section",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "",
    "text": "let‚Äôs clean things up a bit!"
  },
  {
    "objectID": "slides/02/02-layers-2.html#lets-clean-things-up-a-bit",
    "href": "slides/02/02-layers-2.html#lets-clean-things-up-a-bit",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Let‚Äôs clean things up a bit!",
    "text": "Let‚Äôs clean things up a bit!\n\nCodePlot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.6, size = 2, color = \"#012169\") +\n  scale_x_continuous(labels = label_number(big.mark = \",\")) +\n  scale_y_continuous(labels = label_dollar(scale = 1/1000, suffix = \"K\")) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Sale prices of homes in Duke Forest\",\n    subtitle = \"As of November 2020\",\n    caption = \"Source: Zillow.com\"\n  )"
  },
  {
    "objectID": "slides/02/02-layers-2.html#three-variables",
    "href": "slides/02/02-layers-2.html#three-variables",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "Three variables",
    "text": "Three variables\n\ngeom_contour(): contours\ngeom_tile(): tile the plane with rectangles\ngeom_raster(): fast version of geom_tile() for equal sized tiles"
  },
  {
    "objectID": "slides/02/02-layers-2.html#geom_tile",
    "href": "slides/02/02-layers-2.html#geom_tile",
    "title": "Deep dive into ggplot2 layers - II",
    "section": "geom_tile()",
    "text": "geom_tile()\n\nggplot(duke_forest, aes(x = bed, y = bath)) +\n geom_tile(aes(fill = price))"
  },
  {
    "objectID": "slides/03/03-wrangle-1.html",
    "href": "slides/03/03-wrangle-1.html",
    "title": "Data wrangling - I",
    "section": "",
    "text": "HW 1 due Thursday at noon, make sure all checks are passing!\nSee #random on Slack for playlist request\nLab tomorrow: Come with questions on HW 1, particularly Questions 1-4. You‚Äôll have time to work on Question 5 especially in lab.\n\n\n\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(countdown)\n\n# set theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))\n\n# set width of code output\noptions(width = 65)\n\n# set figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 7,        # 7\" width\n  fig.asp = 0.618,      # the golden ratio\n  fig.retina = 3,       # dpi multiplier for displaying HTML output on retina\n  fig.align = \"center\", # center align figures\n  dpi = 300             # higher dpi, sharper image\n)"
  },
  {
    "objectID": "slides/03/03-wrangle-1.html#data-hotel-bookings",
    "href": "slides/03/03-wrangle-1.html#data-hotel-bookings",
    "title": "Data wrangling - I",
    "section": "Data: Hotel bookings",
    "text": "Data: Hotel bookings\n\nData from two hotels: one resort and one city hotel\nObservations: Each row represents a hotel booking\n\n\nhotels <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")"
  },
  {
    "objectID": "slides/03/03-wrangle-1.html#scenario-1",
    "href": "slides/03/03-wrangle-1.html#scenario-1",
    "title": "Data wrangling - I",
    "section": "Scenario 1",
    "text": "Scenario 1\n\nWe‚Ä¶\nhave a single data frame\nwant to slice it, and dice it, and juice it, and process it, so we can plot it"
  },
  {
    "objectID": "slides/03/03-wrangle-1.html#dplyr-101",
    "href": "slides/03/03-wrangle-1.html#dplyr-101",
    "title": "Data wrangling - I",
    "section": "dplyr 101",
    "text": "dplyr 101\n\nWhich of the following (if any) are unfamiliar to you?\n\n\ndistinct()\nselect(), relocate()\narrange(), arrange(desc())\nslice(), slice_head(), slice_tail(), slice_sample()\nfilter()\nmutate()\nsummarise(), count()"
  },
  {
    "objectID": "slides/03/03-wrangle-1.html#average-cost-of-daily-stay",
    "href": "slides/03/03-wrangle-1.html#average-cost-of-daily-stay",
    "title": "Data wrangling - I",
    "section": "Average cost of daily stay",
    "text": "Average cost of daily stay\n\nLet‚Äôs recreate this visualization!"
  },
  {
    "objectID": "slides/03/03-wrangle-1.html#livecoding",
    "href": "slides/03/03-wrangle-1.html#livecoding",
    "title": "Data wrangling - I",
    "section": "Livecoding",
    "text": "Livecoding\nReveal below for code developed during live coding session.\n\n\nCode\nhotels |>\n  mutate(\n    arrival_date = glue::glue(\"{arrival_date_year}-{arrival_date_month}-{arrival_date_day_of_month}\"),\n    arrival_date = ymd(arrival_date)\n    ) |>\n  group_by(hotel, arrival_date) |>\n  summarise(mean_adr = mean(adr), .groups = \"drop\") |>\n  ggplot(aes(x = arrival_date, y = mean_adr, group = hotel, color = hotel)) +\n  geom_line() +\n  scale_color_manual(values = c(\"cornsilk4\", \"deepskyblue3\")) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(\n    x = \"Arrival date\",\n    y = \"Mean average\\ndaily rate (USD)\",\n    color = NULL,\n    title = \"Cost of daily hotel stay\",\n    subtitle = \"July 2015 to August 2017\",\n    caption = \"Source: Antonio, Almeida and Nunes (2019) | TidyTuesday\"\n  ) +\n  theme(\n    legend.position = c(0.15, 0.9),\n    legend.box.background = element_rect(fill = \"white\",\n                                         color = \"white\"),\n    plot.subtitle = element_text(color = \"cornsilk4\"),\n    plot.caption = element_text(color = \"cornsilk4\")\n  )"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html",
    "href": "slides/04/04-wrangle-2.html",
    "title": "Data wrangling - II",
    "section": "",
    "text": "RQ2 due Tuesday:\n\nWill be posted tomorrow\nCovers everything since the previous quiz\n\n\n\n\n\n\n# load packages\nlibrary(countdown)\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(lubridate)\nlibrary(scales)\n\n# set theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))\n\n# set width of code output\noptions(width = 65)\n\n# set figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 7,        # 7\" width\n  fig.asp = 0.618,      # the golden ratio\n  fig.retina = 3,       # dpi multiplier for displaying HTML output on retina\n  fig.align = \"center\", # center align figures\n  dpi = 300             # higher dpi, sharper image\n)"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#data-hotel-bookings",
    "href": "slides/04/04-wrangle-2.html#data-hotel-bookings",
    "title": "Data wrangling - II",
    "section": "Data: Hotel bookings",
    "text": "Data: Hotel bookings\n\nData from two hotels: one resort and one city hotel\nObservations: Each row represents a hotel booking\n\n\nhotels <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#scenario-1",
    "href": "slides/04/04-wrangle-2.html#scenario-1",
    "title": "Data wrangling - II",
    "section": "Scenario 1",
    "text": "Scenario 1\n\nWe‚Ä¶\nhave a single data frame\nwant to slice it, and dice it, and juice it, and process it, so we can plot it"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#monthly-bookings",
    "href": "slides/04/04-wrangle-2.html#monthly-bookings",
    "title": "Data wrangling - II",
    "section": "Monthly bookings",
    "text": "Monthly bookings\n\nCome up with a plan for making the following visualization and write the pseudocode."
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#livecoding",
    "href": "slides/04/04-wrangle-2.html#livecoding",
    "title": "Data wrangling - II",
    "section": "Livecoding",
    "text": "Livecoding\nReveal below for code developed during live coding session.\n\n\nCode\nhotels <- hotels |>\n  mutate(\n    arrival_date_month = fct_relevel(arrival_date_month, month.name),\n    season = case_when(\n      arrival_date_month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      arrival_date_month %in% c(\"March\", \"April\", \"May\")           ~ \"Spring\",\n      arrival_date_month %in% c(\"June\", \"July\", \"August\")          ~ \"Summer\",\n      TRUE                                                         ~ \"Fall\"\n    ),\n    season = fct_relevel(season, \"Winter\", \"Spring\", \"Summer\", \"Fall\"),\n    season_emoji = case_when(\n      season == \"Winter\" ~ \"‚ùÑÔ∏è\",\n      season == \"Spring\" ~ \"‚õÖÔ∏èÔ∏è\",\n      season == \"Summer\" ~ \"‚òÄÔ∏è\",\n      season == \"Fall\"   ~ \"‚òÇÔ∏è\"\n    )\n  )\n\nhotels |>\n  count(season_emoji, hotel, arrival_date_month) |>\n  ggplot(aes(x = arrival_date_month, y = n, group = hotel, linetype = hotel)) +\n  geom_line(linewidth = 0.8, color = \"cornsilk4\") +\n  geom_text(aes(label = season_emoji), size = 6, show.legend = FALSE) +\n  scale_x_discrete(labels = month.abb) +\n  labs(\n    x = \"Arrival month\", y = \"Number of bookings\", linetype = NULL,\n    title = \"Number of monthly bookings\",\n    subtitle = \"July 2015 to August 2017\",\n    caption = \"Source: Antonio, Almeida and Nunes (2019) | TidyTuesday\"\n  ) +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    legend.position = c(0.12, 0.9),\n    legend.box.background = element_rect(fill = \"white\", color = \"white\"),\n    plot.subtitle = element_text(color = \"cornsilk4\"),\n    plot.caption = element_text(color = \"cornsilk4\")\n  )"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#a-few-takeaways",
    "href": "slides/04/04-wrangle-2.html#a-few-takeaways",
    "title": "Data wrangling - II",
    "section": "A few takeaways",
    "text": "A few takeaways\n\nforcats::fct_relevel() in a mutate() is useful for custom ordering of levels of a factor variable\nsummarize() after group_by() with multiple variables results in a message about the grouping structure of the resulting data frame ‚Äì the message can be supressed by defining .groups (e.g., .groups = \"drop\" or .groups = \"keep\")\nsummarize() also lets you get away with being sloppy and not naming your new column, but that‚Äôs not recommended!"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#rowwise-operations",
    "href": "slides/04/04-wrangle-2.html#rowwise-operations",
    "title": "Data wrangling - II",
    "section": "Rowwise operations",
    "text": "Rowwise operations\n\nWe want to calculate the total number of guests for each booking. Why does the following not work?\n\n\nhotels |>\n  select(adults, children, babies) |>\n  mutate(guests = sum(c(adults, children, babies)))\n\n# A tibble: 119,390 √ó 4\n   adults children babies guests\n    <dbl>    <dbl>  <dbl>  <dbl>\n 1      2        0      0     NA\n 2      2        0      0     NA\n 3      1        0      0     NA\n 4      1        0      0     NA\n 5      2        0      0     NA\n 6      2        0      0     NA\n 7      2        0      0     NA\n 8      2        0      0     NA\n 9      2        0      0     NA\n10      2        0      0     NA\n# ‚Ä¶ with 119,380 more rows"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#rowwise-operations-1",
    "href": "slides/04/04-wrangle-2.html#rowwise-operations-1",
    "title": "Data wrangling - II",
    "section": "Rowwise operations",
    "text": "Rowwise operations\n\nhotels |>\n  select(adults, children, babies) |>\n  rowwise() |> \n  mutate(guests = sum(c(adults, children, babies))) |>\n  filter(adults > 0, children > 0, babies > 0) # to show sum works\n\n# A tibble: 172 √ó 4\n# Rowwise: \n   adults children babies guests\n    <dbl>    <dbl>  <dbl>  <dbl>\n 1      2        1      1      4\n 2      2        1      1      4\n 3      2        1      1      4\n 4      2        1      1      4\n 5      2        1      1      4\n 6      2        1      1      4\n 7      2        1      1      4\n 8      2        2      1      5\n 9      2        2      1      5\n10      1        2      1      4\n# ‚Ä¶ with 162 more rows"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#columnwise-operations",
    "href": "slides/04/04-wrangle-2.html#columnwise-operations",
    "title": "Data wrangling - II",
    "section": "Columnwise operations",
    "text": "Columnwise operations\nUse across() combined with summarise() to calculate summary statistics for multiple columns at once:\n\nhotels |>\n  summarise(across(.cols = starts_with(\"stays\"),  mean))\n\n# A tibble: 1 √ó 2\n  stays_in_weekend_nights stays_in_week_nights\n                    <dbl>                <dbl>\n1                   0.928                 2.50\n\nhotels |>\n  summarise(across(.cols = starts_with(\"stays\"),  list(mean, sd)))\n\n# A tibble: 1 √ó 4\n  stays_in_weekend_nights_1 stays_in_weekend_ni‚Ä¶¬π stays‚Ä¶¬≤ stays‚Ä¶¬≥\n                      <dbl>                 <dbl>   <dbl>   <dbl>\n1                     0.928                 0.999    2.50    1.91\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãstays_in_weekend_nights_2,\n#   ¬≤‚Äãstays_in_week_nights_1, ¬≥‚Äãstays_in_week_nights_2"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#select-helpers",
    "href": "slides/04/04-wrangle-2.html#select-helpers",
    "title": "Data wrangling - II",
    "section": "Select helpers",
    "text": "Select helpers\n\nstarts_with(): Starts with a prefix\nends_with(): Ends with a suffix\ncontains(): Contains a literal string\nnum_range(): Matches a numerical range like x01, x02, x03\none_of(): Matches variable names in a character vector\neverything(): Matches all variables\nlast_col(): Select last variable, possibly with an offset\nmatches(): Matches a regular expression (a sequence of symbols/characters expressing a string/pattern to be searched for within text)\n\n\n\nSee help for any of these functions for more info, e.g.¬†?everything."
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#columnwise-operations-1",
    "href": "slides/04/04-wrangle-2.html#columnwise-operations-1",
    "title": "Data wrangling - II",
    "section": "Columnwise operations",
    "text": "Columnwise operations\n\nhotels |>\n  group_by(hotel, is_canceled) |>\n  summarise(\n    across(.cols = starts_with(\"stays\"),  list(mean = mean, sd = sd), .names = \"{.fn}_{.col}\") \n    )\n\n# A tibble: 4 √ó 6\n# Groups:   hotel [2]\n  hotel        is_canceled mean_stays_i‚Ä¶¬π sd_st‚Ä¶¬≤ mean_‚Ä¶¬≥ sd_st‚Ä¶‚Å¥\n  <chr>              <dbl>          <dbl>   <dbl>   <dbl>   <dbl>\n1 City Hotel             0          0.801   0.862    2.12    1.40\n2 City Hotel             1          0.788   0.917    2.27    1.53\n3 Resort Hotel           0          1.13    1.14     3.01    2.45\n4 Resort Hotel           1          1.34    1.14     3.44    2.46\n# ‚Ä¶ with abbreviated variable names\n#   ¬π‚Äãmean_stays_in_weekend_nights, ¬≤‚Äãsd_stays_in_weekend_nights,\n#   ¬≥‚Äãmean_stays_in_week_nights, ‚Å¥‚Äãsd_stays_in_week_nights"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#columnwise-operations-2",
    "href": "slides/04/04-wrangle-2.html#columnwise-operations-2",
    "title": "Data wrangling - II",
    "section": "Columnwise operations",
    "text": "Columnwise operations\n\nhotels |>\n  group_by(hotel, is_canceled) |>\n  summarise(\n    across(.cols = starts_with(\"stays\"),  list(mean = mean, sd = sd), .names = \"{.fn}_{.col}\"),\n    .groups = \"drop\"\n    )\n\n# A tibble: 4 √ó 6\n  hotel        is_canceled mean_stays_i‚Ä¶¬π sd_st‚Ä¶¬≤ mean_‚Ä¶¬≥ sd_st‚Ä¶‚Å¥\n  <chr>              <dbl>          <dbl>   <dbl>   <dbl>   <dbl>\n1 City Hotel             0          0.801   0.862    2.12    1.40\n2 City Hotel             1          0.788   0.917    2.27    1.53\n3 Resort Hotel           0          1.13    1.14     3.01    2.45\n4 Resort Hotel           1          1.34    1.14     3.44    2.46\n# ‚Ä¶ with abbreviated variable names\n#   ¬π‚Äãmean_stays_in_weekend_nights, ¬≤‚Äãsd_stays_in_weekend_nights,\n#   ¬≥‚Äãmean_stays_in_week_nights, ‚Å¥‚Äãsd_stays_in_week_nights"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#setup-for-next-example-hotel_summary",
    "href": "slides/04/04-wrangle-2.html#setup-for-next-example-hotel_summary",
    "title": "Data wrangling - II",
    "section": "Setup for next example: hotel_summary",
    "text": "Setup for next example: hotel_summary\n\nhotels_summary <- hotels |>\n  group_by(hotel, is_canceled) |>\n  summarise(\n    across(\n      .cols = starts_with(\"stays\"),\n      list(mean = mean),\n      .names = \"{.fn}_{.col}\"\n    ),\n    .groups = \"drop\"\n  )\n\nhotels_summary\n\n# A tibble: 4 √ó 4\n  hotel        is_canceled mean_stays_in_weekend_nights mean_st‚Ä¶¬π\n  <chr>              <dbl>                        <dbl>     <dbl>\n1 City Hotel             0                        0.801      2.12\n2 City Hotel             1                        0.788      2.27\n3 Resort Hotel           0                        1.13       3.01\n4 Resort Hotel           1                        1.34       3.44\n# ‚Ä¶ with abbreviated variable name ¬π‚Äãmean_stays_in_week_nights"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#section",
    "href": "slides/04/04-wrangle-2.html#section",
    "title": "Data wrangling - II",
    "section": "",
    "text": "Which variables are plotted in the following visualization? Which aesthetics are they mapped to? Recreate the visualization."
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#livecoding-1",
    "href": "slides/04/04-wrangle-2.html#livecoding-1",
    "title": "Data wrangling - II",
    "section": "Livecoding",
    "text": "Livecoding\nReveal below for code developed during live coding session.\n\n\nCode\nhotels_summary |>\n  mutate(is_canceled = if_else(is_canceled == 0, \"Not canceled\", \"Canceled\")) |>\n  pivot_longer(cols = starts_with(\"mean\"),\n               names_to = \"day_type\",\n               values_to = \"mean_stays\",\n               names_prefix = \"mean_stays_in_\") |>\n  mutate(\n    day_type = if_else(str_detect(day_type, \"weekend\"), \"Weekend\", \"Weekday\")\n    ) |>\n  ggplot(aes(x = str_wrap(is_canceled, 10), y = mean_stays, \n             group = hotel, color = hotel)) +\n  geom_point(show.legend = FALSE) +\n  geom_line(aes(linetype = hotel), linewidth = 1) +\n  facet_wrap(~day_type) +\n  labs(\n    x = \"Booking status\",\n    y = \"Mean number of\\nnights of stay\",\n    color = NULL, linetype = NULL,\n    title = \"Mean number of stays\",\n    subtitle = \"By hotel type and booking status\",\n    caption = \"Source: Antonio, Almeida and Nunes (2019) | TidyTuesday\"\n  ) +\n  scale_color_manual(values = c(\"cornsilk4\", \"deepskyblue3\")) +\n  scale_y_continuous(limits = c(0, 4), breaks = 0:4) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#pivot_wider-and-pivot_longer",
    "href": "slides/04/04-wrangle-2.html#pivot_wider-and-pivot_longer",
    "title": "Data wrangling - II",
    "section": "pivot_wider() and pivot_longer()",
    "text": "pivot_wider() and pivot_longer()\n\n\n\nFrom tidyr\nIncredibly useful for reshaping for plotting\nLots of extra arguments to help with reshaping pain!\nRefer to pivoting vignette when needed"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#stats-geoms",
    "href": "slides/04/04-wrangle-2.html#stats-geoms",
    "title": "Data wrangling - II",
    "section": "Stats < > geoms",
    "text": "Stats < > geoms\n\nStatistical transformation (stat) transforms the data, typically by summarizing\nMany of ggplot2‚Äôs stats are used behind the scenes to generate many important geoms\n\n\n\n\n\n\n\n\nstat\ngeom\n\n\n\n\nstat_bin()\ngeom_bar(), geom_freqpoly(), geom_histogram()\n\n\nstat_bin2d()\ngeom_bin2d()\n\n\nstat_bindot()\ngeom_dotplot()\n\n\nstat_binhex()\ngeom_hex()\n\n\nstat_boxplot()\ngeom_boxplot()\n\n\nstat_contour()\ngeom_contour()\n\n\nstat_quantile()\ngeom_quantile()\n\n\nstat_smooth()\ngeom_smooth()\n\n\nstat_sum()\ngeom_count()"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#layering-with-stats",
    "href": "slides/04/04-wrangle-2.html#layering-with-stats",
    "title": "Data wrangling - II",
    "section": "Layering with stats",
    "text": "Layering with stats\n\nhotels |>\n  filter(adr < 4000) |>\n  ggplot(aes(x = arrival_date_month, y = adr)) +\n  geom_point(alpha = 0.5) +\n  stat_summary(\n    geom = \"point\", fun = \"median\", \n    colour = \"red\", size = 5, pch = 4, stroke = 2\n  ) +\n  facet_wrap(~ hotel, ncol = 1)"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#alternate-layering-with-stats",
    "href": "slides/04/04-wrangle-2.html#alternate-layering-with-stats",
    "title": "Data wrangling - II",
    "section": "Alternate: layering with stats",
    "text": "Alternate: layering with stats\n\nhotels |>\n  filter(adr < 4000) |>\n  ggplot(aes(x = arrival_date_month, y = adr)) +\n  geom_point(alpha = 0.5) +\n  geom_point(\n    stat = \"summary\", fun = \"median\", \n    colour = \"red\", size = 5, pch = 4, stroke = 2\n  ) +\n  facet_wrap(~ hotel, ncol = 1)"
  },
  {
    "objectID": "slides/04/04-wrangle-2.html#statistical-transformations",
    "href": "slides/04/04-wrangle-2.html#statistical-transformations",
    "title": "Data wrangling - II",
    "section": "Statistical transformations",
    "text": "Statistical transformations\n\nWhat can you say about the distribution of price from the following QQ plot?\n\n\nhotels |>\n  filter(adr < 4000) |>\n  ggplot(aes(sample = adr)) +\n  stat_qq() +\n  stat_qq_line() +\n  labs(y = \"adr\")"
  },
  {
    "objectID": "slides/05/05-density-1.html",
    "href": "slides/05/05-density-1.html",
    "title": "Visualizing density - I",
    "section": "",
    "text": "Working with project teams in lab tomorrow!"
  },
  {
    "objectID": "slides/05/05-density-1.html#distributions",
    "href": "slides/05/05-density-1.html#distributions",
    "title": "Visualizing density - I",
    "section": "Distributions",
    "text": "Distributions\nThere are many properties of a distribution of values\n\nCenter: Mean, Median, Modes\nSpread: Variance, Range (Support), Interquartile range\nShape: Skewness, Kurtosis, Quantiles\nAny statistic you can think of\n\n\nUltimately when analyzing data, the distribution is important to know how to proceed:\n\nParametric tests\nErratic Data\nOutliers\n\nSo let‚Äôs visualize them!"
  },
  {
    "objectID": "slides/05/05-density-1.html#histograms",
    "href": "slides/05/05-density-1.html#histograms",
    "title": "Visualizing density - I",
    "section": "Histograms",
    "text": "Histograms\n\n\n\nHistogram of 200 random numbers generated from a \\(\\textsf{Normal}(\\mu=-1, \\sigma=0.5)\\) and 400 generated from a \\(\\textsf{Normal}(\\mu=2, \\sigma=0.75)\\):"
  },
  {
    "objectID": "slides/05/05-density-1.html#density-plots",
    "href": "slides/05/05-density-1.html#density-plots",
    "title": "Visualizing density - I",
    "section": "Density Plots",
    "text": "Density Plots\nWhat‚Äôs the difference? Histograms are counts of bins of observed data. Density plots are estimates of the unknown distribution."
  },
  {
    "objectID": "slides/05/05-density-1.html#so-what",
    "href": "slides/05/05-density-1.html#so-what",
    "title": "Visualizing density - I",
    "section": "So what?",
    "text": "So what?\n\n\nHistograms are sensitive to where the bins are cut\nHistograms vary more per random sample than density plots\nDensity graphs are estimates for what a very fine histogram with lots of data would show\n\n\n\n\n\nviewof binWidth = Inputs.range([0.01, 1.5], {value: 0.2, step: 0.001, label: \"Bin Width\"});\nviewof numPoints = Inputs.range([0, 9000], {value: 900, step: 1, label: \"Number of Points\"});\nviewof generate = Inputs.button(\"Regenerate Data\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport { plotNewData, regenerateData } from \"./histoSampling.js\";\n\n// Generate does not actually get used just forces a refresh\nplotNewData(regenerateData(numPoints / 3), binWidth, generate);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on example by Mike Bostock"
  },
  {
    "objectID": "slides/05/05-density-1.html#motivating-example",
    "href": "slides/05/05-density-1.html#motivating-example",
    "title": "Visualizing density - I",
    "section": "Motivating Example",
    "text": "Motivating Example\n\n\nBaseball! A home run in baseball occurs when a player hits a fair ball outside of the playing field. Examples:\n\n\n\n\n\n\n\n\n\nHome runs are exciting! Baseball currently has a marketing problem, but throughout history Major League Baseball (MLB, the organization running the highest level of professional baseball) has tried to change the rules to increase home runs to help the game be more entertaining.\n\nIn short terms, Home runs = Money, but if everyone hits the same number of home runs they become less exciting.\nExamining the distribution of home runs year-by-year we may be able to see the effect of rule changes."
  },
  {
    "objectID": "slides/05/05-density-1.html#data",
    "href": "slides/05/05-density-1.html#data",
    "title": "Visualizing density - I",
    "section": "Data",
    "text": "Data\n\n\nlibrary(Lahman)\nnames(Batting)\n\n [1] \"playerID\" \"yearID\"   \"stint\"    \"teamID\"   \"lgID\"     \"G\"       \n [7] \"AB\"       \"R\"        \"H\"        \"X2B\"      \"X3B\"      \"HR\"      \n[13] \"RBI\"      \"SB\"       \"CS\"       \"BB\"       \"SO\"       \"IBB\"     \n[19] \"HBP\"      \"SH\"       \"SF\"       \"GIDP\"    \n\n\nOur dataset comes from the R package Lahman. Each row in the data frame is the hitting stats of a player for a given year. We will mostly be using the following columns:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nyearID\nThe year for the statistics\n\n\nplayerID\nPlayer unique ID to distinguish rows\n\n\nHR\nThe number of home runs a player hit in a given year\n\n\nSB\nStolen bases; more stolen bases = faster player\n\n\nG\nNumber of games played; there are 162 games in a baseball season (154 before 1961)\n\n\nBB\nWalks; more walks = defense is worried about player hitting home runs\n\n\nSO\nStrike outs; more strikeouts = Hitter is swinging recklessly"
  },
  {
    "objectID": "slides/05/05-density-1.html#data-we-will-use",
    "href": "slides/05/05-density-1.html#data-we-will-use",
    "title": "Visualizing density - I",
    "section": "Data we will use",
    "text": "Data we will use\n\nhome_runs <- Batting\n\nWe are interested in the distribution of the number of home runs individual players have hit per year. 1"
  },
  {
    "objectID": "slides/05/05-density-1.html#context-1",
    "href": "slides/05/05-density-1.html#context-1",
    "title": "Visualizing density - I",
    "section": "Context 1",
    "text": "Context 1\nThere are many players in the dataset that played very little games per year, so we will limit to players that played at least 100 games in a given year, with the following years excepted:\n\nIn 1994 only about 115 games were played due to labor strikes, so will filter to at least 70 games.\nIn 2020 COVID shortened the season to only 60 games, so we will filter at least 40 games.\n\n\nhome_runs <- Batting |>\n  filter(\n    G >= 100 |\n    (G >= 40 & yearID == 2020) |\n    (G >= 70 & yearID == 1994)\n  )"
  },
  {
    "objectID": "slides/05/05-density-1.html#context-2",
    "href": "slides/05/05-density-1.html#context-2",
    "title": "Visualizing density - I",
    "section": "Context 2",
    "text": "Context 2\n\nWe are only concerned with years after 1920 (known as the ‚Äúlive-ball era‚Äù).\nVery few home runs were hit before 1920 as the same baseball was used for the entire game. About 100 baseballs are used every game today!\n\n\nhome_runs <- Batting |>\n  filter(\n    G >= 100 |\n    (G >= 40 & yearID == 2020) |\n    (G >= 70 & yearID == 1994),\n    yearID > 1920\n  )"
  },
  {
    "objectID": "slides/05/05-density-1.html#context-3",
    "href": "slides/05/05-density-1.html#context-3",
    "title": "Visualizing density - I",
    "section": "Context 3",
    "text": "Context 3\nWe are only considering the AL and NL leagues as they have the best stat-tracking and are the only Major leagues still around today.\n\nhome_runs <- Batting |>\n  filter(\n    G >= 100 |\n    (G >= 40 & yearID == 2020) |\n    (G >= 70 & yearID == 1994),\n    yearID > 1920,\n    lgID %in% c(\"AL\", \"NL\")\n  )"
  },
  {
    "objectID": "slides/05/05-density-1.html#density-graph-example",
    "href": "slides/05/05-density-1.html#density-graph-example",
    "title": "Visualizing density - I",
    "section": "Density Graph Example",
    "text": "Density Graph Example\n\nPlotCode\n\n\n\nggplot(home_runs, aes(HR)) +\n  geom_density() + \n  xlab(\"Home runs per player per year\")\n\n\n\n\n\n\n\n\n\n\nMost players hit just a few home runs per year and the distribution is very right-skewed.\nVery few players hit more than 40 per year."
  },
  {
    "objectID": "slides/05/05-density-1.html#stacked-density-graph-by-decade",
    "href": "slides/05/05-density-1.html#stacked-density-graph-by-decade",
    "title": "Visualizing density - I",
    "section": "Stacked Density Graph By Decade",
    "text": "Stacked Density Graph By Decade\n\nPlotCode\n\n\n\nhome_runs |>\n  mutate(\n    decade = cut(\n      yearID,\n      breaks = seq(1920, 2030, 10),\n      labels = paste0(seq(1920, 2020, 10), \"'s\")\n    )\n  ) |>\n  ggplot(aes(HR, fill = decade)) +\n  geom_density(position = \"stack\") +\n  labs(x = \"Home runs per player per year\")\n\n\n\n\n\n\n\n\n\nIf we stratify by decade, we can see the mode of the density graphs slowly creep forward, but it is difficult to see the tail of the distribution."
  },
  {
    "objectID": "slides/05/05-density-1.html#overlapping-density-graphs-by-decade",
    "href": "slides/05/05-density-1.html#overlapping-density-graphs-by-decade",
    "title": "Visualizing density - I",
    "section": "Overlapping Density Graphs By Decade",
    "text": "Overlapping Density Graphs By Decade\n\nPlotCode\n\n\n\nhome_runs |>\n  mutate(\n    decade = cut(\n      yearID,\n      breaks = seq(1920, 2030, 10),\n      labels = paste0(seq(1920, 2020, 10), \"'s\")\n    )\n  ) |>\n  ggplot(aes(HR, color = decade)) +\n  geom_density() +\n  labs(x = \"Home runs per player per year\")\n\n\n\n\n\n\n\n\n\nThe modes moving forward is a little more apparent now, but the graphs are too coupled to digest easily."
  },
  {
    "objectID": "slides/05/05-density-1.html#density-graph-with-conditional-probabilities",
    "href": "slides/05/05-density-1.html#density-graph-with-conditional-probabilities",
    "title": "Visualizing density - I",
    "section": "Density Graph with Conditional Probabilities",
    "text": "Density Graph with Conditional Probabilities\n\nPlotCode\n\n\n\nhome_runs |>\n  mutate(\n    decade = cut(\n      yearID,\n      breaks = seq(1920, 2030, 10),\n      labels = paste0(seq(1920, 2020, 10), \"'s\")\n    )\n  ) |>\n  ggplot(aes(x = HR, y = after_stat(count), fill = decade)) +\n  geom_density(position = \"fill\") +\n  geom_vline(xintercept = 60, linetype = \"dashed\") +\n  labs(x = \"Home runs per player per year\")\n\n\n\n\n\n\n\n\n\nBy using position = \"fill\" and y = after_stat(count) we graph the conditional probability of a decade given that a player has hit a certain number of home runs. We see that players would hit about 60 homeruns in the 20‚Äôs and 30‚Äôs, but that disappears until the 90‚Äôs and 2000‚Äôs. 2"
  },
  {
    "objectID": "slides/05/05-density-1.html#violin-plot",
    "href": "slides/05/05-density-1.html#violin-plot",
    "title": "Visualizing density - I",
    "section": "Violin Plot",
    "text": "Violin Plot\n\nPlotCode\n\n\n\nhome_runs |>\n  filter(yearID %in% 1985:2005) |>\n  ggplot(aes(HR, x = factor(yearID))) +\n  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +\n  geom_jitter(\n    data = ~ filter(.x, HR >= 30),\n    height = 0, width = 0.1, alpha = 0.5\n  ) +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  labs(x = \"Home runs per player per year\")\n\n\n\n\n\n\n\n\n\nLet‚Äôs examine the years near the change point, 1985 to 2005. All points shown are players that hit 30 or more home runs in a given year. It looks like around 1995 players started hitting a lot more home runs."
  },
  {
    "objectID": "slides/05/05-density-1.html#ridge-plot",
    "href": "slides/05/05-density-1.html#ridge-plot",
    "title": "Visualizing density - I",
    "section": "Ridge Plot",
    "text": "Ridge Plot\n\nPlotCode\n\n\n\nlibrary(ggridges)\n\nhome_runs |>\n  filter(yearID %in% 1985:2010) |>\n  ggplot(aes(x = HR, y = factor(yearID))) +\n  stat_density_ridges(\n    mapping = aes(fill = factor(after_stat(quantile))),\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = c(.25, .50, .75, .95),\n    quantile_lines = TRUE,\n    scale = 2,\n    rel_min_height = 0.01\n  ) +\n  scale_fill_viridis_d(\n    name = \"Quantiles\",\n    labels = c(\"0\", \"25th\", \"50th\", \"75th\", \"95th\")\n  ) +\n  geom_jitter(\n    data = ~ filter(.x, HR >= 30),\n    height = 0.2, width = 0, alpha = 0.3,\n  ) +\n  scale_x_continuous(\n    name = \"Home runs per player per year\",\n    limits = c(0, 73)\n  ) +\n  labs(y = \"Year\")\n\n\n\n\n\n\n\n\n\nThe quantiles also have a consistent increase, along with many more players hitting 30 or more home runs! In 1998 there was a home run record race between two players; this brought a lot of interest back into baseball. 1995 to about 2005 is known as the Steroid Era in baseball. During this time, players would take performance enhancing drugs freely as the league did not enforce the ban on them. League-wide testing began in 2003."
  },
  {
    "objectID": "slides/05/05-density-1.html#application-exercise-more-examples",
    "href": "slides/05/05-density-1.html#application-exercise-more-examples",
    "title": "Visualizing density - I",
    "section": "Application Exercise: More Examples",
    "text": "Application Exercise: More Examples\n\nGo to ae-05\nWork on Exercise 1\n\n\n\n\n‚àí+\n12:00"
  },
  {
    "objectID": "slides/05/05-density-1.html#bandwidth",
    "href": "slides/05/05-density-1.html#bandwidth",
    "title": "Visualizing density - I",
    "section": "Bandwidth",
    "text": "Bandwidth\nDensity graphs are sensitive to bandwidth, but this is a continuous degradation of performance.\n\n\nviewof binWidth2 = Inputs.range([0.01, 1.5], {value: 0.2, step: 0.001, label: \"Bin Width\"});\nviewof bandwidth = Inputs.range([0.01, 2], {value: 0.2, step: 0.001, label: \"Bandwidth\"});\nviewof numPoints2 = Inputs.range([0, 9000], {value: 900, step: 1, label: \"Number of Points\"});\nviewof generate2 = Inputs.button(\"Regenerate Data\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport { plotNewDataBW } from \"./bandwidthSampling.js\";\n\n// Generate does not actually get used just forces a refresh\nplotNewDataBW(regenerateData(numPoints2 / 3), binWidth2, bandwidth, generate2);"
  },
  {
    "objectID": "slides/05/05-density-1.html#automatic-bandwidth-selection",
    "href": "slides/05/05-density-1.html#automatic-bandwidth-selection",
    "title": "Visualizing density - I",
    "section": "Automatic Bandwidth Selection",
    "text": "Automatic Bandwidth Selection\n\n\nBecause change in bandwidth leads to a continuous change in the density estimate, it is often easier to automatically pick a bandwidth!\nSilverman‚Äôs ‚Äòrule-of-thumb‚Äô bw.nrd0 :\n\\[\n\\begin{align*}\n  h = 0.9 * n^{-1/5} \\min(s, IQR/1.34)\n\\end{align*}\n\\]\n\nOne of the most optimal bandwidth selectors if your data comes from a normal distribution\nDefault in ggplot2 and R\n\n\n\n\n\n\nSheather-Jones bw.SJ\n\nMore complicated bandwidth selector that ‚Äúwould rather fit‚Äù as the default\nLess likely to give over-smoothed density graphs\ngeom_density(bw = \"SJ\") to use\n\n\n\n\n\n\n\nOther methods\n\nScott‚Äôs plug in estimator bw.nrd: similar to Silverman‚Äôs\nbw.ucv and bw.bcv: cross validation based methods that are less useful for data visualization\nbw.SJ(<data>, method = \"dpi\"): An easier to calculate Sheather-Jones estimate that gives worse results"
  },
  {
    "objectID": "slides/05/05-density-1.html#sheather-jones-example",
    "href": "slides/05/05-density-1.html#sheather-jones-example",
    "title": "Visualizing density - I",
    "section": "Sheather-Jones Example",
    "text": "Sheather-Jones Example\n\nUsefulNot useful?"
  },
  {
    "objectID": "slides/05/05-density-1.html#kernel-density-estimates-advanced",
    "href": "slides/05/05-density-1.html#kernel-density-estimates-advanced",
    "title": "Visualizing density - I",
    "section": "Kernel Density Estimates (Advanced)",
    "text": "Kernel Density Estimates (Advanced)\n\nDensity graphs are illustrations of Kernel Density Estimates:\n\n\\[\n\\begin{align*}\n\\hat{f}_h(x) & = \\frac{1}{nh} \\sum_{i=1}^n K\\left(\\frac{x - x_i}{h}\\right)\n\\end{align*}\n\\]\n\n\\(x_i\\) is the \\(i^{th}\\) data point\n\\(h\\) is the bandwidth of the Kernel\n\\(K\\) is the Kernel\n\n\\(K\\) can be a number of functions (see kernel option from ?density or Wikipedia) but is usually the Gaussian kernel: \\(K(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)\\).\nChoice of \\(K\\) will give different looking density graphs, but choice of bandwidth is a lot more important than choice of Kernel. The Gaussian Kernel is by far the most used.\nTo see examples of Kernel choices, see this shiny app by Eduardo Garc√≠a-Portugu√©s.\n\n\n\nTo learn more, see Chapter 2 of Nonparametric Statistics by Eduardo Garc√≠a-Portugu√©s."
  },
  {
    "objectID": "slides/05/05-density-1.html#application-exercise-bandwidth",
    "href": "slides/05/05-density-1.html#application-exercise-bandwidth",
    "title": "Visualizing density - I",
    "section": "Application Exercise: Bandwidth",
    "text": "Application Exercise: Bandwidth\n\nGo to ae-05\nWork on Exercise 2\n\n\n\n\n‚àí+\n05:00"
  },
  {
    "objectID": "slides/05/05-density-1.html#cautions",
    "href": "slides/05/05-density-1.html#cautions",
    "title": "Visualizing density - I",
    "section": "Cautions",
    "text": "Cautions\n\nDensity Below 0Long Tailed Data\n\n\n\nlong_tailed_data <- tibble(random_values = rlnorm(1000, -3, 1))\n\n\n\n\nplot(\n  density(long_tailed_data$random_values, bw = \"SJ\"), \n  main = \"Density graph of positive numbers with density below 0\"\n) \nabline(v = 0, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nplot(\n  density(long_tailed_data$random_values, bw = \"SJ\", from = 0),\n  main = \"Density graph of positive numbers with cut density\"\n)\nabline(v = 0, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\n\nggplot2 generally handles this for you by putting bounds at the range of your data, but it can occasionally skip this depending on how complicated your graph becomes.\n\n\n\nlonger_tailed_data <- tibble(random_values = rlnorm(1000, -6, 5))\n\n\n\n\nggplot(longer_tailed_data, aes(x = random_values)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(longer_tailed_data, aes(x = random_values)) +\n  geom_density() +\n  scale_x_continuous(trans = \"log\")\n\n\n\n\n\n\n\n\n\n\nThis occurs in practice quite often!"
  },
  {
    "objectID": "slides/05/05-density-1.html#d-densityhistograms",
    "href": "slides/05/05-density-1.html#d-densityhistograms",
    "title": "Visualizing density - I",
    "section": "2D Density/Histograms",
    "text": "2D Density/Histograms\nPlayers that hit lots of home runs tend to strikeout and walk more.\n\nScatter plot2D Bins2D Density\n\n\n\nhome_runs |>\n  ggplot(aes(x = HR, y = SO + BB)) +\n  geom_jitter(width = 0.3, height = 0.3, alpha = 0.1) +\n  geom_density_2d(alpha = 0.5) +\n  labs(\n    x = \"Home runs per player per year\",\n    y = \"Strike outs and walks per player per year\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nhome_runs |>\n  ggplot(aes(x = HR, y = SO + BB)) +\n  geom_bin_2d(binwidth = c(2, 10)) +\n  geom_density_2d(alpha = 0.5) +\n  labs(\n    x = \"Home runs per player per year\",\n    y = \"Strike outs and walks per player per year\"\n  ) +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\n\n\nhome_runs |>\n  ggplot(aes(x = HR, y = SO + BB)) +\n  geom_density_2d_filled(show.legend = FALSE) +\n  geom_density_2d() +\n  labs(\n    x = \"Home runs per player per year\",\n    y = \"Strike outs and walks per player per year\"\n  )"
  },
  {
    "objectID": "slides/05/05-density-1.html#density-graphs-summary",
    "href": "slides/05/05-density-1.html#density-graphs-summary",
    "title": "Visualizing density - I",
    "section": "Density Graphs Summary",
    "text": "Density Graphs Summary\nPros:\n\nVisualize entire distribution\nMean, median, variance, outliers, support, skewness, normality etc.\nplot(density(Batting$HR)) is usually the first thing I do when analyzing data\n\n\nCons:\n\nSensitive to bandwidth choices\nHarder to communicate to non-statisticians\nDifficult to build yourself (use libraries!)"
  },
  {
    "objectID": "slides/06/06-density-2.html",
    "href": "slides/06/06-density-2.html",
    "title": "Visualizing density - II",
    "section": "",
    "text": "Make sure to review the feedback on your HW 01 repo and close the issue once you‚Äôre done reiewing.\nOnce you review, close the issue\nHW 02 won‚Äôt be graded for those who have open issues from the previously assigned homeework assignment."
  },
  {
    "objectID": "slides/06/06-density-2.html#distributions-and-motivating-example",
    "href": "slides/06/06-density-2.html#distributions-and-motivating-example",
    "title": "Visualizing density - II",
    "section": "Distributions and Motivating Example",
    "text": "Distributions and Motivating Example\n\n\nThere are many properties of a distribution of values\n\nCenter: Mean, Median, Modes\nSpread: Variance, Range (Support), Interquartile range\nShape: Skewness, Kurtosis, Quantiles\nAny statistic you can think of\n\nUltimately when analyzing data, the distribution is important to know how to proceed:\n\nParametric tests\nErratic Data\nOutliers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBaseball! A home run in baseball occurs when a player hits a fair ball outside of the playing field.\nBaseball is a game with a long rich history, but home runs have always been an integral part of it. By examining the distribution of home runs year-by-year we may be able to see the effect of various rule changes or events.\n\n\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "slides/06/06-density-2.html#data",
    "href": "slides/06/06-density-2.html#data",
    "title": "Visualizing density - II",
    "section": "Data",
    "text": "Data\n\n\nlibrary(Lahman)\n\nhome_runs <- Batting |> \n  filter(\n    G >= 100 | # We want to see how many home runs players that played most of the season hit\n    (G >= 40 & yearID == 2020) | # COVID-shortened season\n    (G >= 70 & yearID == 1994), # Strike-shortened season\n    yearID > 1920, # Beginning of live-ball era\n    lgID %in% c(\"AL\", \"NL\")\n  ) # Most common leagues\n\nOur dataset comes from the R package Lahman. Each row in the data frame is the hitting stats of a player for a given year. Today we will use the following columns:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nyearID\nThe year for the statistics\n\n\nHR\nThe number of home runs a player hit in a given year\n\n\nG\nNumber of games played; there are 162 games in a baseball season (154 before 1961)\n\n\n\nIn particular we are interested in the distribution of home runs per year!"
  },
  {
    "objectID": "slides/06/06-density-2.html#important-notes-from-last-time",
    "href": "slides/06/06-density-2.html#important-notes-from-last-time",
    "title": "Visualizing density - II",
    "section": "Important notes from last time",
    "text": "Important notes from last time\n\n\nAlthough density graphs are very useful and can display lots of information, they can be sensitive to bandwidth.\n\n\n\n\n\n\n\n\n\n\n\n\nIt was not clear how to properly determine if two distributions were significantly different."
  },
  {
    "objectID": "slides/06/06-density-2.html#cumulative-distribution-functions-cdf",
    "href": "slides/06/06-density-2.html#cumulative-distribution-functions-cdf",
    "title": "Visualizing density - II",
    "section": "Cumulative Distribution Functions (CDF)",
    "text": "Cumulative Distribution Functions (CDF)\n\n\nFor a random variable \\(X\\), the CDF describes the probability that \\(X\\) is below a certain value:\n\nBetween 0 and 1 (like all probabilities)\nNon-decreasing\nDerivative is the PDF, i.e.¬†the larger the PDF the faster the CDF is increasing.\nExample: If \\(X \\sim \\textsf{Normal}(0, 1)\\)\n\n\n\n\n\\[\n\\begin{align*}\n  F_X(x) & = P(X \\leq x) \\\\\n  F_x(-\\infty) & = 0 \\\\\n  F_x(-1) & = 0.1587 \\\\\n  F_x(0) & = 1/2 \\\\\n  F_x(1) & =  0.8413 \\\\\n  F_x(\\infty) & = 1\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/06/06-density-2.html#empirical-cdf-ecdf",
    "href": "slides/06/06-density-2.html#empirical-cdf-ecdf",
    "title": "Visualizing density - II",
    "section": "Empirical CDF (ECDF)",
    "text": "Empirical CDF (ECDF)\n\n\nThe empirical CDF of data is the proportion of data below a certain value:\n\nBetween 0 and 1 (like all probabilities)\nNon-decreasing\nIncreases at every value of observed data (step function)\nExample: X = c(0, 1, 2, 2, 3, 3.5, 4)\n\n\n\n\n\\[\n\\begin{align*}\n  F_n(t) & = \\frac{1}{n} \\sum_{i=1}^n \\begin{cases} 1 & x_i \\leq t \\\\ 0 & \\text{otherwise} \\end{cases} \\\\\n  F_7(-1) & = 0 \\\\\n  F_7(0) & = 1/7 \\\\\n  F_7(2.5) & = 4/7 \\\\\n  F_7(4) & = 1 \\\\\n  F_7(5) & = 1\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/06/06-density-2.html#empirical-cdfs-in-r",
    "href": "slides/06/06-density-2.html#empirical-cdfs-in-r",
    "title": "Visualizing density - II",
    "section": "Empirical CDFs in R",
    "text": "Empirical CDFs in R\n\nnew_example_data <- c(\n  rnorm(n = 200, mean = -1, sd = 0.5),\n  rnorm(n = 400, mean = 2, sd = 0.75)\n)\nmix_ecdf <- ecdf(new_example_data)\n\n\n\n\n\n\n\n \n  \n    Function Call \n    Probability less than value \n  \n \n\n  \n    mix_ecdf(-3) \n    0.0000 \n  \n  \n    mix_ecdf(-1) \n    0.1617 \n  \n  \n    mix_ecdf(0) \n    0.3367 \n  \n  \n    mix_ecdf(2) \n    0.6583 \n  \n  \n    mix_ecdf(5) \n    1.0000"
  },
  {
    "objectID": "slides/06/06-density-2.html#kolmogorov-smirnov-test-two-sample",
    "href": "slides/06/06-density-2.html#kolmogorov-smirnov-test-two-sample",
    "title": "Visualizing density - II",
    "section": "Kolmogorov-Smirnov Test (Two-sample)",
    "text": "Kolmogorov-Smirnov Test (Two-sample)\n\n\nTheorem: If two random quantities have equal CDF‚Äôs they have the exact same distribution.\nThe Kolmogorov-Smirnov Test finds the maximum difference between two empirical CDF‚Äôs and outputs a test statistic based on the sample sizes.\nThe test is best used with continuous data as it is approximate in the case of discrete data, but it is good enough for our purposes.\nConditions to perform the test (which we somewhat violate):\n\nValues must be i.i.d. within their respective distributions\nThe two distributions being tested must be independent"
  },
  {
    "objectID": "slides/06/06-density-2.html#comparing-distributions-1",
    "href": "slides/06/06-density-2.html#comparing-distributions-1",
    "title": "Visualizing density - II",
    "section": "Comparing Distributions 1",
    "text": "Comparing Distributions 1\n\nOutputCode\n\n\n\n\n\n# Closest 4 years\nHRearly2010s <- home_runs |> \n  filter(yearID %in% 2011:2014)\n\n# Years up to COVID season\nHRlate2010s <- home_runs |> \n  filter(yearID %in% 2016:2019) \n\nks.test(HRearly2010s$HR, HRlate2010s$HR)\n\n\n    Asymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  HRearly2010s$HR and HRlate2010s$HR\nD = 0.16691, p-value = 6.463e-12\nalternative hypothesis: two-sided\n\n\n\n\nget_ks_df <- function(dat1, dat2) {\n  # Make ECDF of each set of data\n  ecdf1 <- ecdf(dat1)\n  ecdf2 <- ecdf(dat2)\n  # Calculate the absolute difference between the 2 ECDFs on the support\n  grid_points <- seq(0, max(c(dat1, dat2)), length.out=1000)\n  differences <- abs(ecdf1(grid_points) - ecdf2(grid_points))\n  # Get the KS statistic and where it occurs\n  ks_stat <- max(differences)\n  first_max_location <- grid_points[which.max(differences)]\n  # Return tibble to help with plotting\n  tibble(\n    x = first_max_location,\n    xend = first_max_location,\n    y = ecdf1(first_max_location),\n    yend = ecdf2(first_max_location)\n  )\n}\n\nks_stat_2010s <- get_ks_df(HRearly2010s$HR, HRlate2010s$HR)\n\nggplot(rbind(HRearly2010s, HRlate2010s), aes(HR, color = factor(yearID < 2015))) +\n  stat_ecdf(geom = \"step\") +\n  geom_segment(\n    data = ks_stat_2010s,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend\n    ),\n    color = \"black\",\n    linetype = \"dashed\"\n  ) +\n  labs(\n    x = \"Homeruns per player per year\",\n    y = \"Empirical CDF\",\n    title = \"Empirical CDFs of player home runs per year in years 2011-2019 \",\n    subtitle = \"Dashed line is the Kolmogorov-Smirnov Statistic\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nMajor League Baseball was accused of replacing the standard baseballs with ‚Äújuiced‚Äù baseballs (easier to hit home runs) secretly in the middle of 2015. Is there credence to this claim?"
  },
  {
    "objectID": "slides/06/06-density-2.html#comparing-distributions-2",
    "href": "slides/06/06-density-2.html#comparing-distributions-2",
    "title": "Visualizing density - II",
    "section": "Comparing Distributions 2",
    "text": "Comparing Distributions 2\n\nOutputCode\n\n\n\n\n\nHR2005 <- home_runs |>\n  filter(yearID == 2005)\nHR2006 <- home_runs |> \n  filter(yearID == 2006)\n\nks.test(HR2005$HR, HR2006$HR)\n\n\n    Asymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  HR2005$HR and HR2006$HR\nD = 0.073827, p-value = 0.503\nalternative hypothesis: two-sided\n\n\n\n\nks_stat_0506 <- get_ks_df(HR2005$HR, HR2006$HR)\n\nggplot(rbind(HR2005, HR2006), aes(HR, color = factor(yearID))) +\n  stat_ecdf(geom = \"step\") +\n  geom_segment(\n    data = ks_stat_0506,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend\n    ),\n    color = \"black\",\n    linetype = \"dashed\"\n  ) +\n  labs(\n    x = \"Homeruns per player per year\",\n    y = \"Empirical CDF\",\n    title = \"Empirical CDFs of player home runs per year in years 2005 and 2006 \",\n    subtitle = \"Dashed line is the Kolmogorov-Smirnov Statistic\",\n    color = \"Year\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n2005 and 2006 are similar years in terms of home runs, so the Kolmogorov-Smirnov test does not reject."
  },
  {
    "objectID": "slides/06/06-density-2.html#application-exercise-comparing-distributions",
    "href": "slides/06/06-density-2.html#application-exercise-comparing-distributions",
    "title": "Visualizing density - II",
    "section": "Application Exercise: Comparing Distributions",
    "text": "Application Exercise: Comparing Distributions\n\nGo to ae-06\nWork on exercise 1\n\n\n\n\n‚àí+\n12:00"
  },
  {
    "objectID": "slides/06/06-density-2.html#using-the-kolmogorov-smirnov-statistic-for-visualization",
    "href": "slides/06/06-density-2.html#using-the-kolmogorov-smirnov-statistic-for-visualization",
    "title": "Visualizing density - II",
    "section": "Using the Kolmogorov-Smirnov statistic for visualization",
    "text": "Using the Kolmogorov-Smirnov statistic for visualization\n\nOur earlier motivation was to compare the distribution of homeruns over time to see if rule changes made a difference.\nWe can‚Äôt use a ridge or violin plot with all 100 years; it would be too cramped.\nWhat if we used the KS statistic to compare all pairs of years and emulated a correlation matrix?"
  },
  {
    "objectID": "slides/06/06-density-2.html#building-the-matrix",
    "href": "slides/06/06-density-2.html#building-the-matrix",
    "title": "Visualizing density - II",
    "section": "Building the Matrix",
    "text": "Building the Matrix\n\n\nks_matrix <- tribble(~year1, ~year2, ~ks_stat, ~p_value)\nall_years <- unique(home_runs$yearID)\n\n# Save some memory\nhome_runs_to_search <- home_runs |> select(yearID, HR)\n\noptions(warn = -1) # Turn off ks.test warning\n\nfor (year1 in all_years) {\n  year1HR <- home_runs_to_search |> filter(yearID == year1)\n  for (year2 in min(all_years):year1) { # Only do half since the test is symmetric\n    if (year1 == year2) {\n      next\n    }\n    year2HR <- home_runs_to_search |> filter(yearID == year2)\n\n    test <- ks.test(\n      year1HR$HR,\n      year2HR$HR\n    )\n\n    ks_matrix <- ks_matrix |>\n      add_row(\n        year1 = year1,\n        year2 = year2,\n        ks_stat = test$statistic,\n        p_value = test$p.value\n      )\n  }\n}\n\nks_matrix <- bind_rows(\n  ks_matrix,\n  ks_matrix |> mutate(\n    tmp_year1 = year1,\n    year1 = year2,\n    year2 = tmp_year1\n  ) |> select(-tmp_year1)\n)\n\noptions(warn = 0)"
  },
  {
    "objectID": "slides/06/06-density-2.html#visualizing-the-matrix-p-values",
    "href": "slides/06/06-density-2.html#visualizing-the-matrix-p-values",
    "title": "Visualizing density - II",
    "section": "Visualizing the Matrix (p-values)",
    "text": "Visualizing the Matrix (p-values)\n\nPlotCode\n\n\n\n\n\nks_matrix |>\n  mutate(signif = cut(\n    p_value,\n    breaks = c(0, 0.001, 0.01, 0.05, 0.1, 1.001),\n    labels = c(\"<0.001\", \"<0.01\", \"<0.05\", \"<0.1\", \"<1\"),\n    include.lowest = T,\n  )) |>\n  ggplot(aes(\n    x = year1,\n    y = year2,\n    fill = factor(signif)\n  )) +\n  geom_tile() +\n  scale_x_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_y_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_fill_manual(values = c(colorspace::heat_hcl(4), \"#AAAAAA\")) +\n  labs(\n    title = \"Unadjusted p-values matrix\",\n    fill = \"Significance\",\n    x = \"Year\",\n    y = \"Year\"\n  ) +\n  coord_fixed() +\n  annotate(\n    \"rect\",\n    xmin = c(2004.5, 2015.5),\n    ymin = c(2015.5, 2004.5),\n    xmax = c(2005.5, 2016.5),\n    ymax = c(2016.5, 2005.5),\n    color = \"#0000FFaa\",\n    alpha = 0,\n    size = 1\n  )\n\n\n\n\n\n\n\n\n\n\nHR2016 <- home_runs |> \n  filter(yearID == 2016)\n\nks.test(HR2005$HR, HR2016$HR)\n\n\n    Asymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  HR2005$HR and HR2016$HR\nD = 0.14405, p-value = 0.01089\nalternative hypothesis: two-sided\n\n\n\nThere seems to be some patterns in our matrix, but there‚Äôs a problem‚Ä¶"
  },
  {
    "objectID": "slides/06/06-density-2.html#multiple-testing",
    "href": "slides/06/06-density-2.html#multiple-testing",
    "title": "Visualizing density - II",
    "section": "Multiple Testing",
    "text": "Multiple Testing\n\n\nWhen performing multiple hypothesis tests, we typically want to control the Family Wise Error Rate: the probability we make at least 1 Type I error (a false rejection).\nNewer methods focus more on controlling the False Discovery Rate: the probability that any particular rejected null hypothesis is actually a false positive.\nBoth require adjusting p-values which is built in to R (?p.adjust).\n\nholm, hochberg and hommel control for Family Wise Error Rate\n\nbonferroni also controls for this, but is very conservative\n\nfdr and BY methods control for False Discovery Rate\n\n\n\n\n\n\n# Let's try all the adjustments and see how they change our visualization\nhalf_matrix <- ks_matrix |>\n  filter(year1 < year2) |>\n  mutate(\n    p_holm = p.adjust(p_value, \"holm\"),\n    p_hochberg = p.adjust(p_value, \"hochberg\"),\n    p_hommel = p.adjust(p_value, \"hommel\"),\n    p_bonferroni = p.adjust(p_value, \"bonferroni\"),\n    p_fdr = p.adjust(p_value, \"fdr\"),\n    p_BY = p.adjust(p_value, \"BY\")\n  )\n\nother_half <- half_matrix |>\n  mutate(\n    tmp_year1 = year1,\n    year1 = year2,\n    year2 = tmp_year1\n  ) |>\n  select(-tmp_year1)\n\nks_matrix <- bind_rows(half_matrix, other_half)"
  },
  {
    "objectID": "slides/06/06-density-2.html#visualizing-the-matrix-corrections",
    "href": "slides/06/06-density-2.html#visualizing-the-matrix-corrections",
    "title": "Visualizing density - II",
    "section": "Visualizing the Matrix (Corrections)",
    "text": "Visualizing the Matrix (Corrections)\n\nPlotCode\n\n\n\nks_matrix |>\n  pivot_longer(\n    c(\n      \"p_holm\",\n      \"p_hochberg\",\n      \"p_hommel\",\n      \"p_bonferroni\",\n      \"p_fdr\",\n      \"p_BY\"\n    ),\n    names_to = \"adjustment\",\n    values_to = \"adjusted_p\"\n  ) |>\n  mutate(signif = cut(\n    adjusted_p,\n    breaks = c(0, 0.001, 0.01, 0.05, 0.1, 1.001),\n    labels = c(\"<0.001\", \"<0.01\", \"<0.05\", \"<0.1\", \"<1\"),\n    include.lowest = T,\n  )) |>\n  ggplot(aes(\n    x = year1,\n    y = year2,\n    fill = factor(signif)\n  )) +\n  geom_tile() +\n  scale_x_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_y_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_fill_manual(values = c(colorspace::heat_hcl(4), \"#AAAAAA\")) +\n  labs(\n    x = \"Year\",\n    y = \"Year\",\n    fill = \"Significance\"\n  ) +\n  facet_wrap(~adjustment) +\n  coord_fixed() +\n  theme(\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )\n\n\n\n\n\n\n\n\nControlling for the Family Wise Error Rate got rid of a lot of our interesting patterns. We don‚Äôt mind some false positives so we choose the BY adjustment as it controls False Discovery Rate but is a bit more conservative than FDR."
  },
  {
    "objectID": "slides/06/06-density-2.html#pre-integration",
    "href": "slides/06/06-density-2.html#pre-integration",
    "title": "Visualizing density - II",
    "section": "Pre-Integration",
    "text": "Pre-Integration\n\nPlotCode\n\n\n\nmat_BY <-\n  ks_matrix |>\n  mutate(signif = cut(\n    p_BY,\n    breaks = c(0, 0.001, 0.01, 0.05, 0.1, 1.001),\n    labels = c(\"<0.001\", \"<0.01\", \"<0.05\", \"<0.1\", \"<1\"),\n    include.lowest = T,\n  )) |>\n  ggplot(aes(x = year1,\n             y = year2)) +\n  geom_tile(aes(fill = factor(signif))) +\n  scale_x_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_y_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_fill_manual(values = c(colorspace::heat_hcl(4), \"#AAAAAA\")) +\n  labs(title = \"BY adjusted p-values matrix\",\n       fill = \"Significance\",\n       x = \"Year\",\n       y = \"Year\") +\n  coord_fixed()\n\ndescription <- \"Major League Baseball was segregated by race until Jackie Robinson broke the color barrier in 1947.The talent level of the league changed rapidly, including the overall distribution of home runs.\" |> \n  str_wrap(width=40)\n\nmat_BY +\n  annotate(\n    \"rect\",\n    xmin = 1920,\n    ymin = 1920,\n    xmax = 1947,\n    ymax = 1947,\n    color = \"#0000FFaa\",\n    alpha = 0\n  ) +\n  annotate(\n    \"label\",\n    x = 1980,\n    y = 1980,\n    label = description,\n    alpha = 0.9,\n    size = 3\n  )"
  },
  {
    "objectID": "slides/06/06-density-2.html#world-war-ii",
    "href": "slides/06/06-density-2.html#world-war-ii",
    "title": "Visualizing density - II",
    "section": "World War II",
    "text": "World War II\n\nPlotCode\n\n\n\ndescription <-\n  \"During World War II, many baseball players fought overseas,making for an atypical number of home runs during these years.\" |> \n  str_wrap(width=40)\n\nmat_BY +\n  annotate(\n    \"rect\",\n    xmin = c(1920, 1941),\n    ymin = c(1941, 1920),\n    xmax = c(2022, 1945),\n    ymax = c(1945, 2022),\n    color = \"#0000FFaa\",\n    alpha = 0\n  ) +\n  annotate(\n    \"label\",\n    x = 1990,\n    y = 1990,\n    label = description,\n    alpha = 0.9,\n    size = 3\n  )"
  },
  {
    "objectID": "slides/06/06-density-2.html#shortened-seasons",
    "href": "slides/06/06-density-2.html#shortened-seasons",
    "title": "Visualizing density - II",
    "section": "Shortened Seasons",
    "text": "Shortened Seasons\n\nPlotCode\n\n\n\ndescription <-\n  \"In 1994 less homeruns were hit due to the strike-shorted season. Similarly, COVID in 2020 called for a shorter season.\" |>\n  str_wrap(width=40)\n\nmat_BY +\n  annotate(\n    \"rect\",\n    xmin = c(1920, 2019, 1920, 1993),\n    ymin = c(2019, 1920, 1993, 1920),\n    xmax = c(2022, 2021, 2022, 1995),\n    ymax = c(2021, 2022, 1995, 2022),\n    color = \"#0000FFaa\",\n    alpha = 0\n  ) +\n  annotate(\n    \"label\",\n    x = 1950,\n    y = 1950,\n    label = description,\n    alpha = 0.9,\n    size = 3\n  )"
  },
  {
    "objectID": "slides/06/06-density-2.html#year-of-the-pitcher",
    "href": "slides/06/06-density-2.html#year-of-the-pitcher",
    "title": "Visualizing density - II",
    "section": "Year of the Pitcher",
    "text": "Year of the Pitcher\n\nPlotCode\n\n\n\ndescription <-\n  \"1968 is known as the Year of the Pitcher, when pitchers dominated the league causing less homeruns. The next year, the pitcher's mound was made smaller to give \\npitchers a smaller advantage.\" |>\n  str_wrap(width = 30)\n\nmat_BY +\n  annotate(\n    \"rect\",\n    xmin = c(1920, 1967),\n    ymin = c(1967, 1920),\n    xmax = c(2022, 1969),\n    ymax = c(1969, 2022),\n    color = \"#0000FFaa\",\n    alpha = 0\n  ) +\n  annotate(\n    \"label\",\n    x = 2000,\n    y = 1950,\n    label = description,\n    alpha = 0.9,\n    size = 3\n  )"
  },
  {
    "objectID": "slides/06/06-density-2.html#application-exercise-follow-the-example",
    "href": "slides/06/06-density-2.html#application-exercise-follow-the-example",
    "title": "Visualizing density - II",
    "section": "Application exercise: Follow the example",
    "text": "Application exercise: Follow the example\n\nGo to ae-06\nWork on exercise 2\n\n\n\n\n‚àí+\n12:00"
  },
  {
    "objectID": "slides/06/06-density-2.html#summary",
    "href": "slides/06/06-density-2.html#summary",
    "title": "Visualizing density - II",
    "section": "Summary",
    "text": "Summary\n\nThe Empirical CDF is a very useful tool in statistics, for both analysis and visualization.\nThe Kolmogorov-Smirnov Test is a good way to test if two distributions of values are different.\n\nHowever, be careful as it is only an approximate test with discrete values.\nFurthermore, be sure to use multiple testing corrections if testing many different distributions.\n\nBaseball is interesting! (you may disagree on this one)"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html",
    "href": "slides/07/07-wrangle-3.html",
    "title": "Data wrangling - III",
    "section": "",
    "text": "Tomorrow in lab: Project proposal peer review\n\nYou‚Äôll be assessed on the quality (and participation) of your peer review\nUpdates based on peer review are due Friday at 5pm\nYour proposal will be ‚Äúgraded‚Äù after that, by me\n\nHW 2 is due Thursday\n\n\n\n\n\n# load packages\nlibrary(countdown)\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(ggthemes)\nlibrary(gt)\nlibrary(palmerpenguins)\nlibrary(openintro)\nlibrary(ggrepel)\n\n# set theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))\n\n# set width of code output\noptions(width = 65)\n\n# set figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 7,        # 7\" width\n  fig.asp = 0.618,      # the golden ratio\n  fig.retina = 3,       # dpi multiplier for displaying HTML output on retina\n  fig.align = \"center\", # center align figures\n  dpi = 300             # higher dpi, sharper image\n)"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#highlights",
    "href": "slides/07/07-wrangle-3.html#highlights",
    "title": "Data wrangling - III",
    "section": "Highlights",
    "text": "Highlights\n\nReview HW 1 issues, and show us you reviewed them by closing the issue.\nDO NOT hard code paths! Use the here package to help with relative paths, if you need."
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#checks",
    "href": "slides/07/07-wrangle-3.html#checks",
    "title": "Data wrangling - III",
    "section": "Checks",
    "text": "Checks\n\nGo to your HW 02 repo and make sure all your changes are committed. Then pull. You‚Äôll see there were some updates. Fix merge conflicts, if any. Then push. Check that your document renders."
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#warnings-and-messages",
    "href": "slides/07/07-wrangle-3.html#warnings-and-messages",
    "title": "Data wrangling - III",
    "section": "Warnings and messages",
    "text": "Warnings and messages\n\nYou should suppress package loading and data loading messages with message: false as a chunk option\nYou should also suppress warnings with warning: false after making sure you‚Äôre ok with them, or update your code to eliminate warnings"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#missing-values-i",
    "href": "slides/07/07-wrangle-3.html#missing-values-i",
    "title": "Data wrangling - III",
    "section": "Missing values I",
    "text": "Missing values I\n\n\n\nIs it ok to suppress the following warning? Or should you update your code to eliminate it?\n\n\ndf <- tibble(\n  x = c(1, 2, 3, NA, 3),\n  y = c(5, NA, 10, 0, 5)\n)\n\n\n\nggplot(df, aes(x = x, y = y)) +\n  geom_point(size = 3)\n\nWarning: Removed 2 rows containing missing values\n(`geom_point()`)."
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#missing-values-ii",
    "href": "slides/07/07-wrangle-3.html#missing-values-ii",
    "title": "Data wrangling - III",
    "section": "Missing values II",
    "text": "Missing values II\n\nset.seed(1234)\ndf <- tibble(x = rnorm(100))\n\n\n\n\np <- ggplot(df, aes(x = x)) +\n  geom_boxplot()\np\n\n\n\n\n\n\n\n\n\n\ndf |>\n  summarize(med_x = median(x))\n\n# A tibble: 1 √ó 1\n   med_x\n   <dbl>\n1 -0.385"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#missing-values-ii-1",
    "href": "slides/07/07-wrangle-3.html#missing-values-ii-1",
    "title": "Data wrangling - III",
    "section": "Missing values II",
    "text": "Missing values II\n\nIs it ok to suppress the following warning? Or should you update your code to eliminate it?\n\n\np + xlim(0, 2)\n\nWarning: Removed 69 rows containing non-finite values\n(`stat_boxplot()`)."
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#missing-values-ii-2",
    "href": "slides/07/07-wrangle-3.html#missing-values-ii-2",
    "title": "Data wrangling - III",
    "section": "Missing values II",
    "text": "Missing values II\n\nIs it ok to suppress the following warning? Or should you update your code to eliminate it?\n\n\np + scale_x_continuous(limits = c(0, 2))\n\nWarning: Removed 69 rows containing non-finite values\n(`stat_boxplot()`)."
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#missing-values-ii-3",
    "href": "slides/07/07-wrangle-3.html#missing-values-ii-3",
    "title": "Data wrangling - III",
    "section": "Missing values II",
    "text": "Missing values II\n\nWhy doesn‚Äôt the following generate a warning?\n\n\np + coord_cartesian(xlim = c(0, 2))"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#coordinate-systems-purpose",
    "href": "slides/07/07-wrangle-3.html#coordinate-systems-purpose",
    "title": "Data wrangling - III",
    "section": "Coordinate systems: purpose",
    "text": "Coordinate systems: purpose\n\nCombine the two position aesthetics (x and y) to produce a 2d position on the plot:\n\nlinear coordinate system: horizontal and vertical coordinates\npolar coordinate system: angle and radius\nmaps: latitude and longitude\n\nDraw axes and panel backgrounds in coordination with the faceter coordinate systems"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#coordinate-systems-types",
    "href": "slides/07/07-wrangle-3.html#coordinate-systems-types",
    "title": "Data wrangling - III",
    "section": "Coordinate systems: types",
    "text": "Coordinate systems: types\n\nLinear coordinate systems: preserve the shape of geoms\n\n\ncoord_cartesian(): the default Cartesian coordinate system, where the 2d position of an element is given by the combination of the x and y positions.\ncoord_fixed(): Cartesian coordinate system with a fixed aspect ratio. (useful only in limited circumstances)\n\n\n\nNon-linear coordinate systems: can change the shapes ‚Äì a straight line may no longer be straight. The closest distance between two points may no longer be a straight line.\n\n\ncoord_trans(): Apply arbitrary transformations to x and y positions, after the data has been processed by the stat\ncoord_polar(): Polar coordinates\ncoord_sf(): Map projections"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#setting-limits-what-the-plots-say",
    "href": "slides/07/07-wrangle-3.html#setting-limits-what-the-plots-say",
    "title": "Data wrangling - III",
    "section": "Setting limits: what the plots say",
    "text": "Setting limits: what the plots say\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + geom_smooth() +\n  labs(title = \"Plot 1\")\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + geom_smooth() +\n  scale_x_continuous(limits = c(190, 220)) + scale_y_continuous(limits = c(4000, 5000)) +\n  labs(title = \"Plot 2\")\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + geom_smooth() +\n  xlim(190, 220) + ylim(4000, 5000) +\n  labs(title = \"Plot 3\")\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + geom_smooth() +\n  coord_cartesian(xlim = c(190,220), ylim = c(4000, 5000)) +\n  labs(title = \"Plot 4\")"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#setting-limits-what-the-warnings-say",
    "href": "slides/07/07-wrangle-3.html#setting-limits-what-the-warnings-say",
    "title": "Data wrangling - III",
    "section": "Setting limits: what the warnings say",
    "text": "Setting limits: what the warnings say\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + geom_smooth() +\n  labs(title = \"Plot 1\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values\n(`geom_point()`).\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + geom_smooth() +\n  scale_x_continuous(limits = c(190, 220)) + scale_y_continuous(limits = c(4000, 5000)) +\n  labs(title = \"Plot 2\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 235 rows containing non-finite values\n(`stat_smooth()`).\n\n\nWarning: Removed 235 rows containing missing values\n(`geom_point()`).\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + geom_smooth() +\n  xlim(190, 220) + ylim(4000, 5000) +\n  labs(title = \"Plot 3\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 235 rows containing non-finite values (`stat_smooth()`).\nRemoved 235 rows containing missing values (`geom_point()`).\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + geom_smooth() +\n  coord_cartesian(xlim = c(190,220), ylim = c(4000, 5000)) +\n  labs(title = \"Plot 4\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values\n(`geom_point()`)."
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#setting-limits",
    "href": "slides/07/07-wrangle-3.html#setting-limits",
    "title": "Data wrangling - III",
    "section": "Setting limits",
    "text": "Setting limits\n\nSetting scale limits: Any data outside the limits is thrown away\n\nscale_*_continuous(), xlim and ylim arguments\nxlim() and ylim()\n\nSetting coordinate system limits: Use all the data, but only display a small region of the plot (zooming in)\n\ncoord_cartesian(), xlim and ylim arguments"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#fixing-aspect-ratio-with-coord_fixed",
    "href": "slides/07/07-wrangle-3.html#fixing-aspect-ratio-with-coord_fixed",
    "title": "Data wrangling - III",
    "section": "Fixing aspect ratio with coord_fixed()",
    "text": "Fixing aspect ratio with coord_fixed()\nUseful when having an aspect ratio of 1 makes sense, e.g.¬†scores on two tests (reading and writing) on the same scale (0 to 100 points)\n\nggplot(hsb2, aes(x = read, y = write)) +\n  geom_point() + geom_smooth(method = \"lm\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"gray\") +\n  labs(title = \"Not fixed\")\n\nggplot(hsb2, aes(x = read, y = write)) +\n  geom_point() + geom_smooth(method = \"lm\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"gray\") +\n  coord_fixed() +\n  labs(title = \"Fixed\")"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#pie-charts-and-bullseye-charts-with-coord_polar",
    "href": "slides/07/07-wrangle-3.html#pie-charts-and-bullseye-charts-with-coord_polar",
    "title": "Data wrangling - III",
    "section": "Pie charts and bullseye charts with coord_polar()",
    "text": "Pie charts and bullseye charts with coord_polar()\n\nggplot(penguins, aes(x = 1, fill = species)) +\n  geom_bar() +\n  labs(title = \"Stacked bar chart\")\n\nggplot(penguins, aes(x = 1, fill = species)) +\n  geom_bar() +\n  coord_polar(theta = \"y\") +\n  labs(title = \"Pie chart\")\n\nggplot(penguins, aes(x = 1, fill = species)) +\n  geom_bar() +\n  coord_polar(theta = \"x\") +\n  labs(title = \"Bullseye chart\")"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#section",
    "href": "slides/07/07-wrangle-3.html#section",
    "title": "Data wrangling - III",
    "section": "",
    "text": "aside: about pie charts‚Ä¶"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#pie-charts",
    "href": "slides/07/07-wrangle-3.html#pie-charts",
    "title": "Data wrangling - III",
    "section": "Pie charts",
    "text": "Pie charts\n\nWhat do you know about pie charts and data visualization best practices? Love ‚Äôem or lose ‚Äôem?"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#pie-charts-when-to-love-em-when-to-lose-em",
    "href": "slides/07/07-wrangle-3.html#pie-charts-when-to-love-em-when-to-lose-em",
    "title": "Data wrangling - III",
    "section": "Pie charts: when to love ‚Äôem, when to lose ‚Äôem",
    "text": "Pie charts: when to love ‚Äôem, when to lose ‚Äôem\nFor categorical variables with few levels, bar charts can work well\n\npie_homeownership\nloans %>%\n  ggplot(aes(x = homeownership, fill = homeownership)) +\n  geom_bar(show.legend = FALSE) +\n  scale_fill_openintro(\"hot\") +\n  labs(x = \"Homeownership\", y = \"Count\")"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#pie-charts-when-to-love-em-when-to-lose-em-1",
    "href": "slides/07/07-wrangle-3.html#pie-charts-when-to-love-em-when-to-lose-em-1",
    "title": "Data wrangling - III",
    "section": "Pie charts: when to love ‚Äôem, when to lose ‚Äôem",
    "text": "Pie charts: when to love ‚Äôem, when to lose ‚Äôem\nFor categorical variables with many levels, bar charts are difficult to read\n\npie_loan_grades\nloans |>\n  ggplot(aes(x = grade, fill = grade)) +\n  geom_bar(show.legend = FALSE) +\n  scale_fill_openintro(\"cool\") +\n  labs(x = \"Loan grade\", y = \"Count\")"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#scenario-2",
    "href": "slides/07/07-wrangle-3.html#scenario-2",
    "title": "Data wrangling - III",
    "section": "Scenario 2",
    "text": "Scenario 2\n\nWe‚Ä¶\nhave multiple data frames\nwant to want to bring them together so we can plot them\n\n\nprofessions <- read_csv(\"data/professions.csv\")\ndates <- read_csv(\"data/dates.csv\")\nworks <- read_csv(\"data/works.csv\")"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#women-in-science-who-changed-the-world",
    "href": "slides/07/07-wrangle-3.html#women-in-science-who-changed-the-world",
    "title": "Data wrangling - III",
    "section": "10 women in science who changed the world",
    "text": "10 women in science who changed the world\n\n\n\n\n\n\n  \n  \n    \n      name\n    \n  \n  \n    Ada Lovelace\n    Marie Curie\n    Janaki Ammal\n    Chien-Shiung Wu\n    Katherine Johnson\n    Rosalind Franklin\n    Vera Rubin\n    Gladys West\n    Flossie Wong-Staal\n    Jennifer Doudna\n  \n  \n  \n\n\n\n\n\n\nSource: Discover Magazine"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#inputs",
    "href": "slides/07/07-wrangle-3.html#inputs",
    "title": "Data wrangling - III",
    "section": "Inputs",
    "text": "Inputs\n\nprofessionsdatesworks\n\n\n\nprofessions\n\n# A tibble: 10 √ó 2\n   name               profession                        \n   <chr>              <chr>                             \n 1 Ada Lovelace       Mathematician                     \n 2 Marie Curie        Physicist and Chemist             \n 3 Janaki Ammal       Botanist                          \n 4 Chien-Shiung Wu    Physicist                         \n 5 Katherine Johnson  Mathematician                     \n 6 Rosalind Franklin  Chemist                           \n 7 Vera Rubin         Astronomer                        \n 8 Gladys West        Mathematician                     \n 9 Flossie Wong-Staal Virologist and Molecular Biologist\n10 Jennifer Doudna    Biochemist                        \n\n\n\n\n\ndates\n\n# A tibble: 8 √ó 3\n  name               birth_year death_year\n  <chr>                   <dbl>      <dbl>\n1 Janaki Ammal             1897       1984\n2 Chien-Shiung Wu          1912       1997\n3 Katherine Johnson        1918       2020\n4 Rosalind Franklin        1920       1958\n5 Vera Rubin               1928       2016\n6 Gladys West              1930         NA\n7 Flossie Wong-Staal       1947         NA\n8 Jennifer Doudna          1964         NA\n\n\n\n\n\nworks\n\n# A tibble: 9 √ó 2\n  name               known_for                                   \n  <chr>              <chr>                                       \n1 Ada Lovelace       first computer algorithm                    \n2 Marie Curie        theory of radioactivity,  first woman Nobel‚Ä¶\n3 Janaki Ammal       hybrid species, biodiversity protection     \n4 Chien-Shiung Wu    experiment overturning theory of parity     \n5 Katherine Johnson  orbital mechanics critical to sending first‚Ä¶\n6 Vera Rubin         existence of dark matter                    \n7 Gladys West        mathematical modeling of the shape of the E‚Ä¶\n8 Flossie Wong-Staal first to clone HIV and map its genes, which‚Ä¶\n9 Jennifer Doudna    one of the primary developers of CRISPR"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#desired-output",
    "href": "slides/07/07-wrangle-3.html#desired-output",
    "title": "Data wrangling - III",
    "section": "Desired output",
    "text": "Desired output\n\n\n# A tibble: 10 √ó 5\n   name               profession          birth‚Ä¶¬π death‚Ä¶¬≤ known‚Ä¶¬≥\n   <chr>              <chr>                 <dbl>   <dbl> <chr>  \n 1 Ada Lovelace       Mathematician            NA      NA first ‚Ä¶\n 2 Marie Curie        Physicist and Chem‚Ä¶      NA      NA theory‚Ä¶\n 3 Janaki Ammal       Botanist               1897    1984 hybrid‚Ä¶\n 4 Chien-Shiung Wu    Physicist              1912    1997 experi‚Ä¶\n 5 Katherine Johnson  Mathematician          1918    2020 orbita‚Ä¶\n 6 Rosalind Franklin  Chemist                1920    1958 <NA>   \n 7 Vera Rubin         Astronomer             1928    2016 existe‚Ä¶\n 8 Gladys West        Mathematician          1930      NA mathem‚Ä¶\n 9 Flossie Wong-Staal Virologist and Mol‚Ä¶    1947      NA first ‚Ä¶\n10 Jennifer Doudna    Biochemist             1964      NA one of‚Ä¶\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãbirth_year, ¬≤‚Äãdeath_year,\n#   ¬≥‚Äãknown_for"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#inputs-reminder",
    "href": "slides/07/07-wrangle-3.html#inputs-reminder",
    "title": "Data wrangling - III",
    "section": "Inputs, reminder",
    "text": "Inputs, reminder\n\n\n\nnames(professions)\n\n[1] \"name\"       \"profession\"\n\nnames(dates)\n\n[1] \"name\"       \"birth_year\" \"death_year\"\n\nnames(works)\n\n[1] \"name\"      \"known_for\"\n\n\n\n\nnrow(professions)\n\n[1] 10\n\nnrow(dates)\n\n[1] 8\n\nnrow(works)\n\n[1] 9"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#joining-data-frames",
    "href": "slides/07/07-wrangle-3.html#joining-data-frames",
    "title": "Data wrangling - III",
    "section": "Joining data frames",
    "text": "Joining data frames\n\nsomething_join(x, y)\n\n\nleft_join(): all rows from x\nright_join(): all rows from y\nfull_join(): all rows from both x and y\nsemi_join(): all rows from x where there are matching values in y, keeping just columns from x\ninner_join(): all rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches\nanti_join(): return all rows from x where there are not matching values in y, never duplicate rows of x\n‚Ä¶"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#setup-1",
    "href": "slides/07/07-wrangle-3.html#setup-1",
    "title": "Data wrangling - III",
    "section": "Setup",
    "text": "Setup\nFor the next few slides‚Ä¶\n\n\n\nx <- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n  )\n\nx\n\n# A tibble: 3 √ó 2\n     id value_x\n  <dbl> <chr>  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny <- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n  )\n\ny\n\n# A tibble: 3 √ó 2\n     id value_y\n  <dbl> <chr>  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#left_join",
    "href": "slides/07/07-wrangle-3.html#left_join",
    "title": "Data wrangling - III",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\nJoining, by = \"id\"\n\n\n# A tibble: 3 √ó 3\n     id value_x value_y\n  <dbl> <chr>   <chr>  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      <NA>"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#left_join-1",
    "href": "slides/07/07-wrangle-3.html#left_join-1",
    "title": "Data wrangling - III",
    "section": "left_join()",
    "text": "left_join()\n\nprofessions |>\n  left_join(dates)\n\nJoining, by = \"name\"\n\n\n# A tibble: 10 √ó 4\n   name               profession                  birth‚Ä¶¬π death‚Ä¶¬≤\n   <chr>              <chr>                         <dbl>   <dbl>\n 1 Ada Lovelace       Mathematician                    NA      NA\n 2 Marie Curie        Physicist and Chemist            NA      NA\n 3 Janaki Ammal       Botanist                       1897    1984\n 4 Chien-Shiung Wu    Physicist                      1912    1997\n 5 Katherine Johnson  Mathematician                  1918    2020\n 6 Rosalind Franklin  Chemist                        1920    1958\n 7 Vera Rubin         Astronomer                     1928    2016\n 8 Gladys West        Mathematician                  1930      NA\n 9 Flossie Wong-Staal Virologist and Molecular B‚Ä¶    1947      NA\n10 Jennifer Doudna    Biochemist                     1964      NA\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãbirth_year, ¬≤‚Äãdeath_year"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#right_join",
    "href": "slides/07/07-wrangle-3.html#right_join",
    "title": "Data wrangling - III",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\nJoining, by = \"id\"\n\n\n# A tibble: 3 √ó 3\n     id value_x value_y\n  <dbl> <chr>   <chr>  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 <NA>    y4"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#right_join-1",
    "href": "slides/07/07-wrangle-3.html#right_join-1",
    "title": "Data wrangling - III",
    "section": "right_join()",
    "text": "right_join()\n\nprofessions |>\n  right_join(dates)\n\nJoining, by = \"name\"\n\n\n# A tibble: 8 √ó 4\n  name               profession                   birth‚Ä¶¬π death‚Ä¶¬≤\n  <chr>              <chr>                          <dbl>   <dbl>\n1 Janaki Ammal       Botanist                        1897    1984\n2 Chien-Shiung Wu    Physicist                       1912    1997\n3 Katherine Johnson  Mathematician                   1918    2020\n4 Rosalind Franklin  Chemist                         1920    1958\n5 Vera Rubin         Astronomer                      1928    2016\n6 Gladys West        Mathematician                   1930      NA\n7 Flossie Wong-Staal Virologist and Molecular Bi‚Ä¶    1947      NA\n8 Jennifer Doudna    Biochemist                      1964      NA\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãbirth_year, ¬≤‚Äãdeath_year"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#full_join",
    "href": "slides/07/07-wrangle-3.html#full_join",
    "title": "Data wrangling - III",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\nJoining, by = \"id\"\n\n\n# A tibble: 4 √ó 3\n     id value_x value_y\n  <dbl> <chr>   <chr>  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      <NA>   \n4     4 <NA>    y4"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#full_join-1",
    "href": "slides/07/07-wrangle-3.html#full_join-1",
    "title": "Data wrangling - III",
    "section": "full_join()",
    "text": "full_join()\n\ndates |>\n  full_join(works)\n\nJoining, by = \"name\"\n\n\n# A tibble: 10 √ó 4\n   name               birth_year death_year known_for            \n   <chr>                   <dbl>      <dbl> <chr>                \n 1 Janaki Ammal             1897       1984 hybrid species, biod‚Ä¶\n 2 Chien-Shiung Wu          1912       1997 experiment overturni‚Ä¶\n 3 Katherine Johnson        1918       2020 orbital mechanics cr‚Ä¶\n 4 Rosalind Franklin        1920       1958 <NA>                 \n 5 Vera Rubin               1928       2016 existence of dark ma‚Ä¶\n 6 Gladys West              1930         NA mathematical modelin‚Ä¶\n 7 Flossie Wong-Staal       1947         NA first to clone HIV a‚Ä¶\n 8 Jennifer Doudna          1964         NA one of the primary d‚Ä¶\n 9 Ada Lovelace               NA         NA first computer algor‚Ä¶\n10 Marie Curie                NA         NA theory of radioactiv‚Ä¶"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#inner_join",
    "href": "slides/07/07-wrangle-3.html#inner_join",
    "title": "Data wrangling - III",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\nJoining, by = \"id\"\n\n\n# A tibble: 2 √ó 3\n     id value_x value_y\n  <dbl> <chr>   <chr>  \n1     1 x1      y1     \n2     2 x2      y2"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#inner_join-1",
    "href": "slides/07/07-wrangle-3.html#inner_join-1",
    "title": "Data wrangling - III",
    "section": "inner_join()",
    "text": "inner_join()\n\ndates |>\n  inner_join(works)\n\nJoining, by = \"name\"\n\n\n# A tibble: 7 √ó 4\n  name               birth_year death_year known_for             \n  <chr>                   <dbl>      <dbl> <chr>                 \n1 Janaki Ammal             1897       1984 hybrid species, biodi‚Ä¶\n2 Chien-Shiung Wu          1912       1997 experiment overturnin‚Ä¶\n3 Katherine Johnson        1918       2020 orbital mechanics cri‚Ä¶\n4 Vera Rubin               1928       2016 existence of dark mat‚Ä¶\n5 Gladys West              1930         NA mathematical modeling‚Ä¶\n6 Flossie Wong-Staal       1947         NA first to clone HIV an‚Ä¶\n7 Jennifer Doudna          1964         NA one of the primary de‚Ä¶"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#semi_join",
    "href": "slides/07/07-wrangle-3.html#semi_join",
    "title": "Data wrangling - III",
    "section": "semi_join()",
    "text": "semi_join()\n\n\n\n\n\nsemi_join(x, y)\n\nJoining, by = \"id\"\n\n\n# A tibble: 2 √ó 2\n     id value_x\n  <dbl> <chr>  \n1     1 x1     \n2     2 x2"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#semi_join-1",
    "href": "slides/07/07-wrangle-3.html#semi_join-1",
    "title": "Data wrangling - III",
    "section": "semi_join()",
    "text": "semi_join()\n\ndates |>\n  semi_join(works)\n\nJoining, by = \"name\"\n\n\n# A tibble: 7 √ó 3\n  name               birth_year death_year\n  <chr>                   <dbl>      <dbl>\n1 Janaki Ammal             1897       1984\n2 Chien-Shiung Wu          1912       1997\n3 Katherine Johnson        1918       2020\n4 Vera Rubin               1928       2016\n5 Gladys West              1930         NA\n6 Flossie Wong-Staal       1947         NA\n7 Jennifer Doudna          1964         NA"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#anti_join",
    "href": "slides/07/07-wrangle-3.html#anti_join",
    "title": "Data wrangling - III",
    "section": "anti_join()",
    "text": "anti_join()\n\n\n\n\n\nanti_join(x, y)\n\nJoining, by = \"id\"\n\n\n# A tibble: 1 √ó 2\n     id value_x\n  <dbl> <chr>  \n1     3 x3"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#anti_join-1",
    "href": "slides/07/07-wrangle-3.html#anti_join-1",
    "title": "Data wrangling - III",
    "section": "anti_join()",
    "text": "anti_join()\n\ndates |>\n  anti_join(works)\n\nJoining, by = \"name\"\n\n\n# A tibble: 1 √ó 3\n  name              birth_year death_year\n  <chr>                  <dbl>      <dbl>\n1 Rosalind Franklin       1920       1958"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#putting-it-altogether",
    "href": "slides/07/07-wrangle-3.html#putting-it-altogether",
    "title": "Data wrangling - III",
    "section": "Putting it altogether",
    "text": "Putting it altogether\n\nscientists <- professions |>\n  left_join(dates) |>\n  left_join(works)\n\nJoining, by = \"name\"\nJoining, by = \"name\"\n\nscientists\n\n# A tibble: 10 √ó 5\n   name               profession          birth‚Ä¶¬π death‚Ä¶¬≤ known‚Ä¶¬≥\n   <chr>              <chr>                 <dbl>   <dbl> <chr>  \n 1 Ada Lovelace       Mathematician            NA      NA first ‚Ä¶\n 2 Marie Curie        Physicist and Chem‚Ä¶      NA      NA theory‚Ä¶\n 3 Janaki Ammal       Botanist               1897    1984 hybrid‚Ä¶\n 4 Chien-Shiung Wu    Physicist              1912    1997 experi‚Ä¶\n 5 Katherine Johnson  Mathematician          1918    2020 orbita‚Ä¶\n 6 Rosalind Franklin  Chemist                1920    1958 <NA>   \n 7 Vera Rubin         Astronomer             1928    2016 existe‚Ä¶\n 8 Gladys West        Mathematician          1930      NA mathem‚Ä¶\n 9 Flossie Wong-Staal Virologist and Mol‚Ä¶    1947      NA first ‚Ä¶\n10 Jennifer Doudna    Biochemist             1964      NA one of‚Ä¶\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãbirth_year, ¬≤‚Äãdeath_year,\n#   ¬≥‚Äãknown_for"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#join-functions",
    "href": "slides/07/07-wrangle-3.html#join-functions",
    "title": "Data wrangling - III",
    "section": "*_join() functions",
    "text": "*_join() functions\n\nFrom dplyr\nIncredibly useful for bringing datasets with common information (e.g., unique identifier) together\nUse by argument when the names of the column containing the common information are not the same across datasets\nAlways check that the numbers of rows and columns of the result dataset makes sense\nRefer to two-table verbs vignette when needed"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#visualizing-joined-data",
    "href": "slides/07/07-wrangle-3.html#visualizing-joined-data",
    "title": "Data wrangling - III",
    "section": "Visualizing joined data",
    "text": "Visualizing joined data"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#but-first",
    "href": "slides/07/07-wrangle-3.html#but-first",
    "title": "Data wrangling - III",
    "section": "But first‚Ä¶",
    "text": "But first‚Ä¶\n\nWhat is the plot in the previous slide called?"
  },
  {
    "objectID": "slides/07/07-wrangle-3.html#livecoding",
    "href": "slides/07/07-wrangle-3.html#livecoding",
    "title": "Data wrangling - III",
    "section": "Livecoding",
    "text": "Livecoding\nReveal below for code developed during live coding session.\n\nTransform\n\n\n\nCode\nscientists_longer <- scientists |>\n  mutate(\n    birth_year = case_when(\n      name == \"Ada Lovelace\" ~ 1815,\n      name == \"Marie Curie\" ~ 1867,\n      TRUE ~ birth_year\n    ),\n    death_year = case_when(\n      name == \"Ada Lovelace\" ~ 1852,\n      name == \"Marie Curie\" ~ 1934,\n      name == \"Flossie Wong-Staal\" ~ 2020,\n      TRUE ~ death_year\n    ),\n    status = if_else(is.na(death_year), \"alive\", \"deceased\"),\n    death_year = if_else(is.na(death_year), 2021, death_year),\n    known_for = if_else(name == \"Rosalind Franklin\", \"understanding of the molecular structures of DNA \", known_for)\n  ) |>\n  pivot_longer(\n    cols = contains(\"year\"),\n    names_to = \"year_type\",\n    values_to = \"year\"\n  ) |>\n  mutate(death_year_fake = if_else(year == 2021, TRUE, FALSE))\n\n\n\nPlot\n\n\n\nCode\nggplot(scientists_longer, \n       aes(x = year, y = fct_reorder(name, as.numeric(factor(profession))), group = name, color = profession)) +\n  geom_point(aes(shape = death_year_fake), show.legend = FALSE) +\n  geom_line(aes(linetype = status), show.legend = FALSE) +\n  scale_shape_manual(values = c(\"circle\", NA)) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n  scale_color_colorblind() +\n  scale_x_continuous(expand = c(0.01, 0), breaks = seq(1820, 2020, 50)) +\n  geom_text(aes(y = name, label = known_for), x = 2030, show.legend = FALSE, hjust = 0) +\n  geom_text(aes(label = profession), x = 1809, y = Inf, hjust = 1, vjust = 1, show.legend = FALSE) +\n  coord_cartesian(clip = \"off\") +\n  labs(\n    x = \"Year\", y = NULL,\n    title = \"10 women in science who changed the world\",\n    caption = \"Source: Discover magazine\"\n  ) +\n  facet_grid(profession ~ ., scales = \"free_y\", space = \"free_y\", switch = \"x\") +\n  theme(\n    plot.margin = unit(c(1, 23, 1, 4), \"lines\"),\n    plot.title.position = \"plot\",\n    plot.caption.position = \"plot\",\n    plot.caption = element_text(hjust = 2), # manual hack\n    strip.background = element_blank(),\n    strip.text = element_blank(),\n    axis.title.x = element_text(hjust = 0),\n    panel.background = element_rect(fill = \"#f0f0f0\", color = \"white\"),\n    panel.grid.major = element_line(color = \"white\", size = 0.5)\n  )"
  },
  {
    "objectID": "slides/08/08-time-series-I.html",
    "href": "slides/08/08-time-series-I.html",
    "title": "Visualizing time series data I",
    "section": "",
    "text": "Project 1 proposal due Friday, 5pm\nRQ 3 due Tuesday by class, covers everything since last reading quiz\nProject 1 presentations ‚Äì Feb 22 in lab, all team members must be there\n\n\n\n\n\n# load packages\nlibrary(countdown)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\nlibrary(colorspace)\nlibrary(broom)\nlibrary(fs)\n\n# set theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))\n\n# set width of code output\noptions(width = 65)\n\n# set figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 7, # 7\" width\n  fig.asp = 0.618, # the golden ratio\n  fig.retina = 3, # dpi multiplier for displaying HTML output on retina\n  fig.align = \"center\", # center align figures\n  dpi = 300 # higher dpi, sharper image\n)"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#air-quality-index",
    "href": "slides/08/08-time-series-I.html#air-quality-index",
    "title": "Visualizing time series data I",
    "section": "Air Quality Index",
    "text": "Air Quality Index\n\nThe AQI is the Environmental Protection Agency‚Äôs index for reporting air quality\nHigher values of AQI indicate worse air quality\n\n\n\n\n\n\n\n\n\n\n\n\nSource: https://www.airnow.gov/aqi-basics"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#aqi-levels",
    "href": "slides/08/08-time-series-I.html#aqi-levels",
    "title": "Visualizing time series data I",
    "section": "AQI levels",
    "text": "AQI levels\nThe previous graphic in tibble form, to be used later‚Ä¶\n\naqi_levels <- tribble(\n  ~aqi_min, ~aqi_max, ~color,    ~level,\n  0,        50,       \"#D8EEDA\", \"Good\",\n  51,       100,      \"#F1E7D4\", \"Moderate\",\n  101,      150,      \"#F8E4D8\", \"Unhealthy for sensitive groups\",\n  151,      200,      \"#FEE2E1\", \"Unhealthy\",\n  201,      300,      \"#F4E3F7\", \"Very unhealthy\",\n  301,      400,      \"#F9D0D4\", \"Hazardous\"\n)"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#aqi-data",
    "href": "slides/08/08-time-series-I.html#aqi-data",
    "title": "Visualizing time series data I",
    "section": "AQI data",
    "text": "AQI data\n\nSource: EPA‚Äôs Daily Air Quality Tracker\n2016 - 2022 AQI (Ozone and PM2.5 combined) for Durham-Chapel Hill, NC core-based statistical area (CBSA), one file per year\n2016 - 2022 AQI (Ozone and PM2.5 combined) for San Francisco-Oakland-Hayward, CA CBSA, one file per year"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#durham-chapel-hill",
    "href": "slides/08/08-time-series-I.html#durham-chapel-hill",
    "title": "Visualizing time series data I",
    "section": "2022 Durham-Chapel Hill",
    "text": "2022 Durham-Chapel Hill\n\nLoad data\n\n\ndch_2022 <- read_csv(here::here(\"data/durham-chapel-hill/ad_aqi_tracker_data-2022.csv\"))\n\n\n\nMetadata\n\n\ndim(dch_2022)\n\n[1] 365  11\n\nnames(dch_2022)\n\n [1] \"Date\"                       \"AQI Value\"                 \n [3] \"Main Pollutant\"             \"Site Name\"                 \n [5] \"Site ID\"                    \"Source\"                    \n [7] \"20-year High (2000-2019)\"   \"20-year Low (2000-2019)\"   \n [9] \"5-year Average (2015-2019)\" \"Date of 20-year High\"      \n[11] \"Date of 20-year Low\""
  },
  {
    "objectID": "slides/08/08-time-series-I.html#clean-variable-names",
    "href": "slides/08/08-time-series-I.html#clean-variable-names",
    "title": "Visualizing time series data I",
    "section": "Clean variable names",
    "text": "Clean variable names\n\ndch_2022 <- dch_2022 |>\n  janitor::clean_names()\n\nnames(dch_2022)\n\n [1] \"date\"                      \"aqi_value\"                \n [3] \"main_pollutant\"            \"site_name\"                \n [5] \"site_id\"                   \"source\"                   \n [7] \"x20_year_high_2000_2019\"   \"x20_year_low_2000_2019\"   \n [9] \"x5_year_average_2015_2019\" \"date_of_20_year_high\"     \n[11] \"date_of_20_year_low\""
  },
  {
    "objectID": "slides/08/08-time-series-I.html#first-look",
    "href": "slides/08/08-time-series-I.html#first-look",
    "title": "Visualizing time series data I",
    "section": "First look",
    "text": "First look\n\nThis plot looks quite bizarre. What might be going on?\n\n\nggplot(dch_2022, aes(x = date, y = aqi_value, group = 1)) +\n  geom_line()"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#peek-at-data",
    "href": "slides/08/08-time-series-I.html#peek-at-data",
    "title": "Visualizing time series data I",
    "section": "Peek at data",
    "text": "Peek at data\n\ndch_2022 |>\n  select(date, aqi_value, site_name, site_id)\n\n# A tibble: 365 √ó 4\n   date       aqi_value site_name     site_id    \n   <chr>      <chr>     <chr>         <chr>      \n 1 01/01/2022 22        Durham Armory 37-063-0015\n 2 01/02/2022 12        Durham Armory 37-063-0015\n 3 01/03/2022 10        Durham Armory 37-063-0015\n 4 01/04/2022 21        Durham Armory 37-063-0015\n 5 01/05/2022 35        Durham Armory 37-063-0015\n 6 01/06/2022 29        Durham Armory 37-063-0015\n 7 01/07/2022 15        Durham Armory 37-063-0015\n 8 01/08/2022 28        Durham Armory 37-063-0015\n 9 01/09/2022 28        Durham Armory 37-063-0015\n10 01/10/2022 15        Durham Armory 37-063-0015\n# ‚Ä¶ with 355 more rows"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#transforming-date",
    "href": "slides/08/08-time-series-I.html#transforming-date",
    "title": "Visualizing time series data I",
    "section": "Transforming date",
    "text": "Transforming date\nUsing lubridate::mdy():\n\ndch_2022 |>\n  mutate(date = mdy(date))\n\n# A tibble: 365 √ó 11\n   date       aqi_value main_pol‚Ä¶¬π site_‚Ä¶¬≤ site_id source x20_y‚Ä¶¬≥\n   <date>     <chr>     <chr>      <chr>   <chr>   <chr>    <dbl>\n 1 2022-01-01 22        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS        111\n 2 2022-01-02 12        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         76\n 3 2022-01-03 10        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         66\n 4 2022-01-04 21        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         61\n 5 2022-01-05 35        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         83\n 6 2022-01-06 29        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         71\n 7 2022-01-07 15        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         75\n 8 2022-01-08 28        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         76\n 9 2022-01-09 28        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         57\n10 2022-01-10 15        PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         71\n# ‚Ä¶ with 355 more rows, 4 more variables:\n#   x20_year_low_2000_2019 <dbl>,\n#   x5_year_average_2015_2019 <dbl>, date_of_20_year_high <chr>,\n#   date_of_20_year_low <chr>, and abbreviated variable names\n#   ¬π‚Äãmain_pollutant, ¬≤‚Äãsite_name, ¬≥‚Äãx20_year_high_2000_2019"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#transforming-aqi-values",
    "href": "slides/08/08-time-series-I.html#transforming-aqi-values",
    "title": "Visualizing time series data I",
    "section": "Transforming AQI values",
    "text": "Transforming AQI values\n\nWhat does this warning mean?\n\n\ndch_2022 |>\n  mutate(aqi_value = as.numeric(aqi_value))\n\nWarning in mask$eval_all_mutate(quo): NAs durch Umwandlung\nerzeugt\n\n\n# A tibble: 365 √ó 11\n  date     aqi_v‚Ä¶¬π main_‚Ä¶¬≤ site_‚Ä¶¬≥ site_id source x20_y‚Ä¶‚Å¥ x20_y‚Ä¶‚Åµ\n  <chr>      <dbl> <chr>   <chr>   <chr>   <chr>    <dbl>   <dbl>\n1 01/01/2‚Ä¶      22 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS        111      10\n2 01/02/2‚Ä¶      12 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS         76       8\n3 01/03/2‚Ä¶      10 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS         66      14\n# ‚Ä¶ with 362 more rows, 3 more variables:\n#   x5_year_average_2015_2019 <dbl>, date_of_20_year_high <chr>,\n#   date_of_20_year_low <chr>, and abbreviated variable names\n#   ¬π‚Äãaqi_value, ¬≤‚Äãmain_pollutant, ¬≥‚Äãsite_name,\n#   ‚Å¥‚Äãx20_year_high_2000_2019, ‚Åµ‚Äãx20_year_low_2000_2019"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#investigating-aqi-values",
    "href": "slides/08/08-time-series-I.html#investigating-aqi-values",
    "title": "Visualizing time series data I",
    "section": "Investigating AQI values",
    "text": "Investigating AQI values\n\nTake a peek at distinct values of AQI\n\n\ndch_2022 |>\n  distinct(aqi_value) |>\n  pull()\n\n [1] \"22\" \"12\" \"10\" \"21\" \"35\" \"29\" \"15\" \"28\" \"25\" \"36\" \"49\" \"19\"\n[13] \"24\" \"46\" \"38\" \"48\" \"34\" \"47\" \"57\" \"26\" \"45\" \"42\" \"13\" \"31\"\n[25] \"39\" \"62\" \"40\" \"30\" \"20\" \"18\" \"27\" \"67\" \"41\" \"56\" \"37\" \"32\"\n[37] \"43\" \"51\" \"50\" \"44\" \"33\" \"54\" \"52\" \"77\" \"74\" \"53\" \"58\" \"64\"\n[49] \"61\" \"93\" \"16\" \"17\" \"23\" \"5\"  \"6\"  \".\"  \"9\"  \"14\" \"59\"\n\n\n\n\".\" likely indicates NA, and it‚Äôs causing the entire column to be read in as characters"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#rewind-and-start-over",
    "href": "slides/08/08-time-series-I.html#rewind-and-start-over",
    "title": "Visualizing time series data I",
    "section": "Rewind, and start over",
    "text": "Rewind, and start over\n\ndch_2022 <- read_csv(\n  here::here(\"data/durham-chapel-hill/ad_aqi_tracker_data-2022.csv\"),\n  na = c(\".\", \"\")\n)\n\n\nglimpse(dch_2022)\n\nRows: 365\nColumns: 11\n$ Date                         <chr> \"01/01/2022\", \"01/02/2022\"‚Ä¶\n$ `AQI Value`                  <dbl> 22, 12, 10, 21, 35, 29, 15‚Ä¶\n$ `Main Pollutant`             <chr> \"PM2.5\", \"PM2.5\", \"PM2.5\",‚Ä¶\n$ `Site Name`                  <chr> \"Durham Armory\", \"Durham A‚Ä¶\n$ `Site ID`                    <chr> \"37-063-0015\", \"37-063-001‚Ä¶\n$ Source                       <chr> \"AQS\", \"AQS\", \"AQS\", \"AQS\"‚Ä¶\n$ `20-year High (2000-2019)`   <dbl> 111, 76, 66, 61, 83, 71, 7‚Ä¶\n$ `20-year Low (2000-2019)`    <dbl> 10, 8, 14, 9, 8, 15, 18, 1‚Ä¶\n$ `5-year Average (2015-2019)` <dbl> 39.2, 36.8, 38.2, 30.4, 26‚Ä¶\n$ `Date of 20-year High`       <chr> \"01/01/2000\", \"01/02/2005\"‚Ä¶\n$ `Date of 20-year Low`        <chr> \"01/01/2007\", \"01/02/2012\"‚Ä¶"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#data-cleaning",
    "href": "slides/08/08-time-series-I.html#data-cleaning",
    "title": "Visualizing time series data I",
    "section": "Data cleaning",
    "text": "Data cleaning\n\ndch_2022 <- dch_2022 |>\n  janitor::clean_names() |>\n  mutate(date = mdy(date))\n\ndch_2022\n\n# A tibble: 365 √ó 11\n   date       aqi_value main_pol‚Ä¶¬π site_‚Ä¶¬≤ site_id source x20_y‚Ä¶¬≥\n   <date>         <dbl> <chr>      <chr>   <chr>   <chr>    <dbl>\n 1 2022-01-01        22 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS        111\n 2 2022-01-02        12 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         76\n 3 2022-01-03        10 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         66\n 4 2022-01-04        21 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         61\n 5 2022-01-05        35 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         83\n 6 2022-01-06        29 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         71\n 7 2022-01-07        15 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         75\n 8 2022-01-08        28 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         76\n 9 2022-01-09        28 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         57\n10 2022-01-10        15 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         71\n# ‚Ä¶ with 355 more rows, 4 more variables:\n#   x20_year_low_2000_2019 <dbl>,\n#   x5_year_average_2015_2019 <dbl>, date_of_20_year_high <chr>,\n#   date_of_20_year_low <chr>, and abbreviated variable names\n#   ¬π‚Äãmain_pollutant, ¬≤‚Äãsite_name, ¬≥‚Äãx20_year_high_2000_2019"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#another-look",
    "href": "slides/08/08-time-series-I.html#another-look",
    "title": "Visualizing time series data I",
    "section": "Another look",
    "text": "Another look\n\nggplot(dch_2022, aes(x = date, y = aqi_value, group = 1)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\nHow would you improve this visualization?"
  },
  {
    "objectID": "slides/08/08-time-series-I.html#visualizing-durham-aqi",
    "href": "slides/08/08-time-series-I.html#visualizing-durham-aqi",
    "title": "Visualizing time series data I",
    "section": "Visualizing Durham AQI",
    "text": "Visualizing Durham AQI\n\nRecreate the following visualization."
  },
  {
    "objectID": "slides/09/09-time-series-II.html",
    "href": "slides/09/09-time-series-II.html",
    "title": "Visualizing time series data II",
    "section": "",
    "text": "‚Ä¶\n\n\n\n\n\n# load packages\nlibrary(countdown)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\nlibrary(colorspace)\nlibrary(broom)\nlibrary(fs)\n\n# set theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))\n\n# set width of code output\noptions(width = 65)\n\n# set figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 7, # 7\" width\n  fig.asp = 0.618, # the golden ratio\n  fig.retina = 3, # dpi multiplier for displaying HTML output on retina\n  fig.align = \"center\", # center align figures\n  dpi = 300 # higher dpi, sharper image\n)"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#aqi-levels",
    "href": "slides/09/09-time-series-II.html#aqi-levels",
    "title": "Visualizing time series data II",
    "section": "AQI levels",
    "text": "AQI levels\nThe previous graphic in tibble form, to be used later‚Ä¶\n\naqi_levels <- tribble(\n  ~aqi_min, ~aqi_max, ~color,    ~level,\n  0,        50,       \"#D8EEDA\", \"Good\",\n  51,       100,      \"#F1E7D4\", \"Moderate\",\n  101,      150,      \"#F8E4D8\", \"Unhealthy for sensitive groups\",\n  151,      200,      \"#FEE2E1\", \"Unhealthy\",\n  201,      300,      \"#F4E3F7\", \"Very unhealthy\",\n  301,      400,      \"#F9D0D4\", \"Hazardous\"\n)"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#aqi-data",
    "href": "slides/09/09-time-series-II.html#aqi-data",
    "title": "Visualizing time series data II",
    "section": "AQI data",
    "text": "AQI data\n\nSource: EPA‚Äôs Daily Air Quality Tracker\n2016 - 2022 AQI (Ozone and PM2.5 combined) for Durham-Chapel Hill, NC core-based statistical area (CBSA), one file per year\n2016 - 2022 AQI (Ozone and PM2.5 combined) for San Francisco-Oakland-Hayward, CA CBSA, one file per year"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#durham-chapel-hill",
    "href": "slides/09/09-time-series-II.html#durham-chapel-hill",
    "title": "Visualizing time series data II",
    "section": "2022 Durham-Chapel Hill",
    "text": "2022 Durham-Chapel Hill\n\ndch_2022 <- read_csv(\n  here::here(\"data/durham-chapel-hill/ad_aqi_tracker_data-2022.csv\"),\n  na = c(\".\", \"\")\n)\n\n\ndch_2022 <- dch_2022 |>\n  janitor::clean_names() |>\n  mutate(date = mdy(date))\n\ndch_2022\n\n# A tibble: 365 √ó 11\n   date       aqi_value main_pol‚Ä¶¬π site_‚Ä¶¬≤ site_id source x20_y‚Ä¶¬≥\n   <date>         <dbl> <chr>      <chr>   <chr>   <chr>    <dbl>\n 1 2022-01-01        22 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS        111\n 2 2022-01-02        12 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         76\n 3 2022-01-03        10 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         66\n 4 2022-01-04        21 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         61\n 5 2022-01-05        35 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         83\n 6 2022-01-06        29 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         71\n 7 2022-01-07        15 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         75\n 8 2022-01-08        28 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         76\n 9 2022-01-09        28 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         57\n10 2022-01-10        15 PM2.5      Durham‚Ä¶ 37-063‚Ä¶ AQS         71\n# ‚Ä¶ with 355 more rows, 4 more variables:\n#   x20_year_low_2000_2019 <dbl>,\n#   x5_year_average_2015_2019 <dbl>, date_of_20_year_high <chr>,\n#   date_of_20_year_low <chr>, and abbreviated variable names\n#   ¬π‚Äãmain_pollutant, ¬≤‚Äãsite_name, ¬≥‚Äãx20_year_high_2000_2019"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#visualizing-durham-aqi",
    "href": "slides/09/09-time-series-II.html#visualizing-durham-aqi",
    "title": "Visualizing time series data II",
    "section": "Visualizing Durham AQI",
    "text": "Visualizing Durham AQI\n\nRecreate the following visualization."
  },
  {
    "objectID": "slides/09/09-time-series-II.html#another-visualization-of-durham-aqi",
    "href": "slides/09/09-time-series-II.html#another-visualization-of-durham-aqi",
    "title": "Visualizing time series data II",
    "section": "Another visualization of Durham AQI",
    "text": "Another visualization of Durham AQI\n\nRecreate the following visualization."
  },
  {
    "objectID": "slides/09/09-time-series-II.html#highlights",
    "href": "slides/09/09-time-series-II.html#highlights",
    "title": "Visualizing time series data II",
    "section": "Highlights",
    "text": "Highlights\n\nThe lubridate package is useful for converting to dates from character strings in a given format, e.g.¬†mdy(), ymd(), etc.\nThe colorspace package is useful for programmatically darkening / lightening colors\nscale_x_date: Set date_labels as \"%b %y\" for month-2 digit year, \"%D\" for date format such as %m/%d/%y, etc. See help for strptime() for more.\nscale_color_identity() or scale_fill_identity() can be useful when your data already represents aesthetic values that ggplot2 can handle directly. By default doesn‚Äôt produce a legend."
  },
  {
    "objectID": "slides/09/09-time-series-II.html#cumulatives-over-time",
    "href": "slides/09/09-time-series-II.html#cumulatives-over-time",
    "title": "Visualizing time series data II",
    "section": "Cumulatives over time",
    "text": "Cumulatives over time\n\nWhen visualizing time series data, a somewhat common task is to calculate cumulatives over time and plot them\nIn our example we‚Äôll calculate the number of days with ‚Äúgood‚Äù AQI (\\(\\le\\) 50) and plot that value on the y-axis and the date on the x-axis"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#calculating-cumulatives-1",
    "href": "slides/09/09-time-series-II.html#calculating-cumulatives-1",
    "title": "Visualizing time series data II",
    "section": "Calculating cumulatives",
    "text": "Calculating cumulatives\nStep 1. Arrange your data\n\ndch_2022 |>\n  select(date, aqi_value) |>\n  filter(!is.na(aqi_value)) |>\n  arrange(date)\n\n# A tibble: 364 √ó 2\n  date       aqi_value\n  <date>         <dbl>\n1 2022-01-01        22\n2 2022-01-02        12\n3 2022-01-03        10\n4 2022-01-04        21\n5 2022-01-05        35\n# ‚Ä¶ with 359 more rows"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#calculating-cumulatives-2",
    "href": "slides/09/09-time-series-II.html#calculating-cumulatives-2",
    "title": "Visualizing time series data II",
    "section": "Calculating cumulatives",
    "text": "Calculating cumulatives\nStep 2. Identify good days\n\ndch_2022 |>\n  select(date, aqi_value) |>\n  filter(!is.na(aqi_value)) |>\n  arrange(date) |>\n  mutate(good_aqi = if_else(aqi_value <= 50, 1, 0))\n\n# A tibble: 364 √ó 3\n  date       aqi_value good_aqi\n  <date>         <dbl>    <dbl>\n1 2022-01-01        22        1\n2 2022-01-02        12        1\n3 2022-01-03        10        1\n4 2022-01-04        21        1\n5 2022-01-05        35        1\n# ‚Ä¶ with 359 more rows"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#calculating-cumulatives-3",
    "href": "slides/09/09-time-series-II.html#calculating-cumulatives-3",
    "title": "Visualizing time series data II",
    "section": "Calculating cumulatives",
    "text": "Calculating cumulatives\nStep 3. Sum over time\n\ndch_2022 |>\n  select(date, aqi_value) |>\n  filter(!is.na(aqi_value)) |>\n  arrange(date) |>\n  mutate(\n    good_aqi = if_else(aqi_value <= 50, 1, 0),\n    cumsum_good_aqi = cumsum(good_aqi)\n  )\n\n# A tibble: 364 √ó 4\n  date       aqi_value good_aqi cumsum_good_aqi\n  <date>         <dbl>    <dbl>           <dbl>\n1 2022-01-01        22        1               1\n2 2022-01-02        12        1               2\n3 2022-01-03        10        1               3\n4 2022-01-04        21        1               4\n5 2022-01-05        35        1               5\n# ‚Ä¶ with 359 more rows"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#plotting-cumulatives",
    "href": "slides/09/09-time-series-II.html#plotting-cumulatives",
    "title": "Visualizing time series data II",
    "section": "Plotting cumulatives",
    "text": "Plotting cumulatives\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndch_2022 |>\n  select(date, aqi_value) |>\n  filter(!is.na(aqi_value)) |>\n  arrange(date) |>\n  mutate(\n    good_aqi = if_else(aqi_value <= 50, 1, 0),\n    cumsum_good_aqi = cumsum(good_aqi)\n  ) |>\n  ggplot(aes(x = date, y = cumsum_good_aqi, group = 1)) +\n  geom_line() +\n  scale_x_date(date_labels = \"%b %Y\") +\n  labs(\n    x = NULL, y = \"Number of days\",\n    title = \"Cumulative number of good AQI days (AQI < 50)\",\n    subtitle = \"Durham-Chapel Hill, NC\",\n    caption = \"\\nSource: EPA Daily Air Quality Tracker\"\n  ) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#detrending-1",
    "href": "slides/09/09-time-series-II.html#detrending-1",
    "title": "Visualizing time series data II",
    "section": "Detrending",
    "text": "Detrending\n\nDetrending is removing prominent long-term trend in time series to specifically highlight any notable deviations\nLet‚Äôs demonstrate using multiple years of AQI data"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#multiple-years-of-durham-chapel-hill-data",
    "href": "slides/09/09-time-series-II.html#multiple-years-of-durham-chapel-hill-data",
    "title": "Visualizing time series data II",
    "section": "Multiple years of Durham-Chapel Hill data",
    "text": "Multiple years of Durham-Chapel Hill data\n\ndch_files <- fs::dir_ls(here::here(\"data/durham-chapel-hill\"))\ndch_files\n\n\n\nC:/Users/Jasmin/OneDrive - Universit√§t Hamburg/Desktop/Dissertation/Teaching/AM1-populism/slides/08/data/durham-chapel-hill/ad_aqi_tracker_data-2016.csv\nC:/Users/Jasmin/OneDrive - Universit√§t Hamburg/Desktop/Dissertation/Teaching/AM1-populism/slides/08/data/durham-chapel-hill/ad_aqi_tracker_data-2017.csv\nC:/Users/Jasmin/OneDrive - Universit√§t Hamburg/Desktop/Dissertation/Teaching/AM1-populism/slides/08/data/durham-chapel-hill/ad_aqi_tracker_data-2018.csv\nC:/Users/Jasmin/OneDrive - Universit√§t Hamburg/Desktop/Dissertation/Teaching/AM1-populism/slides/08/data/durham-chapel-hill/ad_aqi_tracker_data-2019.csv\nC:/Users/Jasmin/OneDrive - Universit√§t Hamburg/Desktop/Dissertation/Teaching/AM1-populism/slides/08/data/durham-chapel-hill/ad_aqi_tracker_data-2020.csv\nC:/Users/Jasmin/OneDrive - Universit√§t Hamburg/Desktop/Dissertation/Teaching/AM1-populism/slides/08/data/durham-chapel-hill/ad_aqi_tracker_data-2021.csv\nC:/Users/Jasmin/OneDrive - Universit√§t Hamburg/Desktop/Dissertation/Teaching/AM1-populism/slides/08/data/durham-chapel-hill/ad_aqi_tracker_data-2022.csv"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#reading-multiple-files",
    "href": "slides/09/09-time-series-II.html#reading-multiple-files",
    "title": "Visualizing time series data II",
    "section": "Reading multiple files",
    "text": "Reading multiple files\n\ndch <- read_csv(dch_files, na = c(\".\", \"\"))\n\ndch <- dch |>\n  janitor::clean_names() |>\n  mutate(\n    date = mdy(date),\n    good_aqi = if_else(aqi_value <= 50, 1, 0)\n  ) |>\n  filter(!is.na(aqi_value)) |>\n  arrange(date) |>\n  mutate(cumsum_good_aqi = cumsum(good_aqi), .after = aqi_value)\n\ndch\n\n# A tibble: 2,547 √ó 13\n  date       aqi_value cumsum_go‚Ä¶¬π main_‚Ä¶¬≤ site_‚Ä¶¬≥ site_id source\n  <date>         <dbl>       <dbl> <chr>   <chr>   <chr>   <chr> \n1 2016-01-01        32           1 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n2 2016-01-02        37           2 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n3 2016-01-03        45           3 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n4 2016-01-04        33           4 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n5 2016-01-05        27           5 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n# ‚Ä¶ with 2,542 more rows, 6 more variables:\n#   x20_year_high_2000_2019 <dbl>, x20_year_low_2000_2019 <dbl>,\n#   x5_year_average_2015_2019 <dbl>, date_of_20_year_high <chr>,\n#   date_of_20_year_low <chr>, good_aqi <dbl>, and abbreviated\n#   variable names ¬π‚Äãcumsum_good_aqi, ¬≤‚Äãmain_pollutant, ¬≥‚Äãsite_name"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#plot-trend-since-2016",
    "href": "slides/09/09-time-series-II.html#plot-trend-since-2016",
    "title": "Visualizing time series data II",
    "section": "Plot trend since 2016",
    "text": "Plot trend since 2016\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndch |>\n  ggplot(aes(x = date, y = cumsum_good_aqi, group = 1)) +\n  geom_smooth(method = \"lm\", color = \"pink\") +\n  geom_line() +\n  scale_x_date(\n    expand = expansion(mult = 0.07),\n    date_labels = \"%Y\"\n  ) +\n  labs(\n    x = NULL, y = \"Number of days\",\n    title = \"Cumulative number of good AQI days (AQI < 50)\",\n    subtitle = \"Durham-Chapel Hill, NC\",\n    caption = \"\\nSource: EPA Daily Air Quality Tracker\"\n  ) +\n  theme(plot.title.position = \"plot\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#detrend",
    "href": "slides/09/09-time-series-II.html#detrend",
    "title": "Visualizing time series data II",
    "section": "Detrend",
    "text": "Detrend\nStep 1. Fit a simple linear regression\n\nm <- lm(cumsum_good_aqi ~ date, data = dch)\n\nm\n\n\nCall:\nlm(formula = cumsum_good_aqi ~ date, data = dch)\n\nCoefficients:\n(Intercept)         date  \n -1.341e+04    7.954e-01"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#detrend-1",
    "href": "slides/09/09-time-series-II.html#detrend-1",
    "title": "Visualizing time series data II",
    "section": "Detrend",
    "text": "Detrend\nStep 2. Augment the data with model results (using broom::augment())\n\ndch_aug <- augment(m)\n\ndch_aug\n\n# A tibble: 2,547 √ó 8\n  cumsum_good_‚Ä¶¬π date       .fitted .resid    .hat .sigma .cooksd\n           <dbl> <date>       <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n1              1 2016-01-01   -42.8   43.8 0.00157   25.4 0.00234\n2              2 2016-01-02   -42.0   44.0 0.00157   25.4 0.00236\n3              3 2016-01-03   -41.3   44.3 0.00156   25.4 0.00238\n4              4 2016-01-04   -40.5   44.5 0.00156   25.4 0.00240\n5              5 2016-01-05   -39.7   44.7 0.00156   25.4 0.00242\n# ‚Ä¶ with 2,542 more rows, 1 more variable: .std.resid <dbl>, and\n#   abbreviated variable name ¬π‚Äãcumsum_good_aqi"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#detrend-2",
    "href": "slides/09/09-time-series-II.html#detrend-2",
    "title": "Visualizing time series data II",
    "section": "Detrend",
    "text": "Detrend\nStep 3. Divide the observed value of cumsum_good_aqi by the respective value in the long-term trend (i.e., .fitted)\n\ndch_aug <- dch_aug |>\n  mutate(ratio = cumsum_good_aqi / .fitted, .after = .fitted)\n\n\ndch_aug\n\n# A tibble: 2,547 √ó 9\n  cumsum_good_‚Ä¶¬π date       .fitted   ratio .resid    .hat .sigma\n           <dbl> <date>       <dbl>   <dbl>  <dbl>   <dbl>  <dbl>\n1              1 2016-01-01   -42.8 -0.0233   43.8 0.00157   25.4\n2              2 2016-01-02   -42.0 -0.0476   44.0 0.00157   25.4\n3              3 2016-01-03   -41.3 -0.0727   44.3 0.00156   25.4\n4              4 2016-01-04   -40.5 -0.0989   44.5 0.00156   25.4\n5              5 2016-01-05   -39.7 -0.126    44.7 0.00156   25.4\n# ‚Ä¶ with 2,542 more rows, 2 more variables: .cooksd <dbl>,\n#   .std.resid <dbl>, and abbreviated variable name\n#   ¬π‚Äãcumsum_good_aqi"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#visualize-detrended-data",
    "href": "slides/09/09-time-series-II.html#visualize-detrended-data",
    "title": "Visualizing time series data II",
    "section": "Visualize detrended data",
    "text": "Visualize detrended data\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndch_aug |>\n  ggplot(aes(x = date, y = ratio, group = 1)) +\n  geom_hline(yintercept = 1, color = \"gray\") +\n  geom_line() +\n  scale_x_date(\n    expand = expansion(mult = 0.07),\n    date_labels = \"%Y\"\n  ) +\n  labs(\n    x = NULL, y = \"Number of days\\n(detrended)\",\n    title = \"Cumulative number of good AQI days (AQI < 50)\",\n    subtitle = \"Durham-Chapel Hill, NC\",\n    caption = \"\\nSource: EPA Daily Air Quality Tracker\"\n  ) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#air-quality-in-durham",
    "href": "slides/09/09-time-series-II.html#air-quality-in-durham",
    "title": "Visualizing time series data II",
    "section": "Air Quality in Durham",
    "text": "Air Quality in Durham\n\n\nbarely anything interesting happening!\n\n\n\nlet‚Äôs look at data from somewhere with a bit more ‚Äúinteresting‚Äù air quality data‚Ä¶"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#read-in-multiple-years-of-sf-data",
    "href": "slides/09/09-time-series-II.html#read-in-multiple-years-of-sf-data",
    "title": "Visualizing time series data II",
    "section": "Read in multiple years of SF data",
    "text": "Read in multiple years of SF data\n\nsf_files <- fs::dir_ls(here::here(\"data/san-francisco\"))\n\n\nsf <- read_csv(sf_files, na = c(\".\", \"\"))\n\nsf <- sf |>\n  janitor::clean_names() |>\n  mutate(\n    date = mdy(date),\n    good_aqi = if_else(aqi_value <= 50, 1, 0)\n  ) |>\n  filter(!is.na(aqi_value)) |>\n  arrange(date) |>\n  mutate(cumsum_good_aqi = cumsum(good_aqi), .after = aqi_value)\n\nsf\n\n# A tibble: 2,557 √ó 13\n  date       aqi_value cumsum_go‚Ä¶¬π main_‚Ä¶¬≤ site_‚Ä¶¬≥ site_id source\n  <date>         <dbl>       <dbl> <chr>   <chr>   <chr>   <chr> \n1 2016-01-01        32           1 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n2 2016-01-02        37           2 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n3 2016-01-03        45           3 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n4 2016-01-04        33           4 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n5 2016-01-05        27           5 PM2.5   Durham‚Ä¶ 37-063‚Ä¶ AQS   \n# ‚Ä¶ with 2,552 more rows, 6 more variables:\n#   x20_year_high_2000_2019 <dbl>, x20_year_low_2000_2019 <dbl>,\n#   x5_year_average_2015_2019 <dbl>, date_of_20_year_high <chr>,\n#   date_of_20_year_low <chr>, good_aqi <dbl>, and abbreviated\n#   variable names ¬π‚Äãcumsum_good_aqi, ¬≤‚Äãmain_pollutant, ¬≥‚Äãsite_name"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#plot-trend-since-2016-1",
    "href": "slides/09/09-time-series-II.html#plot-trend-since-2016-1",
    "title": "Visualizing time series data II",
    "section": "Plot trend since 2016",
    "text": "Plot trend since 2016\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsf |>\n  ggplot(aes(x = date, y = cumsum_good_aqi, group = 1)) +\n  geom_smooth(method = \"lm\", color = \"pink\") +\n  geom_line() +\n  scale_x_date(\n    expand = expansion(mult = 0.07),\n    date_labels = \"%Y\"\n  ) +\n  labs(\n    x = NULL, y = \"Number of days\",\n    title = \"Cumulative number of good AQI days (AQI < 50)\",\n    subtitle = \"San Francisco-Oakland-Hayward, CA\",\n    caption = \"\\nSource: EPA Daily Air Quality Tracker\"\n  ) +\n  theme(plot.title.position = \"plot\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#detrend-3",
    "href": "slides/09/09-time-series-II.html#detrend-3",
    "title": "Visualizing time series data II",
    "section": "Detrend",
    "text": "Detrend\n\nFit a simple linear regression\n\n\nm_sf <- lm(cumsum_good_aqi ~ date, data = sf)\n\n\n\nAugment the data with model results\n\n\nsf_aug <- augment(m_sf)\n\n\n\n\nDivide the observed value of cumsum_good_aqi by the respective value in the long-term trend (i.e., .fitted)\n\n\nsf_aug <- sf_aug |>\n  mutate(ratio = cumsum_good_aqi / .fitted, .after = .fitted)"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#visualize-detrended-data-1",
    "href": "slides/09/09-time-series-II.html#visualize-detrended-data-1",
    "title": "Visualizing time series data II",
    "section": "Visualize detrended data",
    "text": "Visualize detrended data\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsf_aug |>\n  ggplot(aes(x = date, y = ratio, group = 1)) +\n  geom_hline(yintercept = 1, color = \"gray\") +\n  geom_line() +\n  scale_x_date(\n    expand = expansion(mult = 0.07),\n    date_labels = \"%Y\"\n  ) +\n  labs(\n    x = NULL, y = \"Number of days\\n(detrended)\",\n    title = \"Cumulative number of good AQI days (AQI < 50)\",\n    subtitle = \"San Francisco-Oakland-Hayward, CA\",\n    caption = \"\\nSource: EPA Daily Air Quality Tracker\"\n  ) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "slides/09/09-time-series-II.html#detrending-2",
    "href": "slides/09/09-time-series-II.html#detrending-2",
    "title": "Visualizing time series data II",
    "section": "Detrending",
    "text": "Detrending\n\nIn step 2 we fit a very simple model\nDepending on the complexity you‚Äôre trying to capture you might choose to fit a much more complex model\nYou can also decompose the trend into multiple trends, e.g.¬†monthly, long-term, seasonal, etc.\n\n\n\n\n\nInterested in learning more? Take STA 344 - Spatio-temporal analysis!"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Kursinformationen",
    "section": "",
    "text": "Dies ist die Homepage des Aufbaumodul 1 Seminars Vergleichende Empirische Populismusforschung von Jasmin Sarah K√∂nig im Sommersemester 2023. Alle Kursunterlagen werden auf dieser Seite gepostet."
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nOld Chemistry 116.\nTue & Thur 12:00 - 13:15 pm\n\n\nLab 01\nPerkins Link 087 (Classroom 3)\nWed 1:45 - 3:00 pm\n\n\nLab 02\nPerkins Link 087 (Classroom 3)\nWed 3:30 - 4:45 pm"
  },
  {
    "objectID": "course-overview.html#license",
    "href": "course-overview.html#license",
    "title": "Course overview",
    "section": "License",
    "text": "License\n\nThis online work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International. Visit here for more information about the license."
  },
  {
    "objectID": "studienleistung.html",
    "href": "studienleistung.html",
    "title": "Studienleistung",
    "section": "",
    "text": "Um f√ºr den Kurs die Credits angerechnet zu bekommen, muss eine Studienleistung abgelegt werden. Das Seminar verzichtet auf w√∂chentliche Referate, daf√ºr werden 3 kleine Studienleistungen erwartet."
  },
  {
    "objectID": "studienleistung.html#w√∂chentliche-fragen",
    "href": "studienleistung.html#w√∂chentliche-fragen",
    "title": "Studienleistung",
    "section": "W√∂chentliche Fragen",
    "text": "W√∂chentliche Fragen\nJede Woche sind einige Fragen zur Lekt√ºre zu beantworten. Diese sind immer ab Dienstag in der [Syllabus](/index.qmd). Die Fragen sind bis zum Montag vor dem Seminar um 12 Uhr mittags zu beantworten. Zwei bis drei S√§tze pro Frage reichen vollkommen.\nDie Fragen d√ºrfen pro Person in jeweils zwei Wochen verpasst werden.\n\nLesefragen\nF√ºr jede Sitzung muss vorab ein Paper/Kapitel gelesen werden. Um die Lekt√ºre etwas einfacher zu gestalten, werden jede Woche Fragen zu der Lekt√ºre hoch geladen. Ich werde die Fragen am Montag noch zur Vorbereitung des Seminars am Dienstag nutzen, und den Kurs so vorzubereiten, dass alle Fragen zum Text im Laufe des Seminars diskutiert werden k√∂nnen.\n\n\nSocial Media Analyse\n√úber das Semester folgt jede:r Teilnehmende einem Politiker auf einem Social Media Kanal. Bitte achtet insbesondere bei rechtsau√üen Politiker:innen falls m√∂glich darauf, dem Kanal nicht zu folgen, sondern ihn nur zu abbonieren. In dem w√∂chentlichen Fragenkatalog befindet sich jede Woche auch eine Frage zu dem Social Media Kanal, dem gefolgt wird. In einigen F√§llen bezieht dieser sich auf die Lekt√ºre (beispielsweise ‚ÄúWelches Konzept des Begriffs‚ÄùVolk‚Äù nutzt der:die Politiker:in auf ihrem:seinem Kanal?‚Äú, in manchen Wochen frage ich nur nach einer kurzen Zusammenfassung). Auch hier gilt, zwei bis drei S√§tze reichen vollkommen. Es geht bei der Aufgabe darum, die Anwendung von Konzepten auf die Empirie regelm√§√üig zu √ºben."
  },
  {
    "objectID": "studienleistung.html#research-proposal",
    "href": "studienleistung.html#research-proposal",
    "title": "Studienleistung",
    "section": "Research Proposal",
    "text": "Research Proposal\nAm Ende des Semester ist ein Research Proposal von 1000 - 1500 W√∂rtern abzugeben. In dem Proposal soll eine Fragestellung, Hypothesen und ein Vorschlag zur √úberpr√ºfung dieser entwickelt werden."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-syllabus.html#course-description",
    "href": "course-syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course description",
    "text": "Course description\nSTA 313 - Advanced Data Visualization is all about the art and science of visualizing data. Three themes (what, why, and how) will run alongside each other as we cycle through the course topics. In ‚Äúwhat‚Äù we focus on specific types of visualizations for a particular purpose (e.g.¬†maps for spatial data, Sankey diagrams for proportions, etc.) as well as the tooling to produce them (e.g.¬†specific R packages). In ‚Äúhow‚Äù we focus on the process ‚Äì each visualization starts with a design (which we‚Äôll often ask you to do with a rough sketch accompanied by pseudo code), then often needs pre-processing of the data (wrangling, reshaping, joining, etc. to get it into a tidy, rectangular format for visualization), then attributes of the data are mapped to plot aesthetics, then the creator of the visualization needs to make a series of strategic decisions about visual encoding (e.g.¬†accessibility concerns), and finally creating effective visualizations requires post-processing for visual appeal as well as annotation. In ‚Äúwhy‚Äù we discuss the theory that ties the ‚Äúhow‚Äù and the ‚Äúwhat‚Äù together, often focusing on the grammar of graphics. Like any data analysis, data visualization is also an iterative process. We don‚Äôt expect you to land on the perfect visualization on the first try, so we promote the iterative process via critical and constructive review of one‚Äôs own and each others‚Äô work. Independent modules will also touch on topics such as using statistical graphics for visual inference, creating data-based art, and a review of the literature on non-visual approaches to representing data.\nThe course will focus on the use of the R statistical programming language and introduce you to a variety of modern data visualization packages in R. In addition, you will continue to use hone their data science workflow skills that they acquired in pre-requisite courses by working with Git and GitHub for version control and collaboration."
  },
  {
    "objectID": "course-syllabus.html#prerequisites",
    "href": "course-syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis course assumes that this is not your first interaction with working with data in R, using RStudio, and along with version control with Git, and collaboration on GitHub. Any of the following courses meet the prerequisite for the course: STA 198, STA 199, or STA 210. The course will start with a quick review of the relevant technologies."
  },
  {
    "objectID": "course-syllabus.html#learning-goals",
    "href": "course-syllabus.html#learning-goals",
    "title": "Syllabus",
    "section": "Learning goals",
    "text": "Learning goals\n\nUnderstand the principles of designing and creating effective data visualizations.\nEvaluate, critique, and improve upon one‚Äôs own and others‚Äô data visualizations based on how good a job the visualization does for communicating a message clearly and correctly.\nPost-process and refine plots for effective communication.\nUse visualizations for evaluating statistical models and for statistical inference.\nMaster using R and a variety of modern data visualization packages to create data visualizations.\nWork reproducibly individually and collaboratively using Git and GitHub."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nReadings for the course will come from the following textbooks. All of them are freely available online and you do not need to purchase a physical copy of either book to succeed in this class.\n\n[ggplot2-book] Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen. ggplot2: Elegant Graphics for Data Analysis. (in progress) 3rd edition. Springer, 2022.\n[socviz] Kieran Healy. Data Visualization: A Practical Introduction. Princeton University Press, 2018.\n[fdv] Claus O. Wilke. Fundamentals of Data Visualization. O‚ÄôReilly Media, 2019.\n[r4ds] Hadley Wickham, Mine √áetinkaya-Rundel, and Garrett Grolemund. R for Data Science. (in progress) 2nd edition. O‚ÄôReilly, 2022."
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard (DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke‚Äôs Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know! You‚Äôll be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity‚Äôs website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website: vizdata.org.\nI will regularly send course announcements via email and Sakai, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course Slack. There is a chance another student has already asked a similar question, so please check the other posts on Slack before adding a new question. If you know the answer to a question posted on Slack, I encourage you to respond!\n\nCheck out the Support page for more resources.\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don‚Äôt hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you‚Äôre always welcome to talk to me. If I can‚Äôt help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis."
  },
  {
    "objectID": "course-syllabus.html#lectures-and-lab",
    "href": "course-syllabus.html#lectures-and-lab",
    "title": "Syllabus",
    "section": "Lectures and lab",
    "text": "Lectures and lab\nThe goal of both the lectures and the labs is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. Attendance will not be taken during class but you are expected to attend all lecture and lab sessions and meaningfully contribute to in-class exercises and discussion.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. See [Technology accommodations] if you need a loaner laptop."
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nAssessment for the course is comprised of four components: attendance and participation, reading quizzes, homework assignments, and projects.\n\nAttendance and participation is required throughout the semester. Students who attend at least 80% of the lectures and participate regularly during lecture will receive full credit for this portion of their grade. Participation in labs as well as on Slack will also count towards this component.\nReading quizzes (6), due every other week (roughly), completed individually. Each quiz is worth 2% of the grade. Lowest quiz score is dropped.\nReading quizzes will be linked from the course schedule. They always cover reading that is due since the previous quiz and up to and including the deadline for the given quiz. They‚Äôre due by 12pm ET (beginning of class) on the indicated day on the course schedule.\nHomework assignments (6), due every other week (roughly), completed individually. Each homework assignment is worth 8% of the course grade. Lowest homework assignment score is dropped.\nHomework assignments are due by 12pm ET (beginning of class) on the indicated day on the course schedule.\nProjects (2), mid-semester and end of semester, completed in teams.\n\nProject 1: Teams will be given a dataset to visualize. Project 1 is worth 15% of the course grade.\nProject 2: Teams will pick a dataset of interest to them and/or build an R package that implements a new type of data visualization in R. Project 2 is worth 25% of the course grade.\n\nThe deliverables for each project will include a data visualization, a write up of the process and findings, and a presentation. For the second project, you will be encouraged to think beyond a traditional two-dimensional data visualization (e.g.¬†interactive web apps/dashboards, data art, generative art, physical/tangible visualizations, ggplot2 extensions, etc.).\nEach project will have a peer review component to provide at least one round of feedback during the process of development. Teams will provide periodic peer feedback to their teammates while working on the projects as well as upon completion. The scores from the peer evaluations, along with individual contributions tracked by commits on GitHub, will be used to ensure that each student has contributed to the teamwork.\nAll team members must take part in the presentation. Presentations can be given in person in class, or via Zoom if the team prefers. My preference is that the team stick to one method of delivery (all presenters in person or all presenters on Zoom), but I realize a lot can change throughout this semester, and we‚Äôll adjust accordingly.\n\nAll work is expected to be submitted by the deadline and there are no make ups for any missed assessments. See [Late work policy] for policies on late work."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nAttendance and participation\n5%\n\n\nReading quizzes\n10%\n\n\nHomework assignments\n45%\n\n\nProject 1\n15%\n\n\nProject 2\n25%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60\n\n\n\nThese are upper bounds for grade cutoffs, depending on the class performance the cutoffs may be lowered but they won‚Äôt be increased."
  },
  {
    "objectID": "course-syllabus.html#teams",
    "href": "course-syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a different team for each of your two projects. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of each project and you will be asked to evaluate your team members after each assignment is due. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team‚Äôs overall mark.\nYou are expected to make use of the provided GitHub repository as their central collaborative platform. Commits to this repository will be used as a metric (one of several) of each team member‚Äôs relative contribution for each project."
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Don‚Äôt cheat!\nPlease abide by the following as you work on assignments in this course:\n\nCollaboration: Only work that is clearly assigned as team work should be completed collaboratively.\nThe reading quizzes must be completed individually with absolutely no communication with classmates.\nThe homework assignments must also be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what‚Äôs the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nSharing and reusing code: I am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course‚Äôs policy is that you may make use of any online resources (e.g.¬†RStudio Community, StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. On individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one‚Äôs own work, following proper citation of sources, adhering to guidance around group work projects, and more). Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action.\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline.\nPolicy on late work depends on the particular course component:\n\nReading quizzes: Late quizzes are not accepted and there are no make ups for missed quizzes.\nHomework assignments: GitHub repositories will be closed to contributions at the deadline. If you need to submit your work late, send a DM on Slack to Jackie Du (our Head TA) to reopen your repository.\n\nLate, but same day (before midnight): -10% of available points\nLate, but next day: -20% of available points\nTwo days late or later: No credit, and we will not provide written feedback\n\nProjects: The following three components contribute to your project score.\n\nPresentation: Late presentations are not accepted and there are no make ups for missed presentations.\nWrite up: GitHub repositories will be closed to contributions at the deadline. If you need to submit your work late, Slack/email me to reopen your repository.\n\nLate, but same day (before midnight): -10% of available points\nLate, but next day: -20% of available points\nTwo days late or later: No credit, and we will not provide written feedback\n\nPeer evaluation: Late peer evaluations are not accepted and there are no make ups for missed presentations. If you do not turn in your peer evaluation, you get 0 points for your own peer score as well, regardless of how your teammates have evaluated you.\n\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email the Head TA (Jackie Du, mailto:jacquelyn.du@duke.edu) before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade requests\nRegrade requests must be made within one week of when the assignment is returned, and must be typed up and submitted via email to the course Head TA (Jackie Du). These will be considered if points were tallied incorrectly or if you feel your answer is correct but it was marked wrong. No regrade will be made to alter the number of points deducted for a mistake. There will be no grade changes after the second project presentations. Note that during the regrade process your score could go up or go down or not change.\nNo grades will be changed after the project presentations.\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Trinity attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Lab time is dedicated to working on your homework assignments and collaborating with your teammates on your project. If you miss a lab session, make sure to communicate with your team about how you can make up your contribution. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you‚Äôre going to miss a lab session and you‚Äôre feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others‚Äô time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\nNote that attendance and participation is part of your grade as well.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university‚Äôs top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have symptoms related to COVID-19, have had a known exposure to COVID-19, or have tested positive for COVID-19. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health at 919-681-9355. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously or watching a recording of the class.\n\n\nPolicy on video recording course content\nAll lectures will be recorded and available on Panopto, so students should not need to create their own recordings of lectures. If you feel that you need record the lectures yourself, you must get permission from me ahead of time and these recordings should be used for personal study only, no for distribution. The full policy on recording of lectures falls under the Duke University Policy on Intellectual Property Rights, available at provost.duke.edu/sites/default/files/FHB_App_P.pdf. Unauthorized distribution is a cause for disciplinary action by the Judicial Board."
  },
  {
    "objectID": "course-syllabus.html#accommodations",
    "href": "course-syllabus.html#accommodations",
    "title": "Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you are a student with a disability and need accommodations for this class, it is your responsibility to register with the Student Disability Access Office (SDAO) and provide them with documentation of your disability. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: https://trinity.duke.edu/undergraduate/academic-policies/religious-holidays.\nNote: If you‚Äôve read this far in the syllabus, email me a picture of your pet if you have one or your favorite meme!"
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nWednesday, January 11: Classes begin, Monday schedule (no class for us)\nWednesday, January 25: Drop/add ends\nFriday, February 24: Mid-semester grades reported\nSaturday - Sunday, March 11 - 19: Spring Break (continuing, but limited course support available)\nWednesday, March 29: Last day to withdraw with W\nWednesday, April 26: Classes end\nThursday - Sunday, April 27 - 30: Reading period\nThursday, May 4, 2-5pm: Project 2 presentations\n\nFor more important dates, see the full Duke Academic Calendar."
  },
  {
    "objectID": "course-overview.html#termine",
    "href": "course-overview.html#termine",
    "title": "Kursinformationen",
    "section": "Termine",
    "text": "Termine\nAlle Details in der Syllabus.\n\nObligatorische Teilnahme am Blockseminar\nErste Sitzung zur Besprechung des Seminar am 04.04.2023 via Zoom\nSitzungen am 11., 08., und 25.04.2023 entfallen und werden durch verpflichtendes Blockseminar ersetzt"
  },
  {
    "objectID": "course-overview.html#√ºberblick",
    "href": "course-overview.html#√ºberblick",
    "title": "Kursinformationen",
    "section": "√úberblick",
    "text": "√úberblick\nKaum eine politische Krise wird nicht mit Populismus in Verbindung gebracht, durch ihn erkl√§rt oder als Treiber von Populismus eingeordnet. Nicht immer bauen die Argumente dabei auf guter wissenschaftlicher Arbeit auf. Populismus ist als Begriff umstritten und wird oftmals unterschiedlich verstanden. In dem Kurs wollen wir theoretisch verstehen, wie Populismus zu definieren ist, in welchem Spannungsfeld Populismus zur Demokratie steht, welche Effekte populistische Regierungen haben und welche Erkl√§rungen es f√ºr das Erstarken populistischer Parteien gibt.\nDer Kurs fokussiert dabei auch auf Research Design. Wire setzen wir uns mit theoretischen Konzepten rund um das Thema Populismus auseinander und diskutieren deren Annahmen und daraus resultierende Hypothesen. Im Anschluss diskutieren wir wie verschiedene Autoren diese Hypothesen empirisch √ºberpr√ºft haben. Welche Datens√§tze wurden genutzt, welche Methoden wurden angewendet und welche Annahmen liegen diesen Methoden zu Grunde?\nDurch das konkrete Thema, versucht der Kurs die Anwendnung quantitativer empirischer Methoden leicht verst√§ndlich und mit Anwendungsbeispielen zu vermitteln. Um die theoretischen Konzepte besser zu verstehen und ein besser Verst√§ndnis f√ºr die Entwicklung einer Forschungsfrage zu bekommen, wenden wir im Kurs in Gruppen kleine Fallstudien zu den Konzepten, Debatten zwischen den verschiedenen Konzepten und angeleitet erste Datens√§tze auswerten. Der Kurs setzt anstatt auf die w√∂chentlichen Referate auf viele, verschiedene interaktive Elemente, die auf der aktiven Mitarbeit der Studierenden basieren."
  },
  {
    "objectID": "course-overview.html#lernziel",
    "href": "course-overview.html#lernziel",
    "title": "Kursinformationen",
    "section": "Lernziel",
    "text": "Lernziel\n\n√úberblick √ºber die empirische Forschung zu Populismus\nHerleiten von Hypothesen\nEntwurf eines Research Designs zu Populismus\nLesen von einfachen quantitativen Analysen (bsp. Regressionstabellen)\nKenntnis √ºber verschiedene Datens√§tze im Bereich Populismus"
  },
  {
    "objectID": "course-overview.html#vorgehen",
    "href": "course-overview.html#vorgehen",
    "title": "Kursinformationen",
    "section": "Vorgehen",
    "text": "Vorgehen\n\nDiskussionen\nGruppenarbeiten zu Case Studies & mindestens einer strukturierten Debatte\nAnwendungs√ºbungen zur Analyse von Datens√§tzen\nSocial Media Analysen\nEntwicklung einer eigenen Forschungsfrage und Vorschl√§gen wie diese √ºberpr√ºft werden k√∂nnen"
  },
  {
    "objectID": "studienleistung.html#anwesenheitspflicht",
    "href": "studienleistung.html#anwesenheitspflicht",
    "title": "Studienleistung",
    "section": "Anwesenheitspflicht",
    "text": "Anwesenheitspflicht\nF√ºr den Kurs gilt eine Anwesenheitspflicht. Zwei Seminare d√ºrfen ohne Grund verpasst werden (eine kurze Notiz vorab freut mich aber). Solltet ihr dar√ºber hinaus l√§nger verhindert sein (beispielsweise durch eine Krankheit), kontaktiert mich bitte.\nDa das Blockseminar drei Seminare ersetzt gilt hier Anwesenheitspflicht."
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Hilfreiche Links",
    "section": "",
    "text": "Universit√§t Hamburg VPN | üîó on Uni Hamburg VPN"
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Alle Antworten auf weitere Fragen werden hier verewigt."
  },
  {
    "objectID": "hausarbeit.html",
    "href": "hausarbeit.html",
    "title": "Hausarbeit",
    "section": "",
    "text": "Um die in dem Seminar eine Modulpr√ºfung abzulegen gibt es zwei Optionen: die klassische Hausarbeit oder eine Replikationsstudie."
  },
  {
    "objectID": "hausarbeit.html#hausarbeit",
    "href": "hausarbeit.html#hausarbeit",
    "title": "Hausarbeit",
    "section": "Hausarbeit",
    "text": "Hausarbeit\nTBC"
  },
  {
    "objectID": "hausarbeit.html#replikationsstudie",
    "href": "hausarbeit.html#replikationsstudie",
    "title": "Hausarbeit",
    "section": "Replikationsstudie",
    "text": "Replikationsstudie\nTBC"
  },
  {
    "objectID": "sprechstunde.html#email",
    "href": "sprechstunde.html#email",
    "title": "Unterst√ºtzung",
    "section": "Email",
    "text": "Email\nIhr erreicht mich hier via E-mail.\n\nTechnik\nSolltet ihr technische Probleme haben (ein wichtiger Websitelink funktioniert nicht oder der w√∂chentliche Fragenkalatog funktioniert nicht, meldet euch bitte schnellstm√∂glich via E-mail bei mir. Wahrscheinlich haben in dem Fall andere ein √§hnliches Problem, da ein Fehler im Code vorliegt. Das behebe ich nach eurer Meldung so schnell wie m√∂glich.\n\n\nSonstiges\nAuch mit anderen Fragen k√∂nnt ihr euch gerne jederzeit via Mail an mich wenden. Von Montag-Freitag versuche ich euch an demselben Tag noch zu antworten. Am Wochenende werden die E-mails allerdings nicht gelesen."
  },
  {
    "objectID": "sprechstunde.html",
    "href": "sprechstunde.html",
    "title": "Unterst√ºtzung",
    "section": "",
    "text": "Meldet euch gerne f√ºr einen Sprechstundentermin bei mir per E-mail. Grunds√§tzlich habe ich Dienstags zwischen 14 und 16 Uhr immer f√ºr in-person Sprechstunden Termine Zeit, wir k√∂nnen aber gerne auch nach einem anderen Zeitfenster schauen.\nOrt: VMP9 A 408 oder Zoom"
  }
]